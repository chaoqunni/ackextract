<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/jwu/github/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Expression and Recognition of Emotions in the Voice Across Five Nations: A Lens Model Analysis Based on Acoustic Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Scherer</publisher>
				<availability status="unknown"><p>Copyright Scherer</p>
				</availability>
				<date type="published" when="1998">1998. 2012. 1992. 1994. 2010. 1997. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fiske</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kitayama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Nisbett</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jack</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Schyns</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sauter</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ekman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scott</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Stockholm University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Washington University</orgName>
								<address>
									<settlement>St. Louis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Sikkim University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">International University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">University of Queensland</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Olin Business School</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution">Stockholm University</orgName>
								<address>
									<addrLine>Hillary Anger Elfenbein, Washington University in St. Louis; Nutankumar S. Thingujam</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Nanyang Business School</orgName>
								<orgName type="institution">Sikkim University</orgName>
								<address>
									<addrLine>Thomas Rockstuhl</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">Nanyang Tech-nological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department" key="dep1">School of Humanities and Social Sciences</orgName>
								<orgName type="department" key="dep2">Haas School of Business</orgName>
								<orgName type="institution">International University</orgName>
								<address>
									<addrLine>Kenya; Wanda Chui</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">Berkeley; Jean Althoff, UQ Business School</orgName>
								<orgName type="institution" key="instit1">University of California</orgName>
								<orgName type="institution" key="instit2">University of Queensland</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Stockholm University</orgName>
								<address>
									<addrLine>106 91 Stock-holm</addrLine>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Expression and Recognition of Emotions in the Voice Across Five Nations: A Lens Model Analysis Based on Acoustic Features</title>
					</analytic>
					<monogr>
						<imprint>
							<publisher>Scherer</publisher>
							<biblScope unit="volume">111</biblScope>
							<biblScope unit="issue">5</biblScope>
							<biblScope unit="page" from="686" to="705"/>
							<date type="published" when="1998">1998. 2012. 1992. 1994. 2010. 1997. 2016</date>
						</imprint>
					</monogr>
					<note type="submission">This article was published Online First August 18, 2016.</note>
					<note>Supplemental materials: http://dx. The current article attempts to expand this tradition by providing the first direct test of an interactionist theory that has been proposed to integrate existing empirical evidence, namely dialect theory (Elfenbein, 2013; Elfenbein &amp; Ambady, 2002). In doing so, it presents a large-scale investigation that uses a lens model approach contributed equally, and appear in reverse-alphabetical order. We acknowledge Swedish Research Council 2006-1360 to Petri Laukka and U.S. National Science Foundation BCS-0617624 to Hillary Anger Elfenbein. Correspondence concerning this article should be addressed to Petri Laukka, 0022-3514/16/$12.00 http://dx.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0-SNAPSHOT" ident="GROBID-SDO" when="2019-12-20T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>culture</term>
					<term>dialect theory</term>
					<term>emotion</term>
					<term>in-group advantage</term>
					<term>speech</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study extends previous work on emotion communication across cultures with a large-scale investigation of the physical expression cues in vocal tone. In doing so, it provides the first direct test of a key proposition of dialect theory, namely that greater accuracy of detecting emotions from one's own cultural group-known as in-group advantage-results from a match between culturally specific schemas in emotional expression style and culturally specific schemas in emotion recognition. Study 1 used stimuli from 100 professional actors from five English-speaking nations vocally conveying 11 emotional states (anger, contempt, fear, happiness, interest, lust, neutral, pride, relief, sadness, and shame) using standardcontent sentences. Detailed acoustic analyses showed many similarities across groups, and yet also systematic group differences. This provides evidence for cultural accents in expressive style at the level of acoustic cues. In Study 2, listeners evaluated these expressions in a 5 Ï« 5 design balanced across groups. Cross-cultural accuracy was greater than expected by chance. However, there was also in-group advantage, which varied across emotions. A lens model analysis of fundamental acoustic properties examined patterns in emotional expression and perception within and across groups. Acoustic cues were used relatively similarly across groups both to produce and judge emotions, and yet there were also subtle cultural differences. Speakers appear to have a culturally nuanced schema for enacting vocal tones via acoustic cues, and perceivers have a culturally nuanced schema in judging them. Consistent with dialect theory's prediction, in-group judgments showed a greater match between these schemas used for emotional expression and perception.</p><p>A long research tradition in psychology has pondered to what extent emotional expressions are universal versus culturally spe-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" coords="2,48.00,77.04,63.54,7.91" target="#b13">(Brunswik, 1956)</ref> <p>to examine evidence for universal and culturally specific schemas in both the expression and perception of emotion. The current research also expands on past work by presenting cross-cultural data on the communication of emotion via vocal tones, as a complement to the vast majority of existing studies, which focus on static photographs of facial expressions . By contrast, other channels of communication, such as vocal tones, have received relatively less attention <ref type="bibr" coords="2,264.06,154.04,24.00,7.91;2,48.00,165.04,61.60,7.91" target="#b49">(Juslin &amp; Laukka, 2003)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialect Theory and In-Group Advantage</head><p>The current investigation is grounded in the framework of dialect theory <ref type="bibr" coords="2,101.52,220.04,62.63,7.91" target="#b22">(Elfenbein, 2013)</ref>, which was originally developed to help explain the phenomenon of in-group advantage-whereby individuals more accurately judge emotional expressions from their own cultural group compared with expressions from foreign groups. In 1964, <ref type="bibr" coords="2,113.02,264.04,48.51,7.91">Tomkins and</ref> McCarter wrote that cultural differences in emotional expression are like "dialects" of the "more universal grammar of emotion" (p. 127). Just as linguistic dialects can differ subtly in their accents, grammar, and vocabulary-such as American versus British English-we argue in this article for the existence of paralinguistic dialects. Although dialect theory drew primarily from work that had been conducted using facial expressions <ref type="bibr" coords="2,93.57,341.04,63.18,7.91" target="#b22">(Elfenbein, 2013)</ref>, its propositions are also likely to hold for emotion expressed through the voice, which typically shows in-group advantage as well <ref type="bibr" coords="2,176.02,363.04,88.64,7.91" target="#b49">(Juslin &amp; Laukka, 2003)</ref>. Like facial dialects, paralinguistic dialects should involve subtle yet systematic differences across cultures in the style of expressing emotion, in this case via acoustic cues in the voice. In addition, consistent with dialect theory, we argue that individuals tend to judge the vocal expressions of other people based on their own cultural style. Although the dialects of a language are still mutually intelligible, some of the meaning can get lost along the way. As in verbal language, it can be more challenging to understand the vocal tones of someone expressing emotions in a different emotional dialect, due to cultural differences in norms for expressing oneself and understanding others.</p><p>In the case of facial expression, previous studies strongly suggest-but do not conclusively prove-that systematic cultural differences in expression style can create the in-group advantage effect. One study examined composite facial expressions based on the left and right hemispheres of a face-that is, taking one photograph and turning it into two pictures, one that showed the left side twice and one that showed the right side twice <ref type="bibr" coords="2,247.81,561.04,40.24,7.91;2,48.00,572.04,163.52,7.91" target="#b28">(Elfenbein, Mandal, Ambady, Harizuka, &amp; Kumar, 2004)</ref>. In-group advantage was greater when participants judged the left hemisphere, which is more intense and mobile, compared with the right hemisphere, which is more prototypical. Expression style was the only plausible explanation, given that there was a fully within-subject design for both posers and judges. In another study, <ref type="bibr" coords="2,215.65,627.03,72.38,7.91;2,48.00,638.03,103.81,7.91" target="#b26">Elfenbein, BeauprÃ©, LÃ©vesque, and Hess (2007)</ref> identified differences in expressive style in terms of specific muscle movements that varied across the groups' posed facial expressions. Further, greater cultural differences in judgment accuracy were found for the emotions that had greater cultural differences in expression style. An additional source of evidence is that, in many studies of facial expression that do not show in-group advantage, the appearance of stimulus materials was deliberately constrained to be identical across cultures (e.g., <ref type="bibr" coords="2,327.25,77.03,86.26,7.91" target="#b7">BeauprÃ© &amp; Hess, 2005;</ref><ref type="bibr" coords="2,416.52,77.03,65.40,7.91" target="#b10">Biehl et al., 1997)</ref>. Taken together, these results suggest that in-group advantage results from cultural differences in the appearance of emotional expressions.</p><p>This article attempts to take a similar approach to the study of vocal tone. It has been argued that facial expressions are the most visible and controllable canvass for emotional expression, and that they can be made without necessarily being aware and without simultaneously communicating via other channels <ref type="bibr" coords="2,491.46,154.03,51.20,7.91;2,306.00,165.03,41.41,7.91" target="#b20">(Ekman &amp; Friesen, 1969)</ref>. By contrast, vocal expressions are often integrated into deliberate linguistic content. Because of these fundamental differences between communicative channels, we argue that it is worthwhile to examine to what extent past research on dialect theory replicates outside of the particular facial channel in which it has been primarily studied.</p><p>Beyond establishing that existing findings have greater generality, the current studies make a unique contribution by providing the first direct evidence for the core proposition of dialect theoryfor which the previous work reviewed was strongly suggestive and yet the evidence was indirect. In particular, dialect theory argues that differences in the cultural style of producing emotion expressions map onto differences in the style of judging them, and that together they create the phenomenon of in-group advantage. Directly testing this proposition requires a systematic measurement of the physical cues that produce emotional expressions, a task for which vocal expression is ideal. There are a large number of well-documented acoustic parameters that define human vocal cues, related to the pitch, loudness, timbre, and rate of speech, which can be measured objectively during all moments of vocal production (e.g., <ref type="bibr" coords="2,367.93,385.03,66.90,7.91" target="#b31">Eyben et al., 2016)</ref>. As such, the vocal channel is ideal for documenting the role of expressive style as a mechanism for in-group advantage. To achieve this, across the current studies we jointly measure both acoustic properties and human emotion judgments, and conduct a lens model analysis that integrates the expression and perception of vocal tone across cultures. The next section turns attention to this lens model approach.</p><p>properties in the voice. The right side of the model focuses on perception, which is also called decoding or the interpretation of cues. Listeners wish to understand the speaker's emotional state, and they attempt to do so by interpreting the acoustical properties that are available for them to hear. Based on these cues, they integrate both components of the lens model by attempting to infer the speaker's underlying emotion.</p><p>As such, conducting a lens model analysis of vocal expression involves several chronological stages. First, a study needs to identify a range of relevant acoustic cues that might indicate emotion, and then examine to what extent those cues are present versus absent in vocal tones expressing emotion. This is what <ref type="bibr" coords="3,48.00,451.04,63.22,7.91" target="#b13">Brunswik (1956)</ref> called cue validity. Second, a study needs to examine to what extent the acoustic cues are associated with perceivers' emotion judgments, which is what <ref type="bibr" coords="3,225.29,473.04,62.76,7.91" target="#b13">Brunswik (1956)</ref> called cue utilization. Third, the overall accuracy of perceivers' judgments is measured, in terms of the correspondence between their judgments and the intended emotional state. Cue validity and cue utilization can be described as the schemas that people use to express and judge properties of their social worlds, respectively. It is important to emphasize, as per <ref type="bibr" coords="3,184.72,539.04,70.41,7.91" target="#b13">Brunswik's (1956)</ref> original description, that both of these mirror-image processes are probabilistic. Individuals vary in their expression styles and perception styles, and there is room for flexibility and error throughout. From a lens model perspective, the accuracy of communication depends on the degree of correspondence between the speaker's style of expression and the style expected by the perceiver.</p><p>As argued by <ref type="bibr" coords="3,114.57,616.03,169.74,7.91" target="#b87">Scherer, Clark-Polner, and Mortillaro (2011)</ref>, expanding the use of the lens-model approach would be particularly valuable for cross-cultural research because cultural effects may exist in (a) the expression of emotion, which results in culturally specific patterns of acoustic cues; (b) the perception of emotion, which results from cultural differences in the way individuals attend to, perceive, and interpret various acoustic cues; or (c) both. The lens model has been an influential framework for the study of vocal expression <ref type="bibr" coords="3,141.17,704.03,54.15,7.91" target="#b83">(Scherer, 2003)</ref>. However, relevant work has been conducted exclusively in within-cultural settings (e.g., <ref type="bibr" coords="3,306.00,319.03,132.39,7.91" target="#b5">BÃ¤nziger, Hosoya, &amp; Scherer, 2015)</ref>, with the only cross-cultural study to date being on the acoustic cues within music <ref type="bibr" coords="3,513.79,330.03,32.23,7.91;3,306.00,341.03,170.31,7.91" target="#b52">(Laukka, Eerola, Thingujam, Yamasaki, &amp; Beller, 2013)</ref>. The current studies attempt to fill this gap, by extending research using the lens model across cultures to study human emotional states expressed through the voice. We use the lens model approach to generate evidence for the key proposition of dialect theory, namely that cultural differences in the production and perception of specific expression cues combine to create the phenomenon of in-group advantage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Existing Cross-Cultural Studies on Vocal Expression and the Current Research</head><p>In this section we first review existing cross-cultural studies on vocal expression, and then describe how the current research attempts to extend the previous body of work. We start with a discussion of expression (also called encoding) studies and then proceed with perception (also called decoding) studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expression of Emotion</head><p>Research has investigated the acoustic properties associated with various emotions (e.g., <ref type="bibr" coords="3,416.04,572.04,91.45,7.91" target="#b4">Banse &amp; Scherer, 1996;</ref><ref type="bibr" coords="3,511.56,572.04,29.56,7.91;3,306.00,583.04,94.43,7.91" target="#b41">Hammerschmidt &amp; JÃ¼rgens, 2007;</ref><ref type="bibr" coords="3,403.33,583.04,86.43,7.91" target="#b48">Juslin &amp; Laukka, 2001;</ref><ref type="bibr" coords="3,492.66,583.04,53.38,7.91;3,306.00,594.04,83.14,7.91" target="#b78">Sauter, Eisner, Calder, &amp; Scott, 2010)</ref>. These studies have been conducted with several different languages, and findings across the studies suggest that there is a basic consistency to the acoustic properties associated with basic emotions such as anger, fear, happiness, and sadness <ref type="bibr" coords="3,336.88,638.04,90.90,7.91" target="#b49">(Juslin &amp; Laukka, 2003;</ref><ref type="bibr" coords="3,431.17,638.04,52.49,7.91" target="#b83">Scherer, 2003)</ref>. However, relatively little work has examined vocal tones from more than one culture within the same study (e.g., <ref type="bibr" coords="3,446.27,660.04,99.76,7.91" target="#b12">Braun &amp; Heilmann, 2012;</ref><ref type="bibr" coords="3,306.00,671.04,94.27,7.91" target="#b34">Fonagy &amp; Magdics, 1963;</ref><ref type="bibr" coords="3,402.44,671.04,143.60,7.91;3,306.00,682.04,20.50,7.91" target="#b68">Pell, Paulmann, Dara, Alasseri, &amp; Kotz, 2009;</ref><ref type="bibr" coords="3,329.50,682.04,131.15,7.91" target="#b72">Ross, Edmondson, &amp; Seibert, 1986)</ref>. These studies usually do not provide data on systematic tests of cultural differences in acoustic properties, potentially due to the relatively small sample sizes. The number of participants serving as speakers in these This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly. studies tends to range from two to five per culture, or is not reported. A notable exception is <ref type="bibr" coords="4,166.50,88.04,121.55,7.91;4,48.00,99.04,43.47,7.91" target="#b3">Anolli, Wang, Mantovani, and de Toni (2008)</ref>, who compared vocal expressions portrayed by 30 Chinese and 20 Italian undergraduate students. They identified similarities and differences between how the two groups modulated some acoustical parameters in their vocal expressions, and did not investigate emotion perception with these vocal stimuli.</p><p>The closest study to date was based on machine learning, and also did not involve human data on emotion perception. <ref type="bibr" coords="4,258.78,165.04,29.24,7.91;4,48.00,176.04,117.33,7.91" target="#b55">Laukka, Neiberg, and Elfenbein (2014)</ref> used a corpus of stimuli from Australia, India, Kenya, Singapore, and the United States <ref type="bibr" coords="4,258.06,187.04,29.98,7.91;4,48.00,198.04,44.21,7.91" target="#b54">(Laukka et al., 2010)</ref>. They trained acoustic-based classifier programs to recognize emotional expressions. For each model, training was based on stimuli from one cultural group, and recognition was based either on stimuli from the same group on which it was trained or on stimuli from a different group. Accuracy was at levels greater than what would be expected by chance, regardless of whether classifiers were trained and tested on stimuli from the same versus different cultures. This provides evidence for basic universals in the acoustic cues for emotional expression. However, accuracy was higher when classifiers were trained and tested on stimuli from the same versus different cultures. This finding demonstrated systematic acoustic differences across cultures because, logically, no human bias or other influences could have been responsible for better accuracy. The present research builds on this work, using stimuli from the same corpus of vocal tones. We extend this work by conducting acoustical analysis to document which specific paralinguistic cues are responsible for the cultural differences. Further, we collect judgment data from participants versus machine learning models. That is, we know from <ref type="bibr" coords="4,190.91,396.04,79.27,7.91" target="#b55">Laukka et al. (2014)</ref> that cultural differences exist and that they can create in-group advantage under certain simulated circumstances. However, we do not yet know what particular differences these may be, or whether they would create in-group advantage with real human listeners. <ref type="table" coords="4,57.00,484.04,33.39,7.91" target="#tab_0">Table S1</ref> in the online supplemental material contains a comprehensive description of 40 cross-cultural studies of vocal emotion recognition, and we briefly review this literature below. In these cross-cultural studies, vocal expressions are recorded from at least one national or ethnic group, and afterward they are judged by members of their own in-group and at least one national or ethnic group outside of their origin. In the typical design, participants listen to vocal stimuli, and after each stimulus provide a forced-choice judgment among the emotion categories being tested. Within this basic design, there have been three main variations. First, in the most common variant, the many-on-one design, individuals from multiple groups judge stimuli originating from a single group (e.g., <ref type="bibr" coords="4,115.88,616.04,89.89,7.91" target="#b2">Altrov &amp; Pajupuu, 2015;</ref><ref type="bibr" coords="4,208.16,616.04,79.88,7.91" target="#b8">Beier &amp; Zautra, 1972;</ref><ref type="bibr" coords="4,48.00,627.04,136.52,7.91" target="#b39">Graham, Hamblin, &amp; Feldstein, 2001;</ref><ref type="bibr" coords="4,186.72,627.04,101.32,7.91;4,48.00,638.04,20.50,7.91" target="#b85">Scherer, Banse, &amp; Wallbott, 2001;</ref><ref type="bibr" coords="4,71.79,638.04,145.69,7.91" target="#b98">Van Bezooijen, Otto, &amp; Heenan, 1983;</ref><ref type="bibr" coords="4,220.78,638.04,63.39,7.91" target="#b99">Waaramaa, 2015)</ref>. Second, in the one-on-many design, individuals from a single group judge stimuli originating from multiple groups (e.g., <ref type="bibr" coords="4,48.00,671.04,52.40,7.91" target="#b50">Kramer, 1964;</ref><ref type="bibr" coords="4,102.56,671.04,144.81,7.91" target="#b67">Pell, Monetta, Paulmann, &amp; Kotz, 2009;</ref><ref type="bibr" coords="4,249.53,671.04,38.50,7.91;4,48.00,682.04,69.58,7.91" target="#b95">Thompson &amp; Balkwill, 2006)</ref>. In the third main variation, the balanced design, stimuli from multiple groups are judged by members of each of these groups. Most balanced studies examine emotion recognition accuracy with two cultural groups (e.g., <ref type="bibr" coords="4,246.16,715.04,41.88,7.91;4,306.00,77.04,91.43,7.91">Albas, Mc-Cluskey, &amp; Albas, 1976;</ref><ref type="bibr" coords="4,400.41,77.04,96.18,7.91" target="#b66">Paulmann &amp; Uskul, 2014;</ref>, and a few studies have examined three cultural groups <ref type="bibr" coords="4,306.00,99.04,102.26,7.91" target="#b12">(Braun &amp; Heilmann, 2012;</ref><ref type="bibr" coords="4,412.26,99.04,50.75,7.91" target="#b17">Davitz, 1964;</ref><ref type="bibr" coords="4,467.02,99.04,74.35,7.91;4,306.00,110.04,91.84,7.91" target="#b89">Shochi, Rilliard, AubergÃ©, &amp; Erickson, 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perception of Emotion</head><p>Overall, these studies tend to provide evidence for at least minimal universality <ref type="bibr" coords="4,386.24,132.04,54.99,7.91" target="#b74">(Russell, 1994)</ref>, in that participants recognized vocal stimuli from foreign groups more accurately than one would expect from chance guessing alone. In this respect, some of the most revealing studies have recently examined physically isolated cultural groups with little exposure to mass media (e.g., <ref type="bibr" coords="4,306.00,187.04,92.19,7.91" target="#b14">Bryant &amp; Barrett, 2008;</ref><ref type="bibr" coords="4,480.76,187.04,65.30,7.91;4,306.00,198.04,144.63,7.91" target="#b16">Cordaro, Keltner, Tshering, Wangchuk, &amp; Flynn, 2016)</ref>. The finding that these groups are accurate in understanding foreign vocal tones suggests the possibility of innate biological influences on the emotion perception process, because physical isolation limits the plausibility of alternative explanations such as cultural learning. We note that-beyond this minimal universality-all but three of the 40 studies listed in <ref type="table" coords="4,363.98,264.03,32.15,7.91" target="#tab_0">Table S1</ref> in the online supplemental material show some degree of in-group advantage (cf., <ref type="bibr" coords="4,458.62,275.03,69.08,7.91" target="#b0">Albas et al., 1976;</ref><ref type="bibr" coords="4,531.05,275.03,14.99,7.91;4,306.00,286.03,178.20,7.91">Mc-Cluskey, Albas, Niemi, Cuevas, &amp; Ferrer, 1975;</ref><ref type="bibr" coords="4,487.19,286.03,39.11,7.91" target="#b101">Zhu, 2013)</ref>.</p><p>In evaluating evidence for in-group advantage, it is worth emphasizing data from balanced designs, which provide the greatest amount of information. It is important to note that they are able to control for the possible extraneous influence of main effects across expresser and perceiver cultural groups, and they test cultural differences in the form of an interaction effect. After all, any two samples can vary along dimensions other than cultural group. For example, emotion recognition accuracy is influenced by gender composition, age, education level, and socioeconomic status (e.g., <ref type="bibr" coords="4,306.00,396.03,149.49,7.91" target="#b40">Hall, Andrzejewski, &amp; Yopchick, 2009;</ref><ref type="bibr" coords="4,459.18,396.03,44.93,7.91" target="#b44">Izard, 1971;</ref><ref type="bibr" coords="4,507.80,396.03,38.25,7.91;4,306.00,407.03,146.60,7.91" target="#b70">Rosenthal, Hall, DiMatteo, Rogers, &amp; Archer, 1979)</ref>, among other factors that can vary across national samples. Likewise, in spite of attempts to create equivalent stimuli from multiple groups, the recorded expressions could also vary due to differences in recording conditions and equipment, or the skill levels of the individual expressers. Expression and recognition can also be influenced by comfort with the laboratory setting, which tends to be greater among Western university students because they more frequently serve as research participants. Taken together, the ability to control for these known and potentially unknown factors is worthwhile, and the current investigation therefore uses a large-scale balanced design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Current Research: Testing Dialect Theory Using a Lens Model Analysis</head><p>Dialect theory proposes that in-group advantage results from a match between culturally specific schemas in emotional expression style and culturally specific schemas in emotion recognition <ref type="bibr" coords="4,306.00,616.04,63.04,7.91" target="#b22">(Elfenbein, 2013)</ref>. In the current article, we test this proposition directly using three steps. In Study 1, we examine the expression, or encoding, side of the lens model (see <ref type="figure" coords="4,450.74,638.04,28.94,7.91" target="#fig_0">Figure 1</ref>). We hypothesize that there may be systematic differences across cultures in the style of expressing emotion through the voice, and we test this hypothesis by documenting at a micro level the presence of specific nonverbal cues that are used similarly or differently across five cultures. In an effort to maximize the quality of vocal portrayals in producing diagnostic cues, we employ professional actors in each country. We also sample a larger than usual number of speakers This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>from each culture, in order to reduce the possibility of specific item effects that are idiosyncratic to particular individuals. In addition, we include a large number of emotion categories, compared with what has been typically used in previous work, including more positive emotions than usual. Finally, we use an extensive number of acoustic cues, with a set of parameters that has been newly proposed as a potential standard for research on human vocal acoustics <ref type="bibr" coords="5,83.99,154.04,71.84,7.91" target="#b31">(Eyben et al., 2016)</ref>. We next focus on the decoding side of the lens model. Study 2 examines the effect of culture on emotion recognition accuracy. We test both for cultural universality, in the form of better-thanchance accuracy across groups, as well as cultural specificity in the form of in-group advantage. In doing so, we use a balanced design in which vocal expressions from five cultural groups are judged by individuals from each of these groups. The advantage of using such a large design is that it provides a large amount of data using comparable methods from multiple cultures, which provides more generalizable evidence than that based on a smaller number of groups. It also provides the opportunity to examine how relative cultural distance can influence cross-cultural differences in emotion recognition. For example, there may be lesser in-group advantage when speakers and listeners are from Western cultures versus when one group is from the West and another is from East Asia or Africa. Including a relatively large number of cultural groups is challenging but necessary to make such a comparison.</p><p>In the final step to test dialect theory, we connect encoding and decoding together into a lens model analysis. More specifically, we compare the schemas that speakers use to express their emotion via acoustical cues with the schemas that listeners use to judge others' vocal expressions. Based on dialect theory, we hypothesize that the correspondence between these two types of schemas-that is, for expression and for perception-should be greater when speakers and listeners come from the same versus different cultural backgrounds. This paper provides the first reported test of how the expressive styles for producing and judging cues map onto each other across cultures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 1: Effect of Culture on the Expression of Emotion in the Voice</head><p>The first part of this investigation involves documenting the acoustic cues that speakers use across cultures in conveying their nonverbal expressions of emotion through the voice. The current study is the first to examine systematically to what extent the schemas for using acoustic cues to express emotion have both commonalities and systematic differences across cultural groups. In terms of the lens model discussed above (see <ref type="figure" coords="5,227.21,583.54,29.61,7.91" target="#fig_0">Figure 1</ref>), this is the stage of cue validity, and serves as the first step of testing dialect theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Stimulus materials. Vocal stimuli were selected from the Vocal Expressions of Nineteen Emotions across Cultures (VENEC) database, which consists of emotion portrayals by 100 professional actors across five cultures (Australia, India, Kenya, Singapore, and the United States; <ref type="bibr" coords="5,120.27,693.04,76.63,7.91" target="#b54">Laukka et al., 2010)</ref>. To prevent confounds across linguistic backgrounds, each of the included cultures is from a country where English is an official language. The English language was chosen due to its use in a wide range of countries, and the specific countries were selected to sample English speakers from diverse geographic locations. The selected countries also vary greatly with respect to <ref type="bibr" coords="5,406.01,110.62,65.09,7.91" target="#b43">Hofstede's (2001)</ref> cultural dimensions. Considering the five dimensions in <ref type="bibr" coords="5,434.32,121.81,107.58,7.91;5,306.00,133.01,50.74,7.91">Hofstede's model (www.geerthofstede.com;</ref><ref type="bibr" coords="5,359.04,133.01,56.41,7.91" target="#b43">Hofstede, 2001)</ref>, (a) Australia and the United States are often considered individualistic societies, whereas India, Kenya, and Singapore are more collectivistic, (b) India, Kenya, and Singapore are considered high in power distance, whereas the United States and Australia are low, (c) Singapore is low in uncertainty avoidance, with the other four cultures having moderate levels, (d) in terms of masculinity, levels from lowest to highest are Singapore, India, Kenya, the United States, and Australia, and (e) long-term orientation is lower in Australia, Kenya, and the United States, and higher in India and Singapore.</p><p>For the sake of consistency, a "professional actor" was defined in each nation as an individual who had been paid on at least one occasion for their acting. The database contains recordings from 20 actors from each culture (50% women; ages Ï­ 18 -30 years), each of whom was born and raised in their respective country and spoke English since birth or early childhood. In order to increase cultural homogeneity within the sample, recruitment was limited to members of the Marathi ethnic group in India, Chinese ethnic group in Singapore, and Caucasian individuals in Australia and the United States. Each actor conveyed 18 affective states (affection, anger, amusement, contempt, disgust, distress, fear, guilt, happiness, interest, lust, negative surprise, positive surprise, pride, relief, sadness, serenity, and shame), each with three levels of emotion intensity (below average, moderately high, and very high). For comparison, each actor recorded emotionally neutral expressions. In order to maintain consistency across portrayals, in each case the verbal material consisted of short phrases with emotionally neutral standard content ("Let me tell you something", "That is exactly what happened"). This resulted in 1,100 stimuli per culture (20 actors Ï« 18 intended emotions Ï« 3 levels of intensity, plus 1 neutral expression per actor), for a total of 5,500 stimuli from five cultures. As a whole, the VENEC corpus can be expected to contain a diversity of expressive styles due to speaker, culture, and emotion intensity effects.</p><p>The actors were first provided with scenarios based on the appraisal theory of emotion (e.g., <ref type="bibr" coords="5,439.90,524.77,106.15,7.91" target="#b29">Ellsworth &amp; Scherer, 2003;</ref><ref type="bibr" coords="5,306.00,535.97,54.40,7.91" target="#b57">Lazarus, 1991;</ref><ref type="bibr" coords="5,363.56,535.97,117.29,7.91" target="#b62">Ortony, Clore, &amp; Collins, 1988)</ref>. These scenarios describe typical situations in which each of the above emotions may be elicited, and actors were instructed to try to enact finding themselves in these situations. The scenarios presented to the actors are available in the online supplemental material. The protocol further asked the speakers to try to remember similar situations that they had experienced personally and that had evoked the specified emotions. They were asked, if possible, to try to put themselves into the same emotional state of mind. The classic method of acting out emotional episodes by reactivating past emotional experiences is common among actors <ref type="bibr" coords="5,497.31,647.90,48.75,7.91;5,306.00,659.09,19.37,7.91" target="#b91">(Stanislavski, 1936)</ref>. These instructions were used to encourage consistency in the methods employed by the individuals providing stimuli, and to limit idiosyncratic or cultural differences in interpreting the meaning of each emotional category label. The actors were also instructed to try to express the emotions as convincingly as possible, but without using overtly stereotypical expressions. Experimenters This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>did not provide the actors with feedback or recommendations of any kind. The recordings were conducted on location in each country (Brisbane, Australia; Pune, India; Nairobi, Kenya; Singapore, Singapore; and Los Angeles, United States). Conditions were standardized across locations, in order to maximize consistency in the methods. All recordings took place in localities with dampened acoustics, and the actors' speech was recorded directly onto a computer with 44 kHz sampling frequency using a high-quality microphone (sE Electronics USB2200A, Shanghai, China). To enable a wide dynamic range while avoiding clipping, each actor first produced sample stimuli, and recording levels were optimized and held constant based on the loudest sample.</p><p>Selection of vocal stimuli. We sampled 550 expression portrayals from the VENEC corpus. Doing so first involved selecting 10 of the 18 affective states (anger, contempt, fear, happiness, interest, sexual lust, pride, relief, sadness, and shame). In each case, to reduce the number of stimuli and to limit floor effects, we used only the vocal tones expressed in the condition with instructions for a moderately high level of emotion intensity. We also included the emotionally neutral utterances, which provide a baseline to compare emotionally expressive stimuli. Further, in Study 2 with human listeners, the inclusion of neutral voices provides an option that effectively serves as a non-of-the-above option if participants do not believe that any item is appropriate from the forced-choice list of emotional categories.</p><p>In reducing the number of emotion categories, we relied on the same items as in <ref type="bibr" coords="6,116.53,374.04,76.76,7.91" target="#b55">Laukka et al. (2014)</ref>. This selection included well-studied emotional states that are largely agreed to represent basic emotions (anger, fear, happiness, and sadness; e.g., <ref type="bibr" coords="6,260.29,396.04,27.75,7.91;6,48.00,407.04,19.37,7.91" target="#b19">Ekman, 1992)</ref>. This also included several less well-studied emotions that are considered basic emotions by some but not all theorists: contempt, interest, lust, and relief (see <ref type="bibr" coords="6,188.54,429.04,82.59,7.91" target="#b97">Tracy &amp; Randles, 2011</ref>, for a summary of the current debate). For variety and to increase the available data, we also included two self-conscious emotions <ref type="bibr" coords="6,48.00,462.04,91.73,7.91" target="#b93">(Tangney &amp; Tracy, 2012</ref>)-pride and shame-which have rarely figured in studies of vocal expression. Notably, and in contrast to most previous empirical work that has focused on negative emotions (see <ref type="bibr" coords="6,85.90,495.03,47.57,7.91" target="#b76">Sauter, 2010)</ref>, our selection included equal numbers of positive and negative emotions. This allows us to explore which positive emotions have recognizable vocal signals across cultures.</p><p>We further reduced the number of stimuli using a pretest to indicate those among the portrayals that were best recognized and, thus, most likely to contain diagnostic acoustical cues. In a small within-cultural pilot test of N Ï­ 121, all moderate-intensity portrayals from each culture were judged in a forced-choice format by individuals from the same cultural group as each set of stimuli. The pilot test included all 19 affective states that are contained in the larger VENEC corpus, and was not limited to the emotional states included in the current study. This resulted in 380 stimuli per culture (20 actors Ï« 19 intended expressions Ï­ 380 stimuli per culture). Due to the cumbersome nature of including 19 options in a forced-choice design, separate tests were conducted for positive and negative expressions. Listeners were asked to choose one emotion label that best described the expressed emotion for each stimulus. They used an 11-alternative forced-choice task, which included the 9 states from that valence as well as neutral. In addition, the task included a none-of-the-above option which was labeled as "other emotion" in participant instructions. The re-sponse options for the negative valence test were anger, contempt, disgust, distress, fear, guilt, neutral, sadness, shame, (negative) surprise, and "other emotion". The options for the positive valence test instead were affection, amusement, happiness, interest, lust, neutral, pride, relief, serenity, (positive) surprise, and "other emotion". Each response option was explained to pilot participants by giving them the same scenarios as presented to the actors (see online supplemental material), to ensure that emotion words were interpreted similarly across individuals and cultures. Participants listened to the stimuli through headphones, and the experiments were run individually using MediaLab software <ref type="bibr" coords="6,485.47,187.03,50.40,7.91" target="#b46">(Jarvis, 2008)</ref> to present stimuli and record responses.</p><p>The pilot tests were conducted on location in each respective country (Brisbane, Australia; Pune, India; Nairobi, Kenya; Singapore, Singapore; and Berkeley, United States). Pilot participants judged all stimuli in Australia (N Ï­ 8, 6 women, age M Ï­ 29.1), India (N Ï­ 24, 9 women, age M Ï­ 25.2), and the United States (N Ï­ 25, 14 women, age M Ï­ 31.0). Due to time constraints, a small number of participants could only judge one valence or the other in Kenya (total N Ï­ 30, 15 women, age M Ï­ 22.0; negative emotions N Ï­ 28, positive emotions N Ï­ 30), and Singapore (total N Ï­ 34, 18 women, age M Ï­ 22.8; negative emotions N Ï­ 31, positive emotions N Ï­ 30). This led to a total of 121 participants involved, who were all born and raised in their respective country and spoke English since birth or early childhood.</p><p>The pilot test results were used to select the portrayals with the highest recognition accuracy. This included separately for each of the five cultures: five male and five female stimuli for each of the 11 selected expressions, for a final total of 550 vocal stimuli. The overall proportion of correct recognition for the selected stimuli was 42.5%, which is 4.7 times higher than chance performance (chance level Ï­ 9.1%). The rates for the individual emotions were: anger (63.8%), neutral (59.4%), sadness (51.5%), lust (50.3%), relief (45.8%), fear (37.8%), happiness (36.2%), contempt (34.7%), interest (33.0%), pride (29.3%), and shame (26.1%). Note that, for these moderate intensity-level stimuli, selecting the most highly recognized items did not lead to ceiling effects. The number of portrayals that each individual actor contributed to this selection varied.</p><p>Acoustic analysis. Vocal stimuli were analyzed with regard to 65 acoustic parameters. For overviews on voice physiology, acoustics, and perception, see <ref type="bibr" coords="6,397.41,528.02,97.94,7.91" target="#b51">Kreiman and Sidtis (2011)</ref> and <ref type="bibr" coords="6,514.31,528.04,31.74,7.91;6,306.00,539.04,99.60,7.91" target="#b69">Raphael, Borden, and Harris (2011)</ref>. First, we first utilized openSMILE software <ref type="bibr" coords="6,340.50,550.04,167.04,7.91" target="#b32">(Eyben, Weninger, Gross, &amp; Schuller, 2013)</ref> to extract the parameters included in the Geneva Minimalistic Acoustic Parameter Set (GeMAPS; see <ref type="bibr" coords="6,420.51,572.04,67.59,7.91" target="#b31">Eyben et al., 2016</ref>, for a detailed description). GeMAPS provides a standardized state-of-the-art method to measure a baseline set of acoustic cues containing frequency, energy, spectral balance, and temporal descriptors. Frequency related cues include aspects of the fundamental frequency (F0) of the voice-which represents the rate of vocal fold vibration and is strongly correlated to the perception of pitch-and the vocal tract resonance frequencies called formants. Energy cues refer to aspects of the intensity of the voice signal, which is subjectively heard as loudness and reflects the effort required to produce the speech. The third class of cues reflects the spectral balance of the voice signal. These cues are related to perceived voice quality, or the timbre of the voice, and are influenced by a variety of laryngeal and supralaryngeal features. Temporal cues, finally, include infor-This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>mation about the rate and duration of voiced and unvoiced speech segments. We used a prerelease version of GeMAPS that contained 58 cues. The GeMAPS features were selected by an international expert group, based on (a) their potential to reflect physiological changes in voice production (e.g., , (b) the frequency and success with which they have been used in previous studies, and (c) their theoretical significance (e.g., <ref type="bibr" coords="7,48.00,165.04,51.63,7.91" target="#b80">Scherer, 1986)</ref>. Experiments have demonstrated that classification models can be applied to vocal expressions using GeMAPS and achieve good recognition accuracy <ref type="bibr" coords="7,180.51,187.04,73.40,7.91" target="#b31">(Eyben et al., 2016)</ref>. Indeed, this work shows that these particular cues provide recognition accuracy on par with that of much larger parameter sets.</p><p>Second, we added seven cues not in GeMAPS. This included six cues containing dynamic frequency and energy information (i.e., delta regression coefficients and proportion of frames with rising or falling frequency/energy). For the final cue, we added utterance duration (which provides a measure of speech rate for standard content utterances) to the parameter set. This led to a total of 65 acoustic cues. The additional parameters were extracted using Praat software <ref type="bibr" coords="7,254.31,286.04,33.76,7.91;7,48.00,297.04,63.54,7.91" target="#b11">(Boersma &amp; Weenink, 2008)</ref>, and we refer readers to <ref type="bibr" coords="7,199.45,297.04,88.60,7.91;7,48.00,308.04,102.46,7.91" target="#b56">Laukka, Neiberg, Forsell, Karlsson, and Elenius (2011)</ref> for details.</p><p>Because 65 cues can provide a potentially unwieldy data set, results for the 550 stimuli were included in a principal components analysis with varimax normalized rotation. This allowed us to reduce the number of acoustic cues to include in the subsequent statistical analyses. Parallel analysis indicated the number of factors to retain, as implemented in the "paran" package in R <ref type="bibr" coords="7,203.38,374.04,45.10,7.91" target="#b18">(Dinno, 2009</ref>). This revealed a 14-factor solution. Based on the PCA results, 16 cues were retained based on the highest factor loadings and/or interpretability for each class of cues. <ref type="table" coords="7,114.37,407.04,26.48,7.91" target="#tab_0">Table 1</ref> lists these acoustic parameters. A description of the full set of cues, and their factor loadings, is available in the online supplemental material in <ref type="table" coords="7,161.33,429.04,30.03,7.91" target="#tab_1">Table S2</ref>.</p><p>It is valuable to control for individual differences in baseline values between actors while enabling the comparison of the direc-tion and magnitude of acoustic variation across conditions <ref type="bibr" coords="7,521.07,77.03,24.99,7.91;7,306.00,88.30,61.87,7.91" target="#b4">(Banse &amp; Scherer, 1996;</ref><ref type="bibr" coords="7,370.18,88.30,84.69,7.91" target="#b48">Juslin &amp; Laukka, 2001;</ref>. For example, a person's physical size or gender can influence the size and shape of their throat, vocal folds, and laryngeal and supralaryngeal features. Individual differences of these types are nuisance factors that are worthwhile to control when examining emotional expression cues. For this reason, the raw values for each cue were normalized using a Fisher z transformation across all portrayals produced by each actor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Analyses were conducted to examine evidence for cultural universals and differences in the acoustical patterns associated with vocal expressions of emotions across five groups. For each of the 16 acoustic cues used in analysis, a separate 5 (expresser culture: Australia, India, Kenya, Singapore, and the United States) Ï« 11 (emotion: anger, contempt, fear, happiness, interest, lust, neutral, pride, relief, sadness, and shame) between-groups analysis of variance (ANOVA) examined speakers' use of the cue. Results of these analyses appear in <ref type="table" coords="7,397.95,304.75,26.86,7.91" target="#tab_1">Table 2</ref>.</p><p>All cues showed a main effect for emotion, which indicated that actors made use of these cues to distinguish their portrayals differently across emotional states. The trends for this emotion main effect are summarized in <ref type="table" coords="7,403.61,349.80,27.65,7.91" target="#tab_1">Table 2</ref>, in terms of which emotional categories tend to have high, medium, or low levels for each cue. More details are available in the supplemental materials <ref type="table" coords="7,511.33,372.30,30.81,7.91" target="#tab_2">Table S3</ref>, including mean values and 95% confidence intervals. The acoustic profiles are generally in line with previous research (e.g., <ref type="bibr" coords="7,515.60,394.80,30.44,7.91;7,306.00,406.05,53.53,7.91" target="#b49">Juslin &amp; Laukka, 2003)</ref> for the well-studied emotions (anger, fear, happiness, and sadness), and also provide new data on the acoustic patterns associated with less well-studied emotions. Relatively little previous data are available for the vocal expression of contempt, interest, lust, pride, relief, and shame. Note. For a more comprehensive description of the acoustic cues, see <ref type="bibr" coords="7,278.48,706.70,61.68,7.03" target="#b31">Eyben et al. (2016)</ref> and <ref type="bibr" coords="7,355.95,706.70,63.90,7.03" target="#b56">Laukka et al. (2011)</ref>. See text for description of the models yielding the factor loadings listed. This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>Note that the main effect for the culture of speaker is not included, because it is not meaningful when analyzing z scores that control for individual differences across speakers.</p><p>Within these ANOVAs, the effect of primary interest is the Emotion Ï« Expresser Culture interaction. These were statistically significant for 13 of the 16 cues, including at least one cue per type, that is, frequency-related cues, energy-related cues, spectral balance cues, and temporal cues. After using a Bonferroni correction to account for the large number of tests conducted, values remained significant for 9 of the 16 cues, again including at least one cue per type. Given these significant omnibus results, we conducted a series of post hoc analyses to understand how these cues varied across expresser culture. Separately for each emotion and for each acoustic cue, we conducted one-way ANOVAs (5 expresser cultures) predicting the speaker's use of the cue. <ref type="table" coords="8,85.97,649.04,26.22,7.91" target="#tab_2">Table 3</ref> lists acoustic cues that differ across cultures. In the interest of space and exploratory analysis, only statistically significant differences are displayed in <ref type="table" coords="8,143.79,671.04,24.83,7.91" target="#tab_2">Table 3</ref>. Descriptive statistics for each cue as a function of emotion and culture are available in the supplementary <ref type="table" coords="8,64.86,693.04,30.79,7.91" target="#tab_2">Table S3</ref>. Significant effects of culture on acoustic cues were observed for each emotion, with the largest number of effects emerging for anger and lust. For anger, portrayals from Singapore seem to have been portrayed with stronger vocal effort compared with other cultures, as suggested by, for example, relatively higher values of F0M and IntM, and lower values of Hammarberg and H1-A3. For lust, Indian portrayals stood out with lower values of HNR, F1Amplitude, Hammarberg, H1-A3, and VoicedSegM, which in turn suggests that they were portrayed more forcefully than in other cultures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>These data provide evidence for both cultural similarities and cultural differences in the use of acoustic cues to convey emotion through the human voice. Alongside universals in the pattern of cues, there were subtle differences in the acoustic cues in these nonverbal expressions of emotion. We used a corpus of stimuli that were collected with the intention of being as similar as possible in every manner other than the cultural background of speakers. A total of 100 professional actors portrayed 10 different affective states. Based on pilot testing, a total of 550 vocal tones were used from five cultures, which is a larger stimulus set than that used in research typically conducted on vocal tone. Results suggest that, Note. Underlined F values remained significant p Ï½ .05 after Bonferroni adjustment for multiple testing. High (1) and low (2) denotes cues with z values above 0 or below 0, respectively; as indicated by 95% CI not overlapping with 0. Medium (Ï­) denotes cues with z values around 0, as indicated by 95% CI that includes 0. An Ï­ anger; Co Ï­ contempt; Fe Ï­ fear; Ha Ï­ happiness; In Ï­ interest; Lu Ï­ lust; Ne Ï­ neutral; Pr Ï­ pride; Re Ï­ relief; Sa Ï­ sadness; Sh Ï­ shame. See <ref type="table" coords="8,107.76,449.70,24.88,7.03" target="#tab_0">Table 1</ref> for an explanation of cue abbreviations. a F(10, 493). b F(10, 494).</p><p>This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>consistent with dialect theory, speakers tend to have subtly differing schemas across cultures for the cues they use to convey their emotional states. This new evidence provides detailed information about the specific acoustic cues involved in cross-cultural similarities and differences. Notably, effects of culture were observed for all types of acoustic cues (frequency, intensity, spectral balance and temporal features), which suggests that many aspects of vocal tone can be influenced by culture.</p><p>Limitations to this study, as well as implications, are discussed below in the General Discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 2: Effect of Culture on the Perception of Emotion in the Voice</head><p>Study 1 documented differences in the style of expressing emotion through vocal tones across five distinct cultural groups. In Study 2, we examine whether these expressive differences correspond to cultural differences in emotion recognition accuracy. Dialect theory distinguishes between nonverbal dialects and what are called nonverbal accents <ref type="bibr" coords="9,165.87,704.04,122.16,7.91;9,48.00,715.04,19.37,7.91" target="#b58">(Marsh, Elfenbein, &amp; Ambady, 2003)</ref>. In the linguistic metaphor, typically an accent is noticeable yet unchallenging, whereas a difference in dialect can create difficulty in understanding another person's speech. As such, an accent may be considered a weaker instantiation of a dialect. 1 Taken together, nonverbal dialects are those differences in expressive style that impede accurate emotion recognition, whereas nonverbal accents consist of any differences that do not affect recognition accuracy.</p><p>We employ a large scale balanced design where the vocal expressions from Study 1 are judged by individuals from the same five cultural groups in a forced-choice task. Consistent with previous findings of in-group advantage, we expect participants to show higher recognition rates when judging expressions from their own cultural group versus expressions from another cultural group. If so, this would provide evidence that the cultural differences in vocal expression style found in Study 1 are indeed dialects rather than accents. Further, we investigate if relative cultural distance is associated with the accuracy of cross-cultural emotion recognition. <ref type="bibr" coords="9,314.00,714.44,3.00,4.40">1</ref> We thank an anonymous reviewer for this point.  <ref type="table" coords="9,527.81,459.70,18.22,7.03;9,48.00,468.70,4.00,7.03" target="#tab_0">Table  1</ref> for an explanation of cue abbreviations.</p><p>This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. A total of 320 participants (143 women) took part from Australia (N Ï­ 59; 29 women; age M Ï­ 21.7), India (N Ï­ 60; 30 women; age M Ï­ 20.6), Kenya (N Ï­ 60; 27 women; age M Ï­ 21.9), Singapore (N Ï­ 62; 34 women; age M Ï­ 22.8), and the United States (N Ï­ 79; 23 women; age M Ï­ 19.0). All were born and raised in their respective country. All participants were members of their regional majority ethnic group in Australia (Caucasian), India (Marathi), and Singapore (Chinese). In Kenya, the sample included members of the Kikuyu (33%), Luo (20%), Kalenjin (10%), Kamba (8%), and other (28%) African ethnic groups. In the United States, the participants were Caucasian (91%), African American (6%), and Latino/Latina (3%), with individuals excluded from Asian heritage due to the greater possibility of cultural learning with respect to Asian groups in this study. All experiments were conducted on location in each country (Brisbane, Australia; Pune, India; Nairobi, Kenya; Singapore, Singapore; and St. Louis, United States).</p><p>Procedure. Participants judged the same 550 vocal stimuli that were used in Study 1. To reduce fatigue from responding to large numbers of trials, stimuli were split arbitrarily into two sets. Each set contained five items from each of the five cultures (Australia, India, Kenya, Singapore, United States) and 11 expressions (anger, contempt, fear, happiness, interest, lust, neutral, pride, relief, sadness, and shame), which resulted in 275 trials per set. Participants were assigned at random to judge one of these two sets. The number of participants judging each set in each culture was nearly identical, which meant that each stimulus was judged by 28 -40 listeners from each culture, in a fully balanced 5 (expresser culture, within-subject) Ï« 5 (perceiver culture, between-subjects) design.</p><p>Judgments were collected using a forced-choice response method. Participants were instructed to choose one label that best represented the expression conveyed by each speech stimulus. Their alternatives were the same as the 11 intended expressions above. The response alternatives were explained by giving the participants the same scenarios as presented to the actors (see online supplemental material), to control for possible idiosyncratic or culturally specific nuances in the meaning of emotion labels. Responses were scored as correct if the response matched the intended emotion portrayal. Data were collected individually using MediaLab software <ref type="bibr" coords="10,121.38,535.03,48.31,7.91" target="#b46">(Jarvis, 2008)</ref>, which presented stimuli one at a time. The presentation order of the vocal tones was randomized, and the participants could listen to each one as many times as needed to make a judgment. The participants listened to stimuli through headphones with constant sound levels. The length of each experimental session was approximately 1 h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Emotion recognition accuracy. We used <ref type="bibr" coords="10,224.89,627.04,63.15,7.91" target="#b100">Wagner's (1993)</ref> "unbiased hit rate" (Hu) as the dependent variable in our analyses of better-than-chance accuracy and in-group advantage. This measure accounts for the possibility that systematic biases in participants' use of response categories could artificially inflate their apparent accuracy. For example, a participant could at an extreme receive an apparent recognition rate of 100% for anger by simply responding to all stimuli as angry, even though this participant had no apparent ability to distinguish anger stimuli from others. Hu is an estimate of "the joint probability both that a stimulus is correctly identified (given that it is presented) and that a response is correctly used (given that it is used)" <ref type="bibr" coords="10,445.36,99.06,79.94,7.91">(Wagner, 1993, p. 16)</ref>. It is calculated as the hit rate multiplied by one minus the rate of false alarms. Hu ranges from zero to one. A score of one indicates that all stimuli of an emotion have been correctly classified and that the respective emotion has never been misclassified as a different emotion. This correction is similar to signal detection methods except, unlike signal detection terms, it allows separate analyses for each stimulus category.</p><p>Better-than-chance accuracy. <ref type="table" coords="10,435.00,187.16,28.26,7.91" target="#tab_3">Table 4</ref> displays emotion recognition accuracy for each combination of expresser culture, perceiver culture, and intended emotion. Using Hu, we can conduct a rigorous test of the extent to which perceiver judgments were accurate at rates greater than chance. As a null hypothesis, it is possible to calculate the Hu that would be expected merely by chance guessing. This is provided by <ref type="bibr" coords="10,446.22,253.22,55.56,7.91" target="#b100">Wagner (1993)</ref> as the joint probability that a stimulus and a response of the corresponding category would occur by chance, and can be calculated for each judge by multiplying together the independent probabilities of each event occurring alone. We compared these chance scores with the observed Hu scores using paired t tests. The vast majority of Hu scores were significantly higher than the chance level, p Ï½ .05, with Bonferroni corrections to reflect the large number of statistical tests. The few exceptions are labeled as nonsignificant in <ref type="table" coords="10,306.00,352.33,26.32,7.91" target="#tab_3">Table 4</ref>. Notably, accuracy was significant for all combinations of expresser and perceiver groups and for all emotions except pride and shame. For these two emotions, performance for some combinations was not significantly above chance-level performance following the Bonferroni correction. Given that each participant judged only half of the stimuli, we also report Hu scores separately for each stimulus set in <ref type="table" coords="10,401.53,418.40,34.20,7.91" target="#tab_3">Table S4</ref> in the online supplementary materials while noting that there were no systematic differences.</p><p>Analysis of variance. Accuracy scores (Hu) were analyzed using a 5 (perceiver culture: Australia, India, Kenya, Singapore, and United States) Ï« 5 (expresser culture: Australia, India, Kenya, Singapore, and United States) Ï« 11 (emotion: anger, contempt, fear, happiness, interest, lust, neutral, pride, relief, sadness, and shame) mixed measures ANOVA, with perceiver culture betweensubjects and expresser culture and emotion within-subject. <ref type="bibr" coords="10,521.18,505.05,3.50,4.83">2</ref> In-group advantage. The key effect of interest is the interaction of Expresser Culture Ï« Perceiver Culture. Central to a test of dialect theory is the notion that this term is significant, and in the direction of greater accuracy for matched versus mismatched cultural group membership. This interaction term was significant, F(16, 1260) Ï­ 16.71, p Ï½ .001, p 2 Ï­ .18, and is illustrated in <ref type="figure" coords="10,306.00,583.54,28.90,7.91" target="#fig_1">Figure 2</ref>. This omnibus interaction term of a 5 Ï« 5 balanced design contains 16 degrees of freedom in the numerator, as an unfocused test. In particular, we examined evidence for in-group advantage, 2 In a preliminary analysis, we also included a factor for stimulus set. This preliminary analysis revealed neither a significant main effect of stimulus set, F(1, 310) Ï­ 0.58, p Ï­ .45, p 2 Ï­ .002-with overall accuracy rates essentially identical across both sets, at Hu of .22 and .21-nor a significant Stimulus Set Ï« Expresser Culture Ï« Perceiver Culture interaction, F(16, 1240) Ï­ 1.26, p Ï­ .21, p 2 Ï­ .016. For this reason, data were merged across the two sets of stimuli for the analyses. However, for the sake of completeness, we also conducted similar ANOVA analyses separately for each stimulus set. Results showed great consistency across data sets, and are reported in full in the online supplemental material. This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>calculated in terms of the mean difference between in-group and out-group Hu across conditions, which is summarized in <ref type="table" coords="11,258.02,572.04,26.65,7.91" target="#tab_3">Table 4</ref>. Overall Hu was higher in the within-cultural (.25) versus crosscultural (.20) conditions. A separate t test comparing each listener's overall in-group Hu to their out-group Hu indicated that this difference was statistically significant, t 319 Ï­ 10.61, p Ï½ .001, d Ï­ .60. 3 <ref type="figure" coords="11,57.00,638.04,30.29,7.91" target="#fig_1">Figure 2</ref> shows the average accuracy levels that perceivers from the five cultures achieved when judging stimuli from all five cultures. These values were standardized using the Fisher z transformation at the level of each individual participant, in order to control for group and individual differences in overall accuracy. The figure illustrates that relative accuracy for expressions from the perceivers' own culture was generally higher than for expressions from the other cultures. In most cases, there is a nonover-lapping 95% confidence interval between the in-group judgments-which are indicated with asterisks-and any of the four cross-cultural judgments made by the perceivers. One exception was that American and Australian perceivers did not differ with regard to their recognition of expressions from the United States (although perceivers from Australia performed better than perceivers from the United States for Australian expressions, t 136 Ï­ 2.31, p Ï­ .023, d Ï­ .40). We speculate that this one exception may be related to the relatively lower cultural difference between the 3 A similar t test conducted on the uncorrected hit rates (proportion of occasions that participants labeled stimuli with the intended category) also showed evidence for in-group advantage, with significantly higher accuracy for within-cultural (43.6%) versus cross-cultural (38.1%) judgments, t 319 Ï­ 10.60, p Ï½ .001, d Ï­ .54. Note. Perceivers from Australia (N Ï­ 59), India (N Ï­ 60), Kenya (N Ï­ 60), Singapore (N Ï­ 62), and the United States (N Ï­ 79). The in-group advantage was calculated as the difference between accuracy judging same-culture stimuli and accuracy judging other-culture stimuli, and was averaged across all perceivers. Unless otherwise indicated, Hu scores were significantly higher than chance-level performance (paired t-tests, p Ï½ .05, Bonferroni corrected). Values for in-group accuracy are marked in bold. An Ï­ anger; Co Ï­ contempt; Fe Ï­ fear; Ha Ï­ happiness; In Ï­ interest; Lu Ï­ lust; Ne Ï­ neutral; Pr Ï­ pride; Re Ï­ relief; Sa Ï­ sadness; Sh Ï­ shame.</p><p>This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>United States and Australia than the other country-pairs in this study <ref type="bibr" coords="12,70.50,319.04,60.10,7.91" target="#b43">(Hofstede, 2001)</ref>. A small but significant three-way interaction of perceiver culture, expresser culture, and emotion, F(160, 12600) Ï­ 2.25, p Ï½ .001, p 2 Ï­ .03, indicated that the Perceiver Ï« Expresser interaction also varied across emotions. To examine this interaction further, a series of pairwise t tests examined in-group advantage by comparing each listener's in-group versus out-group Hu scores separately for each emotion. These tests showed that the in-group advantage was statistically significant for all emotions except for relief, t 319 Ï­ 0. In a post hoc analysis that examined individual combinations of Emotion Ï« Expresser Group Ï« Perceiver Group, the largest ingroup advantage was observed for Indian expressions of happiness and lust, and for Singaporean expressions of happiness. To further illustrate how in-group advantage varies across conditions, the online supplemental <ref type="figure" coords="12,125.18,561.04,36.34,7.91" target="#fig_0">Figure S1</ref> shows the same material that appears in <ref type="figure" coords="12,79.97,572.04,29.86,7.91" target="#fig_1">Figure 2</ref>, separately for each culture pair for each of the 11 emotions tested.</p><p>Other effects. We also observed significant main effects of perceiver culture, expresser culture, and emotion, as well as significant Perceiver Culture Ï« Emotion and Expresser Culture Ï« Emotion interactions. These effects do not qualify the above conclusions about in-group advantage, and are presented in full in the online supplemental material.</p><p>Cultural distance analyses. The above results and prior research (e.g., <ref type="bibr" coords="12,96.63,671.04,111.33,7.91" target="#b24">Elfenbein &amp; Ambady, 2003a)</ref> suggest that cultures with greater cultural similarity may be more accurate when judging each other's emotions. To further investigate this possibility, we conducted an additional set of analyses which could only be accomplished with a relatively large design such as a balanced set of 5 Ï« 5 cultures. This involved examining the 5 Ï« 5 matrix consisting of residual accuracy after controlling for main effects of expression and perception culture. This matrix of residuals reveals the degree of relative accuracy versus inaccuracy for each country pair. It was compared vis-Ã -vis an additional 5 Ï« 5 matrix consisting of the cultural distance between each country pair based on <ref type="bibr" coords="12,306.00,143.65,66.53,7.91" target="#b43">Hofstede's (2001)</ref> survey research. 4 A test of statistical contrast was used to examine whether the correlation between these two matrices predicted emotion recognition accuracy between country pairs <ref type="bibr" coords="12,328.00,176.96,141.65,7.91" target="#b71">(Rosnow, Rosenthal, &amp; Rubin, 2000)</ref>. We combined the cultural dimensions from <ref type="bibr" coords="12,402.74,188.07,66.56,7.91" target="#b43">Hofstede's (2001)</ref> model together into overall cultural distance by calculating the euclidean distance between country pairs in a 5-dimensional space for the five cultural factors. As predicted, greater overall cultural distance predicted lower recognition accuracy, F(1, 1260) Ï­ 10.26, p Ï½ .001, r contrast Ï­ .20.</p><p>In this analysis, anger appeared to be an outlier, which might result from anger showing relatively low in-group advantage. A contrast analysis that attempts to explain the correlates of accuracy in terms of cultural distance is closely related with in-group advantage, in that in-group judgments have zero cultural distance. Along these lines, an additional analysis excluded the three emotions that had the lowest magnitude of in-group advantage, namely relief, pride, and anger. The association became stronger between greater cultural distance and lower relative emotion recognition accuracy, F(1, 1260) Ï­ 22.01, p Ï½ .001, r contrast Ï­ .29. We conducted additional analysis to examine another potential outlier in these data. Australia and the United States have very low cultural distance-less than one-quarter the distance as the next most culturally similar nation-pairs, that is, India and Kenya-and there is also relatively high mutual emotion recognition accuracy between Australia and the United States. To test whether this might influence the results, we removed the United States from analysis. 5 The association increased in effect size, F(1, 711) Ï­ 12.10, p Ï­ .001, r contrast Ï­ .25, and more so when excluding anger, pride, and relief, F(1, 711) Ï­ 22.74, p Ï½ .001, r contrast Ï­ .31. Overall, these analyses show that there can be greater nuances than simply classifying country pairs as in-group versus out-group.</p><p>Confusion patterns. Although the use of unbiased hit rates (Hu) controls for many biases in recognition accuracy, the most complete picture of perceiver judgments is provided by a confusion matrix (e.g., <ref type="bibr" coords="12,373.84,532.09,146.02,7.91" target="#b6">BÃ¤nziger, Mortillaro, &amp; Scherer, 2012;</ref><ref type="bibr" coords="12,523.56,532.09,18.74,7.91;12,306.00,543.18,185.30,7.91" target="#b27">Elfenbein, Mandal, Ambady, Harizuka, &amp; Kumar, 2002)</ref>. <ref type="table" coords="12,497.80,543.18,27.61,7.91" target="#tab_5">Table 5</ref> summarizes the results of participant ratings using such a matrix, which plots the intended emotions in the columns and the participant judgments in the rows. In each cell, the value on the left of the slash indicates the average proportion of judgments from 4 Data are provided in the appendix of <ref type="bibr" coords="12,452.58,616.70,60.02,7.03" target="#b43">Hofstede's (2001)</ref> book for Australia, India, Singapore, and the United States. The book presents data for East Africa aggregated across nations, and data for Kenya in particular are provided online (www.geert-hofstede.com). Note that these online materials regarding the cultural dimension of long-term orientation do not include a value for Kenya. So as not to lose the nation from analysis, in this one case the value was used instead from the book's appendix for East African nations. <ref type="bibr" coords="12,314.00,687.44,3.00,4.40">5</ref> The United States was removed instead of Australia due to potential asymmetry in that the United States has a highly developed industry that distributes emotional expression stimuli within entertainment as a cultural export product. This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>members of the one in-group culture, and the value on the right indicates the average proportion of judgments from members of the four out-group cultures. Inspection of <ref type="table" coords="13,211.11,322.04,29.31,7.91" target="#tab_5">Table 5</ref> reveals that confusion patterns were very similar in in-group and out-group conditions. Diagonal entries (printed in bold) indicate the proportion of occasions that participants labeled stimuli with the intended category. Underlined font indicates the most frequent confusions, for which a particular intended state was judged as another particular state with frequency higher than that expected by chance, as indicated by z tests (zs Õ5.05, ps Ï½ .05, Bonferroni corrected for multiple testing). Anger, fear, happiness, interest, lust, neutral, relief and sadness were rarely misclassified as other emotions. Contempt, pride and shame received the lowest recognition rates, and for this reason they had more frequent misclassifications. Contempt was mainly confused with neutral and pride, pride with neutral and interest, and shame with sadness and neutral. Indeed, for both pride and shame, some misclassifications were more frequent than the correct classification. For pride this occurred in both in-and out-group conditions, but for shame it occurred in out-group conditions only. For the sake of completeness, 25 separate confusion matrices appear in the online supplemental <ref type="table" coords="13,266.85,531.04,21.21,7.91;13,48.00,542.04,12.57,7.91" target="#tab_5">Table  S5</ref>-one matrix for each combination of five expresser and five perceiver cultures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Results showed that emotion recognition accuracy was greater for same-culture versus other-culture judgments, which documented the presence of in-group advantage. This in turn suggests that the cultural differences in expression patterns observed in Study 1 may be considered as dialects rather than accents (see <ref type="bibr" coords="13,48.00,649.04,67.48,7.91" target="#b58">Marsh et al., 2003)</ref>. There was in-group advantage across positive emotions, negative emotions, and even neutral expressions, with the magnitude varying across emotions.</p><p>We further explored differences in accuracy beyond the dichotomous status of in-group versus out-group, and examined to what extent cultural similarity led to relatively greater accuracy for each set of country-pairs in the five groups. This test was significant for an overall measure of cultural distance which combined the five cultural dimensions from <ref type="bibr" coords="13,505.46,311.17,40.60,7.91;13,306.00,322.29,24.89,7.91" target="#b43">Hofstede's (2001)</ref> landmark research. We do note a limitation to these analyses, in that they do include in-group judgments and would represent a more precise test if analyses could include only out-group judgments.</p><p>Limitations and implications are discussed below in the General Discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combining Expression and Perception in a Lens Model Analysis</head><p>Completing the lens model provides the primary analysis to test dialect theory, which is the primary purpose of this paper. Doing so involves comparing the results of the acoustic analyses from Study 1-which document cross-cultural differences in expressive style-with the results from Study 2-which document in-group advantage in emotion recognition. Together, these two studies provide the data necessary to test directly the dialect theory's proposition that individuals are more accurate when judging emotion expressions conveyed in their own cultural style.</p><p>To complete the lens model, we examine the acoustic cues that correspond with the speakers' intended expressions from Study 1. This is called the cue validity stage of the lens model (see <ref type="figure" coords="13,522.54,559.45,23.50,7.91;13,306.00,570.57,3.25,7.91" target="#fig_1">Figure  2</ref>), and can be described as the schemas speakers use to express vocal tones. We also examine the acoustic cues that correspond with the listener judgments from Study 2. This is called the cue utilization stage of the lens model, and can be described as the schemas listeners use to perceive vocal tones. Consistent with <ref type="bibr" coords="13,306.00,626.14,67.54,7.91" target="#b13">Brunswik's (1956)</ref> lens model, judges achieve greater accuracy the greater the match between schemas used for expression (cue validity) and schemas used for perception (cue utilization). Our analyses allow us to examine quantitatively this degree of match versus mismatch for the communication of vocal emotion. Consistent with dialect theory <ref type="bibr" coords="13,402.03,681.71,62.12,7.91" target="#b22">(Elfenbein, 2013)</ref>, our prediction is that in-group versus out-group judgments will show a greater match between cue validity and cue utilization. If so, this would provide direct evidence for dialect theory. Note. Recognition rates for which the expression portrayed is the same as the expression judged are shown in the diagonal cells (marked in bold). Observations/emotion: in-group conditions <ref type="figure" coords="13,189.59,263.00,39.30,8.00" target="#fig_0">(N Ï­ 3,180)</ref>, out-group conditions (N Ï­ 12,720). All recognition rates and underlined misclassification rates were higher than what would be expected by chance guessing (9.09%), as indicated by z tests (ps Ï½ .05, Bonferroni corrected).</p><p>This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Patterns of valid and utilized cues. First, using the data from Study 1, separately for each acoustic cue we calculated the pointbiserial correlations between the expressers' intended emotions (dichotomously dummy-coded as 1 or 0) and the acoustic cue values for each vocal stimulus. These correlations represent the cue validity and provide an index of the degree to which expressers used each cue to convey each of the 11 emotions. Second, separately for each acoustic cue we also calculated the correlations between the perceivers' average emotion judgments collected in Study 2 and the acoustic cue values for each vocal stimulus established in Study 1. Emotion judgments were coded in terms of the continuous proportion of correct responses rather than a dichotomous variable. The resulting correlations represent the cue utilization, and provide an index of the degree to which each cue was used by perceivers on a consistent basis to make inferences about each of the conveyed emotions. We used the same selection of 16 acoustic cues as in Study 1, and refer to <ref type="table" coords="14,235.84,272.32,29.23,7.91" target="#tab_0">Table 1</ref> for a description of the parameters. <ref type="table" coords="14,57.00,294.45,27.39,7.91">Table 6</ref> presents cue validity and cue utilization correlations for each acoustic cue, which are displayed as a function of emotion across all expresser and perceiver groups. To give an example of how to read <ref type="table" coords="14,96.04,327.66,27.22,7.91">Table 6</ref>, expressers tended to portray anger using a loud voice, which is exemplified by a high cue validity correlation for mean voice intensity (IntM) for anger, r Ï­ .48, p Ï½ .001. Perceivers' anger judgments were also associated with loud voice intensity, as exemplified by a high cue utilization correlation for IntM for anger, r Ï­ .55, p Ï½ .001. Focusing on the cues that were both valid and utilized, <ref type="table" coords="14,134.52,394.07,27.56,7.91">Table 6</ref> paints a similar picture as <ref type="table" coords="14,260.47,394.07,27.56,7.91" target="#tab_1">Table 2</ref> in terms of the culturally invariant acoustic profiles for each emotion, as described above in the results section of Study 1.</p><p>We also calculated cue validity and cue utilization correlations separately for each pairing of expresser and perceiver culture, see <ref type="table" coords="14,48.00,449.41,32.23,7.91">Table S6</ref> in the online supplemental material. Due to the oversized nature of this table (which contains r-values for all combinations of 16 acoustic cues Ï« 11 emotions Ï« 5 expresser cultures Ï« 5 perceiver cultures), it appears in the online supplemental material, as <ref type="table" coords="14,58.85,493.68,31.68,7.91">Table S6</ref>. Inspection of this table reveals that there were few instances where valid cues were limited in their utilization exclusively to in-group conditions (e.g., IntFracFall for Indian expressions of lust and UnvoicedSegM for Kenyan expressions of pride). Most of the valid cues were instead utilized in both in-group and out-group conditions-however, they were used to varying degrees. This indicates that cultural differences in cue utilization are not about "all or nothing" differences, where some cues are utilized in entirely different ways in different cultures. Rather, the cross-cultural differences in expression and perception style are more subtle and yet systematic. Indeed, this makes sense in that it may often be difficult to change only one acoustic cue at a time, because these properties of the voice are intercorrelated due to the physiology associated with producing sounds.</p><p>Correspondence between cue validity and cue utilization. Finally, in order to quantify the degree of match between expressers' and perceivers' uses of cues, we calculated the correlations between the cue validity and cue utilization patterns, that is, correspondence scores that represent how well perceivers make use of the true schema for emotional expression. Following <ref type="bibr" coords="14,48.00,715.05,72.44,7.91" target="#b52">Laukka et al. (2013)</ref>, these correlations were calculated across the 16 selected acoustic cues for each combination of intended emotion, expresser culture, and perceiver culture, using the values reported in online supplemental <ref type="table" coords="14,427.43,99.05,31.81,7.91">Table S6</ref>. The full set of correspondence scores is shown in <ref type="table" coords="14,415.27,110.05,32.45,7.91">Table S7</ref> in the online supplemental material, and a high correlation suggests a good match between cue validity and cue utilization patterns.</p><p>For each emotion and pairing of expresser and perceiver cultures, we compared the in-group correspondence score with the average of the correspondence scores across the four out-group conditions (also shown in online supplemental <ref type="table" coords="14,482.54,176.04,31.29,7.91">Table S7</ref>). A dependent measures t test indicated that the correlation between cue validity and cue utilization was significantly higher in in-group conditions (mean Fisher Z Ï­ 1.54) than in out-group conditions (mean Fisher Z Ï­ 1.41, t 54 Ï­ 3.97, p Ï½ .001, d Ï­ .22). This provides evidence for the central proposition of dialect theory, namely that there is a better match between expression and perception styles when expressers and perceivers share the same cultural background. 6 Inspection of online supplemental <ref type="table" coords="14,513.36,264.04,32.69,7.91">Table S7</ref> revealed that the overall differences between in-group and outgroup correspondence scores were largest for contempt, interest and pride. Note that these results vary slightly from the previous analyses, which examined the effects of individual acoustic cues versus the gestalt across all acoustic cues. The two methods thus capture different aspects for interpreting the influence of culture on vocal expression and perception, and results are consistent across them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Results from the lens model analysis provided an in-depth look at which acoustic cues were correlated significantly with both the expressers' intended emotion (cue validity) as well as with the perceivers' judgments (cue utilization). It is important to note that findings support dialect theory's key proposition that systematic cultural differences in expression style are responsible for systematic cultural differences in recognition accuracy. That is, for ingroup judgments, there was a higher correlation between what <ref type="bibr" coords="14,306.00,484.79,70.28,7.91" target="#b13">Brunswik's (1956)</ref> theory referred to as cue validity and cue utilization. This indicates a tighter mapping for in-group judgments between the schemas used to express and the schemas used to perceive emotional expressions, and this tighter mapping improves recognition accuracy.</p><p>Limitations and implications are discussed below in the General Discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Taking a large-scale approach to examining the expression and recognition of vocal emotion, the current investigation expanded beyond longstanding tradition on cross-cultural research that has tended to focus primarily on still photographs of the face. Emotional expressions were collected from 100 professional actors from five English-speaking nations that span 4 continents. These 6 To ensure that this effect was not limited to the particular 16 acoustic cues selected to limit the number of analyses, we also calculated the correspondence scores using the entire set of 65 acoustic cues. The ingroup mean (Z Ï­ 1.53) was again significantly higher than the out-group mean (Z Ï­ 1.40, t 54 Ï­ 4.53, p Ï½ .001, d Ï­ .23). This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.  <ref type="figure" coords="15,325.35,646.00,28.89,8.00">N Ï­ 548)</ref>. A significant cue-validity correlation (i.e., the correlation between a cue and the expressers' intended emotion) suggests that the cue is used in a consistent fashion by the expressers to convey a certain emotion. A significant cue-utilization correlation (i.e., the correlation between a cue and the perceivers' mean recognition accuracy) suggests that the cue is used in a consistent fashion to make inferences about the conveyed emotion. Bold typeface indicates which cues were both valid and utilized for each emotion. See <ref type="table" coords="15,62.21,682.70,24.88,7.03" target="#tab_0">Table 1</ref> for an explanation of cue abbreviations. â«Ø¡â¬ p Ï½ .05. â«Ø¡Ø¡â¬ p Ï½ .01. â«Ø¡Ø¡Ø¡â¬ p Ï½ .001. This document is copyrighted by the American Psychological Association or one of its allied publishers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6 A Lens-Model Analysis of the Correlations (Pearson r) Between Acoustic Cues and (a) the Expressers' Intended Expression (Cue Validity) and (b) the Perceivers' Emotion Judgments (Cue Utilization), Across Cultural Conditions</head><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>actors portrayed a large number of distinct emotional categories, including more positive states than typically sampled in crosscultural research. In addition to neutral tones, the list included anger, contempt, fear, happiness, interest, lust, pride, relief, sadness, and shame. In conducting a project of this unusual size, the study increased by an order of magnitude the body of available data to fill in the basic science of understanding the human voice in expressing emotion. The five cultures served as replications of each other, with portrayals that were collected to be as similar as possible in every manner other than the actors' cultural background.</p><p>The resulting data set enabled us to conduct the first direct test of dialect theory <ref type="bibr" coords="16,114.74,209.04,63.69,7.91" target="#b22">(Elfenbein, 2013)</ref>. In the first step (Study 1), stimuli were analyzed in terms of their fundamental acoustic properties. As predicted, both cultural similarities and systematic differences emerged. In the next step (Study 2), human listeners made forced-choice judgments of these stimuli. There was substantial accuracy across cultures, which indicated a degree of basic universality. There were also cultural differences in the form of an in-group advantage. In the last step, <ref type="bibr" coords="16,178.85,286.04,67.72,7.91" target="#b13">Brunswik's (1956)</ref> lens model was used for the first time to study human vocal emotion across cultures, and provided the most precise test to date of dialect theory by examining emotional expression style down the microlevel features of acoustic cues. Results demonstrated that ingroup versus out-group judgments showed a greater match versus mismatch between the pattern of emitting acoustic cues and the pattern of judging them. Consistent with dialect theory, this tighter mapping in schemas was responsible for the presence of in-group advantage. Taken together, findings are consistent with interactionist perspectives that attempt to incorporate both universals and cultural differences in emotional expression. This topic has been controversial over the decades (e.g., <ref type="bibr" coords="16,181.67,418.04,50.72,7.91" target="#b74">Russell, 1994)</ref>, and hard data are worthwhile alongside theoretical arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Considering Origins: Why Paralinguistic Dialects?</head><p>This paper provides evidence to document paralinguistic dialects, but does not provide evidence for how or why they develop over time. Why should cultures have dialects in their nonverbal communication of emotion, and why should there be dialects for acoustical properties in particular? We argue that attempts to answer this question benefit from taking seriously the linguistic metaphor of dialects, which allows theories to be grounded in related theory from the field of linguistics. Linguists argue that language is constantly evolving, and that it tends to diverge across groups of people who are separated by geographic or social boundaries <ref type="bibr" coords="16,69.40,583.04,200.37,7.91" target="#b61">(O'Grady, Archibald, Aronoff, &amp; Rees-Miller, 2001)</ref>. As such, greater social stratification tends to increase the degree of differentiation between speakers of the same language, even if these dialects are mutually intelligible. In the case of verbal language, ultimately a large enough degree of stratification renders languages unable to be mutually understood.</p><p>In the case of nonverbal dialects, we argue that the at least partial biological nature of emotional expression prevents drift of nonverbal styles past the point of mutual unintelligibility. <ref type="bibr" coords="16,257.05,671.04,31.00,7.91;16,48.00,682.04,20.23,7.91" target="#b15">BÃ¼hler's (1934</ref><ref type="bibr" coords="16,72.27,682.04,16.18,7.91" target="#b15">BÃ¼hler's ( /1990</ref>) Organon model argues that there are three distinct functions for emotional expression <ref type="bibr" coords="16,178.12,693.04,55.01,7.91" target="#b81">(Scherer, 1988)</ref>. First, expressions can be symptoms of internal states. As such, our basic biology can determine how emotion-related physiological changes can influence the voice production apparatus <ref type="bibr" coords="16,479.41,77.04,56.64,7.91" target="#b80">(Scherer, 1986</ref>)such as throat tightening versus loosening-and this should be similar across cultures. Second, expressions are used as signals to produce a reaction in others (e.g., <ref type="bibr" coords="16,445.60,110.04,58.82,7.91" target="#b36">Fridlund, 1994;</ref><ref type="bibr" coords="16,509.49,110.04,36.56,7.91;16,306.00,121.04,54.18,7.91" target="#b63">Owren &amp; Rendall, 2001)</ref>. It is likely that deliberate expressions tend to imitate changes in vocal quality that are found in spontaneous expressions, because these cues would be better recognized for their intended meaning <ref type="bibr" coords="16,394.84,154.04,101.94,7.91" target="#b86">(Scherer &amp; BÃ¤nziger, 2010)</ref>. This would serve as another constraint on the magnitude of cultural differences in nonverbal expression-even if it is a looser constraint than the constraint on cues resulting from strictly biological processes. Third, there is a "symbolic" function, in that expressions represent objects or events, similar to linguistic expressions (e.g., <ref type="bibr" coords="16,509.59,209.04,36.44,7.91;16,306.00,220.04,60.05,7.91" target="#b53">Laukka &amp; Elfenbein, 2012;</ref><ref type="bibr" coords="16,368.35,220.04,173.82,7.91" target="#b75">Russell, Bachorowski, &amp; Fernandez-Dols, 2003)</ref>. Inasmuch as the symbolic function maps most directly onto verbal language-which drifts substantially across cultures-one might expect greater drift across cultures in the evolution of cues that draw from the symbolic function. Taking these three functions together, with their varying potential for cultural difference, nonverbal dialects should be relatively subtle, and mutually intelligible. This is consistent with the base of empirical findings.</p><p>The concept of social stratification leads to two distinct mechanisms for the development of dialects, which can occur separately or in tandem. First, some changes in language occur merely through random drift. Particularly in the absence of formal records for vocal characteristics-unlike written text-passing down language from one generation to the next involves evolution through no deliberate effort. Cultural groups that are more physically distant have less opportunity to maintain consistency in their styles that evolve through random drift. As such, dialects may emerge inadvertently, when drifts become shared among some speakers but not others <ref type="bibr" coords="16,358.75,418.03,79.59,7.91" target="#b61">(O'Grady et al., 2001)</ref>. In the second psychological mechanism, some changes occur through motivated processes of asserting a distinct social identity. For example, jargon and slang can create a marker or even deliberate barrier that defines group membership. Both of these explanations can be consistent with the above results. Notably, we found relatively greater emotion recognition accuracy among culture-pairs that were similar along <ref type="bibr" coords="16,306.00,495.03,65.54,7.91" target="#b43">Hofstede's (2001)</ref> dimensions. Cultural similarity between groups may provide less opportunity for random drift. This could help to maintain expressive style similarity and mutual understanding even as these styles potentially change over time. A potential mechanism for this is that cultural similarity might open up greater channels for cross-cultural contact, and verbal communication could help to facilitate convergence in nonverbal expression style.</p><p>It is worth noting that the exact form of a dialect does not necessarily need a functional goal. For example, there may be no reason why Bostonians drop the retroflex r at the end of a word instead of the dental t. This may or may not be the case for nonverbal accents. Functional goals are possible, and some explanations for in-group advantage do not necessarily follow linguistic principles. For example, an appraisal view of nonverbal dialects has the potential to preserve the notion that people across cultures have a universal mapping from their internal feeling states to their outward displays <ref type="bibr" coords="16,371.71,671.03,89.69,7.91" target="#b42">(Hess &amp; Thibault, 2009)</ref>. The idea here is that emotions exist within broader families-such as irritation, rage, and anger-and cultures may differ in their modal experience within these emotion families <ref type="bibr" coords="16,426.76,704.03,119.30,7.91;16,306.00,715.03,19.37,7.91" target="#b35">(Fontaine, Scherer, &amp; Soriano, 2013)</ref>. If there is a one-to-one mapping from emotional experi-This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>ences to the appearance of expressions, then this difference in modal experience could lead to dialects that are better recognized by in-group members. Empirical support would be necessary to support this account, but it is worth mentioning even so as a potential alternative. However, we note that the potential for this explanation in the current study is reduced by design, because we used a protocol in which participants received explicit instructions based on appraisal theory that limited room for idiosyncratic or culturally specific interpretations of the emotion categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations and Further Work</head><p>A number of important limitations qualify the findings reported above.</p><p>One concern is a potential limit to generality in that all five cultures represented in the study are English-speaking. This was intended to control for differences in the words that were used in standard-content sentences spoken by the actors, so that linguistic properties could be kept constant while paralinguistic properties varied. This also keeps relatively consistent across cultures the meaning of the particular emotional categories. As mentioned directly above, there can be subtle differences in the modal experience within broader emotion families <ref type="bibr" coords="17,194.97,319.04,85.33,7.91" target="#b42">(Hess &amp; Thibault, 2009</ref>), but we attempted to reduce this potential influence by providing clear guidance about how to interpret emotion labels. Further, in the case of expression, we controlled for group differences in emotion intensity by instructing actors to portray emotions with well-defined levels of intensity. The use of English speakers had the additional benefit of allowing us to sample distinct cultures from four different continents, given the pervasiveness of English around the globe. Nonetheless, it would be valuable to conduct research on the cross-cultural understanding of vocal emotion in multiple languages.</p><p>Another limitation is that the judgment data in Study 2 were collected using forced-choice responses, rather than the more naturalistic free labeling of stimuli <ref type="bibr" coords="17,175.76,462.04,53.57,7.91" target="#b73">(Russell, 1993)</ref>. This was done because the lens model analysis requires the same response categories for emotional expression and perception. Using forcedchoice also provided greater methodological convenience, given that there were 275 trials tested for each participant. It is possible that a design using free labeling would provide different insights, in that linguistic categories can be woven into interpersonal judgments (e.g., <ref type="bibr" coords="17,92.87,539.04,191.29,7.91" target="#b37">Gendron, Roberson, van der Vyver, &amp; Barrett, 2014)</ref>.</p><p>Future studies using open-ended responses would therefore be valuable.</p><p>A limitation that will be important to address in future work is the use of posed expressions instead of spontaneous speech. This is consistent with the vast majority of research that has been conducted about recognizing emotional expression across cultures. We followed this dominant convention without endorsing it as complete. The use of deliberate expression made it possible to elicit each of 11 distinct emotional states each from a large number of actors. However, one potential limitation with acted portrayals is that actors may sometimes develop norms to exaggerate their expressions in order to make them more recognizable, or otherwise produce speech samples that differ from what would be produced spontaneously. As such, deliberate portrayals could come at the tradeoff of authenticity. To address this, the protocol instructed actors not to use overtly stereotypical expressions, and to use moderate levels of intensity. Further, the protocol involved the <ref type="bibr" coords="17,306.00,88.12,69.86,7.91" target="#b91">Stanislavski (1936)</ref> technique of method acting, in which speakers attempted to reactivate past authentic emotional experience. The Stanislavski technique has the potential to increase authenticity and help mitigate the challenge of producing vocal cues by voluntary intention. The use of a single professional technique across all 100 actors also attempted to reduce potential cultural differences in the training of actors, as well as idiosyncratic differences in acting styles. Although we believe that professional actors may provide the best case scenario to enact voluntary nonverbal cues (see <ref type="bibr" coords="17,324.50,187.94,100.62,7.91" target="#b86">Scherer &amp; BÃ¤nziger, 2010)</ref>, it could also be a worthwhile extension to examine portrayals from speakers who are not professional actors.</p><p>In discussing this concern, we note empirical evidence that speak against the possibility that it threatens the validity of the present work. Posed and spontaneous expressions tend to produce highly similar patterns of acoustic cues, and the differences reported tend to be relatively small. In a recent investigation, Scherer (2013) compared speech samples obtained from mood induction and acting procedures, and reported that speech samples from both techniques tended to be comparable at the acoustic level. In addition, evidence from human listeners suggests the similarity of acted and spontaneous portrayals. Participants tend to perform poorly when asked to distinguish whether stimuli are posed versus portrayed <ref type="bibr" coords="17,343.58,343.07,76.64,7.91" target="#b47">(JÃ¼rgens et al., 2013)</ref>. Reviewing these and other findings, Scherer (2013) challenged the notion that using acted samples in empirical research is a concern. Taken together, we believe that the limitation of using posed expressions is an important one, but that it does not invalidate the research presented here. Nevertheless, we would welcome efforts that aim to replicate the current results using instead spontaneous expressions. It will be a worthwhile challenge to develop an experimental manipulation for each of these 11 categories that would involve the production of spontaneous same-content verbal utterances. Increased efforts have recently been directed at developing databases of spontaneous affective speech in several research communities (e.g., <ref type="bibr" coords="17,513.82,464.95,32.25,7.91;17,306.00,476.03,113.99,7.91" target="#b88">Schuller, Batliner, Steidl, &amp; Seppi, 2011)</ref>. We speculate that, when suitable databases of spontaneous expressions become available, it may also be possible to conduct comparisons of the acoustic properties of our stimuli and spontaneous vocal tones using data from speech collections not originally designed for cross-cultural comparisons. <ref type="bibr" coords="17,542.56,518.92,3.50,4.83">7</ref> A final limitation we note is the potential for linguistic accents to be confounded with paralinguistic accents. In past work, ingroup advantage has been documented even when linguistic dialects were not a plausible explanation. In particular, some studies used expressions standardized to be identical across cultural groups, and in others the apparent cultural origin of stimuli was experimentally manipulated (for reviews, see <ref type="bibr" coords="17,351.14,608.99,48.19,7.91" target="#b77">Sauter, 2013;</ref><ref type="bibr" coords="17,401.79,608.99,127.91,7.91" target="#b94">Thibault, Bourgeois, &amp; Hess, 2006)</ref>. As such, the sound of a clearly foreign accent could lead to lesser motivation and accuracy, but verbal accents cannot explain away the lens model analysis presented above. This is because the lens analysis was conducted after standardizing all acoustic cues within-speaker. Because the stimuli consisted of standard-content sentences, the influence on speech of a verbal accent should be the same across each emotion category. Analyses examined the rela- <ref type="bibr" coords="17,314.00,714.44,3.00,4.40">7</ref> We thank an anonymous reviewer for this suggestion. This document is copyrighted by the American Psychological Association or one of its allied publishers.</p><p>This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.</p><p>tive change in the use of cues from one emotion to the next. As such, any systematic pattern in the use of cues across particular emotions is part of the phenomenon itself-that is, showing that there can be cultural differences in paralinguistic style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical Implications: Practice Makes Perfect</head><p>We argue that the findings above present a source of optimism. To the extent that cultural differences in emotional expression style can create barriers for individuals who interact across cultural group boundaries, these barriers can be overcome. Dialect theory focuses on the role of information in explaining cultural differences in emotion recognition accuracy. If someone lacks the necessary familiarity with another group's dialects, this is remediable versus destiny. By contrast, it would be harder to overcome a deficit resulting from biological preprogramming, or even from prejudice against members of foreign groups. Past research based on facial expressions has shown that individuals can learn to bridge the gap through study abroad and even experimental feedback <ref type="bibr" coords="18,67.86,280.29,63.61,7.91" target="#b21">(Elfenbein, 2006;</ref><ref type="bibr" coords="18,134.35,280.29,107.64,7.91" target="#b25">Elfenbein &amp; Ambady, 2003b)</ref>. In a recent study examining vocal tones, <ref type="bibr" coords="18,161.15,291.29,51.22,7.91" target="#b1">Altrov (2013)</ref> found likewise that Russians who lived in Estonia were more accurate with Estonian expressions than Russians who lived in Russia. Integrating the available evidence emphasizes the value of expanding our horizons. Cross-group contact and even deliberate training can help maximize our ability to communicate with individuals from all around the world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,159.28,284.63,275.47,7.03"><head>Figure 1 .</head><label>1</label><figDesc>A lens model of cross-cultural communication of emotion via the voice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="12,48.00,239.53,240.03,7.03;12,48.00,249.53,240.05,7.03;12,48.00,259.53,240.02,7.03;12,48.00,268.83,240.04,8.00;12,48.00,278.83,161.50,8.00"><head>Figure 2 .</head><label>2</label><figDesc>Standardized overall unbiased hit rates (Hu) as a function of expresser and perceiver culture. Error bars represent 95% confidence intervals and asterisks indicate in-group conditions (i.e., match between expresser and perceiver culture). AUS Ï­ Australia; IND Ï­ India; KEN Ï­ Kenya; SIN Ï­ Singapore; USA Ï­ United States.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,48.00,473.55,498.01,225.45"><head>Table 1</head><label>1</label><figDesc>Summary of Acoustic Cues Measured in Study 1</figDesc><table coords="7,48.00,504.20,498.01,194.80">Feature type 
Description 
Factor loading 

Frequency-related cues 
F0M 
Mean fundamental frequency (F0) on a semitone frequency scale 
Factor 2: .90 
F0PercRange 
Range of the 20th to the 80th percentile of F0 
Factor 5: .59 
F0SlopeRise 
Mean slope of signal parts with rising F0 
Factor 9: .95 
F0SlopeFall 
Mean slope of signal parts with falling F0 
Factor 7: .92 
F0FracRise 
Percentage of frames with rising F0 
Factor 11: .72 
F1FreqM 
Mean of first formant (F1) centre frequency 
Factor 5: .83 
F1FreqSD 
Standard deviation of first formant (F1) centre frequency 
Factor 12: .80 
Energy-related cues 
IntM 
Mean voice intensity estimated from an auditory spectrum 
Factor 3: .81 
HNR 
Mean harmonics-to-noise ratio, i.e., the relation of energy in harmonic vs. noise-like components 
Factor 2: .91 
IntFracRise 
Percentage of frames with rising voice intensity 
Factor 10: .82 
IntFracFall 
Percentage of frames with falling voice intensity 
Factor 8: Ïª.74 
Spectral-balance cues 
F1Amplitude 
Relative energy of the spectral envelope in the first formant region 
Factor 1: .97 
Hammarberg 
Hammarberg index, i.e., the ratio of the strongest energy peaks in the 0-2 kHz vs. 2-5 kHz regions 
Factor 4: .76 
H1-A3 
Ratio of energy of the first F0 harmonic vs. the highest harmonic in the third formant range 
Factor 4: .63 
Temporal cues 
VoicedSegM 
Mean length of continuously voiced regions 
Factor 6: .69 
UnvoicedSegM 
Mean length of unvoiced regions (approximating pauses) 
Factor 1: Ïª.79 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,48.00,77.04,497.01,337.70"><head>Table 2</head><label>2</label><figDesc>Analysis of Variance of Acoustic Cues Contained in Vocal Emotion Stimuli Across Five Cultures and 10 Affective States(Study 1)</figDesc><table coords="8,48.00,107.00,497.01,307.74">Emotion effect 

Emotion Ï« Culture 
interaction 
Trends for the emotion effect 

Acoustic cue 
F(10, 495) 
p 
p 

2 

F(40, 495) 
p 
p 

2 

High (1) 
Medium (Ï­) 
Low (2) 

Frequency-related cues 
F0M 
38.79 
.001 .44 
1.90 
.001 .13 
Fe, Ha, In, 
An 

Sa 
Pr, Re, Co, Sh, Ne, Lu 

F0PercRange 
5.60 
.001 .10 
1.77 
.003 .12 
In, Lu, Co 
Pr, Ha, An, Sa, Re, Sh 
Fe, Ne 
F0SlopeRise 
3.81 
.001 .07 
1.65 
.008 .12 
Fe, Sa 
Ne, Sh, Pr, Lu, Co, 
Re, An 

Ha, In 

F0SlopeFall 
1.90 
.043 .04 
1.05 
.394 .08 
Lu 
Sa, In, Sh, Co, Pr, An, 
Fe, Ha, Ne 

Re 

F0FracRise a 
10.75 
.001 .18 
1.90 
.001 .13 
In, Ha, Pr 
An, Fe, Lu, Sa 
Co, Ne, Re, Sh 
F1FreqM 
5.74 
.001 .10 
1.74 
.004 .12 
Fe, An 
Ha, In, Lu, Re, Sa, 
Co, Sh, Pr 

Ne 

F1FreqSD 
3.79 
.001 .07 
.93 
.599 .07 
An, Ha, Sa 
Fe, Pr, Co, Re, In, Lu, 
Sh 

Ne 

Energy-related cues 
IntM 
60.60 
.001 .55 
3.13 
.001 .20 
An, Ha, Fe 
In, Co, Pr, Re 
Sa, Ne, Sh, Lu 
HNR 
16.44 
.001 .25 
1.79 
.003 .13 
In, Fe, Sa 
Ha, Sh, Re 
Pr, An, Ne, Co, Lu 
IntFracRise b 
5.29 
.001 .10 
1.10 
.309 .08 
An 
Fe, Sa, Co, In, Pr, Ha, 
Ne, Sh 

Re, Lu 

IntFracFall b 
9.37 
.001 .16 
2.10 
.001 .15 
An, Ha, 
Fe, In 

Sa, Ne, Pr, Co 
Sh, Re, Lu 

Spectral-balance cues 
F1Amplitude 
19.54 
.001 .28 
2.06 
.001 .14 
Ha, Ne, 
An, In 

Pr, Co, Fe, Sa 
Sh, Re, Lu 

Hammarberg 
25.09 
.001 .34 
3.26 
.001 .21 
Ne, Sa, Sh, 
In 

Lu, Pr 
Co, Fe, Ha, Re, An 

H1-A3 
14.28 
.001 .22 
2.09 
.001 .14 
Ne, Sh, Sa 
In, Co, Lu, Pr, Re 
Ha, Fe, An 
Temporal cues 
VoicedSegM 
3.66 
.001 .07 
2.27 
.001 .15 
Ha 
Co, Pr, An, Fe, In, Sa, 
Lu, Ne, Re 

Sh 

UnvoicedSegM 
17.70 
.001 .26 
1.61 
.012 .12 
Lu, Re, Sh 
Co, Pr, Sa, An, Fe 
Ha, In, Ne 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,48.00,77.04,498.06,389.96"><head>Table 3</head><label>3</label><figDesc>Analysis of Variance of Acoustic Cues Used in Vocal Emotion Stimuli Across Five Cultures (Study 1)Note. Multiple comparisons for assessing main trends for culture were conducted using Tukey honest significant difference tests (ps Ï½ .05). See</figDesc><table coords="9,262.23,107.70,44.87,7.03">Culture effect 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,48.00,77.04,498.00,405.69"><head>Table 4</head><label>4</label><figDesc>Emotion Recognition Accuracy (Hu) byEmotion, Expresser Culture, and Perceiver Culture (Study 2)    </figDesc><table coords="11,315.84,107.70,56.88,7.03">Intended emotion 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,48.00,417.25,240.07,86.94"><head></head><label></label><figDesc>92, p Ï­ .36, d Ï­ .07. The values for the other emotions were, in order from smallest to largest effect size: anger, t 319 Ï­ 2.20, p Ï­ .029, d Ï­ .17; pride, t 319 Ï­ 2.21, p Ï­ .028, d Ï­ .17; sadness, t 319 Ï­ 3.69, p Ï½ .001, d Ï­ .27; contempt, t 319 Ï­ 4.69, p Ï½ .001; d Ï­ .34; shame, t 319 Ï­ 5.18, p Ï½ .001, d Ï­ .39; neutral, t 319 Ï­ 6.39, p Ï½ .001, d Ï­ .40; fear, t 319 Ï­ 5.89, p Ï½ .001, d Ï­ .41; interest, t 319 Ï­ 5.61, p Ï½ .001, d Ï­ .44; happiness, t 319 Ï­ 6.80, p Ï½ .001, d Ï­ .47; and lust, t 319 Ï­ 7.45, p Ï½ .001, d Ï­ .47.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="13,48.00,77.05,498.01,169.69"><head>Table 5</head><label>5</label><figDesc>Confusion Matrix Illustrating the Proportion of Participant Judgments Made Across Intended Emotions as a Function of In-Group vs. Out-Group Stimuli (Study 2)</figDesc><table coords="13,65.99,118.70,31.11,7.03">Judgment 
</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="18,48.00,395.70,240.00,7.03;18,56.00,405.70,232.01,7.03;18,56.00,415.70,232.01,7.03;18,56.00,425.70,80.22,7.03" xml:id="b0">
	<analytic>
		<title level="a" type="main">Perception of the emotional content of speech: A comparison of two Canadian groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Albas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Mccluskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Albas</surname></persName>
		</author>
		<idno type="DOI">10.1177/002202217674009</idno>
		<ptr target="http://dx.doi.org/10.1177/002202217674009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="481" to="490" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,435.70,240.01,7.03;18,56.00,445.70,216.51,7.03" xml:id="b1">
	<analytic>
		<title level="a" type="main">Aspects of cultural communication in recognizing emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Altrov</surname></persName>
		</author>
		<idno type="DOI">10.3176/tr.2013.2.04</idno>
		<ptr target="http://dx.doi.org/10.3176/tr.2013.2.04" />
	</analytic>
	<monogr>
		<title level="j">Trames</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,455.70,240.00,7.03;18,56.00,465.70,231.99,7.03;18,56.00,475.70,231.96,7.03;18,56.00,485.70,16.00,7.03" xml:id="b2">
	<analytic>
		<title level="a" type="main">The influence of language and culture on the understanding of vocal emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Altrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pajupuu</surname></persName>
		</author>
		<idno type="DOI">10.12697/jeful.2015.6.3.01</idno>
		<ptr target="http://dx.doi.org/10.12697/jeful.2015.6.3.01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Estonian and Finno-Ugric Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="11" to="48" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,495.70,240.03,7.03;18,56.00,505.70,232.01,7.03;18,56.00,515.70,232.00,7.03" xml:id="b3">
	<analytic>
		<title level="a" type="main">The voice of emotions in Chinese and Italian young adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Anolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mantovani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Toni</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022022108321178</idno>
		<ptr target="http://dx.doi.org/10.1177/0022022108321178" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="565" to="598" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,525.70,240.02,7.03;18,56.00,535.70,232.01,7.03;18,56.00,545.70,147.12,7.03" xml:id="b4">
	<analytic>
		<title level="a" type="main">Acoustic profiles in vocal emotion expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Banse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.70.3.614</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.70.3.614" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="614" to="636" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,555.70,240.01,7.03;18,56.00,565.70,232.00,7.03;18,56.00,575.70,90.44,7.03" xml:id="b5">
	<analytic>
		<title level="a" type="main">Path models of vocal emotion communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>BÃ¤nziger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hosoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0136675</idno>
		<ptr target="http://dx.doi.org/10.1371/journal.pone.0136675" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,585.70,240.02,7.03;18,56.00,595.70,232.02,7.03;18,56.00,605.70,232.00,7.03;18,56.00,615.70,31.55,7.03" xml:id="b6">
	<analytic>
		<title level="a" type="main">Introducing the Geneva Multimodal expression corpus for experimental research on emotion perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>BÃ¤nziger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mortillaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0025827</idno>
		<ptr target="http://dx.doi.org/10.1037/a0025827" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1161" to="1179" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,625.70,240.02,7.03;18,56.00,635.70,232.00,7.03;18,56.00,645.70,191.78,7.03" xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-cultural emotion recognition among Canadian ethnic groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>BeauprÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hess</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022022104273656</idno>
		<ptr target="http://dx.doi.org/10.1177/0022022104273656" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="355" to="370" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,655.70,240.03,7.03;18,56.00,665.70,232.00,7.03;18,56.00,675.70,173.77,7.03" xml:id="b8">
	<analytic>
		<title level="a" type="main">Identification of vocal communication of emotions across cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Beier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Zautra</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0033170</idno>
		<ptr target="http://dx.doi.org/10.1037/h0033170" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consulting and Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,48.00,685.70,240.04,7.03;18,56.00,695.70,232.01,7.03;18,56.00,705.70,232.00,7.03;18,56.00,715.70,147.12,7.03" xml:id="b9">
	<analytic>
		<title level="a" type="main">Dyad rapport and the accuracy of its judgment across situations: A lens model analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Bernieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Gillis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Grahe</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.71.1.110</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.71.1.110" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="110" to="129" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,77.20,240.02,7.03;18,314.00,87.68,232.03,7.03;18,314.00,98.16,232.02,7.03;18,314.00,108.64,232.01,7.03;18,314.00,119.11,88.22,7.03" xml:id="b10">
	<analytic>
		<title level="a" type="main">Matsumoto and Ekman&apos;s Japanese and Caucasian Facial Expressions of Emotion (JACFEE): Reliability data and cross-national differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hearn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Heider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ton</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1024902500935</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1024902500935" />
	</analytic>
	<monogr>
		<title level="j">Journal of Nonverbal Behavior</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3" to="21" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,129.59,240.01,7.03;18,314.00,140.07,191.28,7.03" xml:id="b11">
	<monogr>
		<title level="m" type="main">Praat: Doing phonetics by computer [Computer software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boersma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weenink</surname></persName>
		</author>
		<ptr target="http://www.praat.org" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,150.55,240.02,7.03;18,314.00,161.01,203.98,7.03" xml:id="b12">
	<monogr>
		<title level="m" type="main">SynchronEmotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Heilmann</surname></persName>
		</author>
		<idno type="DOI">10.3726/978-3-653-01595-9</idno>
		<ptr target="http://dx.doi.org/10.3726/978-3-653-01595-9" />
		<imprint>
			<date type="published" when="2012" />
			<publisher>Peter Lang</publisher>
			<pubPlace>Bern, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,171.48,240.01,7.03;18,314.00,181.94,217.49,7.03" xml:id="b13">
	<monogr>
		<title level="m" type="main">Perception and the representative design of psychological experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brunswik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1956" />
			<publisher>University of California Press</publisher>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,192.41,240.03,7.03;18,314.00,202.88,231.99,7.03;18,314.00,213.34,129.11,7.03" xml:id="b14">
	<analytic>
		<title level="a" type="main">Vocal emotion recognition across disparate cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Barrett</surname></persName>
		</author>
		<idno type="DOI">10.1163/156770908X289242</idno>
		<ptr target="http://dx.doi.org/10.1163/156770908X289242" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Culture</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="135" to="148" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,223.81,240.01,7.03;18,314.00,234.27,232.03,7.03;18,314.00,244.74,232.02,7.03;18,314.00,255.20,18.66,7.03" xml:id="b15">
	<analytic>
		<title level="a" type="main">Theory of language. The representational function of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">; D F</forename><surname>BÃ¼hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodwin</surname></persName>
		</author>
		<idno type="DOI">10.1075/fos.25</idno>
		<ptr target="http://dx.doi.org/10.1075/fos.25" />
	</analytic>
	<monogr>
		<title level="j">Trans.)</title>
		<imprint>
			<date type="published" when="1934" />
			<publisher>John Benjamins</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,265.67,240.03,7.03;18,314.00,276.13,232.02,7.03;18,314.00,286.60,232.01,7.03;18,314.00,297.07,62.00,7.03" xml:id="b16">
	<analytic>
		<title level="a" type="main">The voice conveys emotion in ten globalized cultures and one remote village in Bhutan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Cordaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tshering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wangchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Flynn</surname></persName>
		</author>
		<idno type="DOI">10.1037/emo0000100</idno>
		<ptr target="http://dx.doi.org/10.1037/emo0000100" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,307.53,240.01,7.03;18,314.00,318.00,232.02,7.03;18,314.00,328.46,83.08,7.03" xml:id="b17">
	<monogr>
		<title level="m" type="main">The communication of emotional meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Davitz</surname></persName>
		</author>
		<editor>J. R. Davitz</editor>
		<imprint>
			<date type="published" when="1964" />
			<publisher>McGraw-Hill</publisher>
			<biblScope unit="page" from="143" to="156" />
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Minor studies and some hypotheses</note>
</biblStruct>

<biblStruct coords="18,306.00,338.93,240.01,7.03;18,314.00,349.40,232.02,7.03;18,314.00,359.86,221.77,7.03" xml:id="b18">
	<monogr>
		<title level="m" type="main">Exploring the sensitivity of Horn&apos;s parallel analysis to the distributional form of random data. Multivariate Behavioral Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dinno</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273170902938969</idno>
		<ptr target="http://dx.doi.org/10.1080/00273170902938969" />
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="362" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,370.33,240.00,7.03;18,314.00,380.79,209.85,7.03" xml:id="b19">
	<analytic>
		<title level="a" type="main">An argument for basic emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<idno type="DOI">10.1080/02699939208411068</idno>
		<ptr target="http://dx.doi.org/10.1080/02699939208411068" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="169" to="200" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,391.26,240.02,7.03;18,314.00,401.73,114.26,7.03" xml:id="b20">
	<analytic>
		<title level="a" type="main">Nonverbal leakage and clues to deception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">V</forename><surname>Friesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychiatry</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="88" to="106" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,412.19,240.02,7.03;18,314.00,422.66,232.02,7.03;18,314.00,433.12,216.87,7.03" xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning in emotion judgments: Training and the cross-cultural understanding of facial expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10919-005-0002-y</idno>
		<ptr target="http://dx.doi.org/10.1007/s10919-005-0002-y" />
	</analytic>
	<monogr>
		<title level="j">Journal of Nonverbal Behavior</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="21" to="36" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,443.59,240.04,7.03;18,314.00,454.05,232.01,7.03;18,314.00,464.52,64.00,7.03" xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonverbal dialects and accents in facial expressions of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<idno type="DOI">10.1177/1754073912451332</idno>
		<ptr target="http://dx.doi.org/10.1177/1754073912451332" />
	</analytic>
	<monogr>
		<title level="j">Emotion Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="90" to="96" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,474.98,240.01,7.03;18,314.00,485.45,232.02,7.03;18,314.00,495.92,219.33,7.03" xml:id="b23">
	<analytic>
		<title level="a" type="main">On the universality and cultural specificity of emotion recognition: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.128.2.203</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-2909.128.2.203" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="203" to="235" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,506.38,240.03,7.03;18,314.00,516.85,232.03,7.03;18,314.00,527.31,232.01,7.03;18,314.00,537.78,127.34,7.03" xml:id="b24">
	<analytic>
		<title level="a" type="main">Cultural similarity&apos;s consequences: A distance perspective on cross-cultural differences in emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022022102239157</idno>
		<ptr target="http://dx.doi.org/10.1177/0022022102239157" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="92" to="110" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,548.24,240.03,7.03;18,314.00,558.71,232.01,7.03;18,314.00,569.18,232.01,7.03;18,314.00,579.64,84.89,7.03" xml:id="b25">
	<analytic>
		<title level="a" type="main">When familiarity breeds accuracy: Cultural exposure and facial emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.85.2.276</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.85.2.276" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="276" to="290" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,590.11,240.04,7.03;18,314.00,600.57,232.02,7.03;18,314.00,611.04,231.93,7.03;18,314.00,621.50,80.89,7.03" xml:id="b26">
	<analytic>
		<title level="a" type="main">Toward a dialect theory: Cultural differences in the expression and recognition of posed facial expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>BeauprÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>LÃ©vesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hess</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.7.1.131</idno>
		<ptr target="http://dx.doi.org/10.1037/1528-3542.7.1.131" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="131" to="146" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,631.97,240.03,7.03;18,314.00,642.43,232.02,7.03;18,314.00,652.90,232.01,7.03;18,314.00,663.37,84.89,7.03" xml:id="b27">
	<analytic>
		<title level="a" type="main">Cross-cultural patterns in emotion recognition: Highlighting design and analytical techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.2.1.75</idno>
		<ptr target="http://dx.doi.org/10.1037/1528-3542.2.1.75" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,673.83,240.03,7.03;18,314.00,684.30,232.02,7.03;18,314.00,694.76,232.00,7.03;18,314.00,705.23,88.22,7.03" xml:id="b28">
	<analytic>
		<title level="a" type="main">Hemifacial differences in the in-group advantage in emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1080/02699930341000257</idno>
		<ptr target="http://dx.doi.org/10.1080/02699930341000257" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="613" to="629" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,306.00,715.69,240.01,7.03;18,7.70,556.60,7.03,14.22;18,7.70,522.39,7.03,31.55;18,7.70,514.39,7.03,5.34;18,7.70,473.51,7.03,38.22;18,7.70,462.85,7.03,8.00;18,7.70,450.41,7.03,9.78;18,7.70,416.21,7.03,31.54;18,7.70,368.66,7.03,44.89;18,7.70,328.22,7.03,37.78;18,7.70,318.89,7.03,6.66;18,7.70,304.68,7.03,11.55;18,7.70,295.35,7.03,6.66;18,7.70,285.13,7.03,7.56;18,7.70,264.70,7.03,17.78;18,7.70,227.15,7.03,34.89;18,17.70,567.25,7.03,14.22;18,17.70,544.60,7.03,19.99;18,17.70,536.60,7.03,5.34;18,17.70,506.39,7.03,27.55;18,17.70,484.62,7.03,19.11;18,17.70,472.63,7.03,9.33;18,17.70,460.19,7.03,9.78;18,17.70,430.42,7.03,27.10;18,17.70,417.10,7.03,10.66;18,17.70,407.77,7.03,6.66;18,17.70,395.33,7.03,9.78;18,17.70,360.22,7.03,32.45;18,17.70,344.23,7.03,13.33;18,17.70,330.02,7.03,11.55;18,17.70,322.02,7.03,5.34;18,17.70,309.14,7.03,10.22;18,17.70,300.25,7.03,6.22;18,17.70,290.04,7.03,7.55;18,17.70,245.60,7.03,41.78;18,17.70,216.50,7.03,26.44" xml:id="b29">
	<monogr>
		<title level="m" type="main">Appraisal processes in emotion. This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,56.00,77.20,232.03,7.03;19,56.00,87.51,232.04,7.03;19,56.00,97.82,18.89,7.03" xml:id="b30">
	<monogr>
				<title level="m">Handbook of affective sciences</title>
		<editor>R. J. Davidson, K. R. Scherer, &amp; H. H. Goldsmith</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="572" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,108.13,240.03,7.03;19,56.00,118.43,232.02,7.03;19,56.00,128.74,232.03,7.03;19,56.00,139.05,232.00,7.03;19,56.00,149.35,72.90,7.03" xml:id="b31">
	<analytic>
		<title level="a" type="main">The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for voice research and affective computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>AndrÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1109/TAFFC.2015.2457417</idno>
		<ptr target="http://dx.doi.org/10.1109/TAFFC.2015.2457417" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="190" to="202" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,159.66,240.03,7.03;19,56.00,169.97,232.02,7.03;19,56.00,180.28,232.05,7.03;19,56.00,190.58,232.02,7.03;19,56.00,200.96,232.01,6.86;19,56.00,211.20,232.04,7.03;19,56.00,221.50,179.77,7.03" xml:id="b32">
	<analytic>
		<title level="a" type="main">Recent developments in openSMILE, the Munich open-source multimedia feature extractor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2502081.2502224</idno>
		<ptr target="http://dx.doi.org/10.1145/2502081.2502224" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Association for Computing Machinery International Conference on Multimedia</title>
		<editor>A. Jaimes, N. Sebe, N. Boujemaa, D. Gatica-Perez, D. A. Shamma, M. Worring, &amp; R. Zimmermann</editor>
		<meeting>the 21st Association for Computing Machinery International Conference on Multimedia<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="835" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,231.81,240.03,7.03;19,56.00,242.12,232.03,7.03;19,56.00,252.41,232.02,7.03;19,56.00,262.71,147.29,7.03" xml:id="b33">
	<analytic>
		<title level="a" type="main">The cultural matrix of social psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kitayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Markus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Nisbett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The handbook of social psychology</title>
		<editor>D. Gilbert, S. Fiske, &amp; G. Lindzey</editor>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="915" to="981" />
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct coords="19,48.00,273.00,239.99,7.03;19,56.00,283.30,232.02,7.03;19,56.00,293.59,94.88,7.03" xml:id="b34">
	<monogr>
		<title level="m" type="main">Emotional patterns in intonation and music. Zeitschrift fÃ¼r Phonetik, Sprachwissenschaft und Kommunikationsforschung</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fonagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Magdics</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="293" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,303.89,240.02,7.03;19,56.00,314.19,232.03,7.03;19,56.00,324.48,231.89,7.03;19,56.00,334.78,18.00,7.03" xml:id="b35">
	<monogr>
		<title level="m" type="main">Components of emotional meaning: A sourcebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J R</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soriano</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780199592746.001.0001</idno>
		<ptr target="http://dx.doi.org/10.1093/acprof:oso/9780199592746.001.0001" />
		<editor>C.</editor>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,345.07,240.01,7.03;19,56.00,355.37,94.19,7.03" xml:id="b36">
	<monogr>
		<title level="m" type="main">Human facial expression: An evolutionary view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Fridlund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,365.66,240.03,7.03;19,56.00,375.96,232.00,7.03;19,56.00,386.25,232.00,7.03" xml:id="b37">
	<analytic>
		<title level="a" type="main">Cultural relativity in perceiving emotion from vocalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gendron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Van Der Vyver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Barrett</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613517239</idno>
		<ptr target="http://dx.doi.org/10.1177/0956797613517239" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="911" to="920" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,396.55,240.03,7.03;19,56.00,406.84,232.01,7.03;19,56.00,417.14,232.00,7.03;19,56.00,427.43,147.12,7.03" xml:id="b38">
	<analytic>
		<title level="a" type="main">A lens-mapping framework for understanding the encoding and decoding of interpersonal dispositions in nonverbal behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gifford</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.66.2.398</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.66.2.398" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="398" to="412" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,437.73,240.02,7.03;19,56.00,448.02,232.00,7.03;19,56.00,458.32,232.00,7.03;19,56.00,468.61,157.40,7.03" xml:id="b39">
	<analytic>
		<title level="a" type="main">Recognition of emotion in English voices by speakers of Japanese, Spanish, and English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feldstein</surname></persName>
		</author>
		<idno type="DOI">10.1515/iral.39.1.19</idno>
		<ptr target="http://dx.doi.org/10.1515/iral.39.1.19" />
	</analytic>
	<monogr>
		<title level="j">International Review of Applied Linguistics in Language Teaching</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="19" to="37" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,478.91,240.03,7.03;19,56.00,489.20,232.03,7.03;19,56.00,499.50,232.01,7.03;19,56.00,509.79,22.66,7.03" xml:id="b40">
	<analytic>
		<title level="a" type="main">Psychosocial correlates of interpersonal sensitivity: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Andrzejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Yopchick</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10919-009-0070-5</idno>
		<ptr target="http://dx.doi.org/10.1007/s10919-009-0070-5" />
	</analytic>
	<monogr>
		<title level="j">Journal of Nonverbal Behavior</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="149" to="180" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,520.09,240.03,7.03;19,56.00,530.38,231.99,7.03;19,56.00,540.68,65.78,7.03" xml:id="b41">
	<analytic>
		<title level="a" type="main">Acoustical correlates of affective prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammerschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>JÃ¼rgens</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jvoice.2006.03.002</idno>
		<ptr target="http://dx.doi.org/10.1016/j.jvoice.2006.03.002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Voice</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="531" to="540" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,550.97,240.02,7.03;19,56.00,561.27,205.84,7.03" xml:id="b42">
	<analytic>
		<title level="a" type="main">Darwin and emotion expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thibault</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0013386</idno>
		<ptr target="http://dx.doi.org/10.1037/a0013386" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="120" to="128" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,571.57,240.03,7.03;19,56.00,581.86,232.01,7.03;19,56.00,592.16,54.65,7.03" xml:id="b43">
	<monogr>
		<title level="m" type="main">Culture&apos;s consequences: Comparing values, behaviors, institutions, and organizations across nations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hofstede</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Sage</publisher>
			<pubPlace>Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct coords="19,48.00,602.45,240.03,7.03;19,56.00,612.75,50.44,7.03" xml:id="b44">
	<monogr>
		<title level="m" type="main">The face of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Izard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<publisher>Appleton-Century-Crofts</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,623.04,240.01,7.03;19,56.00,633.34,232.01,7.03;19,56.00,643.63,232.02,7.03;19,56.00,653.93,74.66,7.03" xml:id="b45">
	<analytic>
		<title level="a" type="main">Internal representations reveal cultural diversity in expectations of facial expressions of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Jack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caldara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Schyns</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0023463</idno>
		<ptr target="http://dx.doi.org/10.1037/a0023463" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="19" to="25" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,48.00,664.22,240.05,7.03;19,56.00,674.52,115.09,7.03" xml:id="b46">
	<monogr>
		<title level="m" type="main">MediaLab (Version</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Jarvis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Empirisoft Corporation</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct coords="19,48.00,684.81,240.03,7.03;19,56.00,695.11,232.02,7.03;19,56.00,705.40,232.00,7.03;19,56.00,715.70,78.00,7.03" xml:id="b47">
	<analytic>
		<title level="a" type="main">Encoding conditions affect recognition of vocally expressed emotions across cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>JÃ¼rgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drolet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pirow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Scheiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00111</idno>
		<ptr target="http://dx.doi.org/10.3389/fpsyg.2013.00111" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,77.20,240.01,7.03;19,314.00,87.50,232.00,7.03;19,314.00,97.81,217.18,7.04" xml:id="b48">
	<analytic>
		<title level="a" type="main">Impact of intended emotion intensity on cue utilization and decoding accuracy in vocal expression of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.1.4.381</idno>
		<ptr target="http://dx.doi.org/10.1037/1528-3542.1.4.381" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="381" to="412" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,108.13,240.00,7.03;19,314.00,118.43,232.02,7.03;19,314.00,128.74,232.00,7.03;19,314.00,139.05,50.00,7.03" xml:id="b49">
	<analytic>
		<title level="a" type="main">Communication of emotions in vocal expression and music performance: Different channels, same code?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.129.5.770</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-2909.129.5.770" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="770" to="814" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,149.35,240.02,7.03;19,314.00,159.66,231.99,7.03;19,314.00,169.97,87.34,7.03" xml:id="b50">
	<analytic>
		<title level="a" type="main">Elimination of verbal cues in judgments of emotion from voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kramer</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0042473</idno>
		<ptr target="http://dx.doi.org/10.1037/h0042473" />
	</analytic>
	<monogr>
		<title level="j">Journal of Abnormal Psychology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="390" to="396" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,180.27,240.01,7.03;19,314.00,190.58,232.00,7.03;19,314.00,200.89,210.21,7.03" xml:id="b51">
	<monogr>
		<title level="m" type="main">Foundations of voice studies: An interdisciplinary approach to voice production and perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kreiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sidtis</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781444395068</idno>
		<ptr target="http://dx.doi.org/10.1002/9781444395068" />
		<imprint>
			<date type="published" when="2011" />
			<publisher>Wiley-Blackwell</publisher>
			<pubPlace>Chichester, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,211.20,240.01,7.03;19,314.00,221.50,232.02,7.03;19,314.00,231.81,232.02,7.03;19,314.00,242.12,114.01,7.03" xml:id="b52">
	<analytic>
		<title level="a" type="main">Universal and culture-specific factors in the recognition and performance of musical affect expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eerola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Thingujam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Beller</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0031388</idno>
		<ptr target="http://dx.doi.org/10.1037/a0031388" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="434" to="449" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,252.41,240.02,7.03;19,314.00,262.71,232.03,7.03;19,314.00,273.00,232.00,7.03" xml:id="b53">
	<analytic>
		<title level="a" type="main">Emotion appraisal dimensions can be inferred from vocal expressions. Social Psychological and Personality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<idno type="DOI">10.1177/1948550611428011</idno>
		<ptr target="http://dx.doi.org/10.1177/1948550611428011" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="529" to="536" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,283.30,240.01,7.03;19,314.00,293.59,232.02,7.03;19,314.00,303.89,232.03,7.03;19,314.00,314.18,232.00,7.03;19,314.00,324.48,232.04,7.03;19,314.00,334.85,232.02,6.86;19,314.00,345.07,232.02,7.03;19,314.00,355.37,39.78,7.03" xml:id="b54">
	<analytic>
		<title level="a" type="main">Presenting the VENEC corpus: Development of a cross-cultural corpus of vocal emotion expressions and a novel method of annotating emotion appraisals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Thingujam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">K</forename><surname>Iraki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rockstuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Althoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on Corpora for Research on Emotion and Affect</title>
		<editor>L. Devillers, B. Schuller, R. Cowie, E. Douglas-Cowie, &amp; A. Batliner</editor>
		<meeting>the LREC 2010 Workshop on Corpora for Research on Emotion and Affect<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="53" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,365.66,240.04,7.03;19,314.00,375.96,232.02,7.03;19,314.00,386.25,232.00,7.03;19,314.00,396.55,31.55,7.03" xml:id="b55">
	<analytic>
		<title level="a" type="main">Evidence for cultural dialects in vocal emotion expression: Acoustic classification within and across five nations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Neiberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0036048</idno>
		<ptr target="http://dx.doi.org/10.1037/a0036048" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="445" to="449" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,406.84,240.03,7.03;19,314.00,417.14,232.03,7.03;19,314.00,427.43,232.00,7.03;19,314.00,437.73,216.51,7.03" xml:id="b56">
	<analytic>
		<title level="a" type="main">Expression of affect in spontaneous speech: Acoustic correlates and automatic detection of irritation and resignation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Neiberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Elenius</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2010.03.004</idno>
		<ptr target="http://dx.doi.org/10.1016/j.csl.2010.03.004" />
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="84" to="104" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,448.02,240.04,7.03;19,314.00,458.32,55.33,7.03" xml:id="b57">
	<monogr>
		<title level="m" type="main">Emotion and adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Lazarus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,468.61,240.02,7.03;19,314.00,478.91,232.02,7.03;19,314.00,489.20,231.86,7.03;19,314.00,499.50,22.00,7.03" xml:id="b58">
	<analytic>
		<title level="a" type="main">Nonverbal &quot;accents&quot;: Cultural differences in facial expressions of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Elfenbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.24461</idno>
		<ptr target="http://dx.doi.org/10.1111/1467-9280.24461" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="373" to="376" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,509.79,240.03,7.03;19,314.00,520.09,232.02,7.03;19,314.00,530.38,231.99,7.03;19,314.00,540.68,232.01,7.03;19,314.00,550.97,120.00,7.03" xml:id="b59">
	<analytic>
		<title level="a" type="main">Cross-cultural differences in the perception of emotional content of speech: A study of the development of sensitivity in Canadian and Mexican children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Mccluskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Albas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Niemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Ferrer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.11.5.551</idno>
		<ptr target="http://dx.doi.org/10.1037/0012-1649.11.5.551" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="551" to="555" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,561.27,240.01,7.03;19,314.00,571.56,231.96,7.03;19,314.00,581.86,88.89,7.03" xml:id="b60">
	<analytic>
		<title level="a" type="main">Cultural variations in emotions: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Frijda</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.112.2.179</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-2909.112.2.179" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="179" to="204" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,592.15,240.03,7.03;19,314.00,602.45,232.03,7.03" xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>O&amp;apos;grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Archibald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aronoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rees-Miller</surname></persName>
		</author>
		<title level="m">Contemporary linguistics</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Bedford/St. Martin&apos;s Press</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct coords="19,306.00,612.75,240.00,7.03;19,314.00,623.04,232.03,7.03;19,314.00,633.34,111.56,7.03" xml:id="b62">
	<monogr>
		<title level="m" type="main">The cognitive structure of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Clore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511571299</idno>
		<ptr target="http://dx.doi.org/10.1017/CBO9780511571299" />
		<imprint>
			<date type="published" when="1988" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,643.63,240.03,7.03;19,314.00,653.93,232.01,7.03;19,314.00,664.22,231.99,7.03;19,314.00,674.52,76.22,7.03" xml:id="b63">
	<analytic>
		<title level="a" type="main">Sound on the rebound: Bringing form and function back to the forefront in understanding nonhuman primate vocal signaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Owren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rendall</surname></persName>
		</author>
		<idno type="DOI">10.1002/evan.1014</idno>
		<ptr target="http://dx.doi.org/10.1002/evan.1014" />
	</analytic>
	<monogr>
		<title level="j">Evolutionary Anthropology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="58" to="71" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,306.00,684.81,240.03,7.03;19,314.00,695.11,232.00,7.03;19,314.00,705.40,232.00,7.03;19,314.00,715.70,14.00,7.03" xml:id="b64">
	<analytic>
		<title level="a" type="main">Mapping emotions into acoustic space: The role of voice production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>BjÃ¶rkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sundberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2011.02.010</idno>
		<ptr target="http://dx.doi.org/10.1016/j.biopsycho.2011.02.010" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="93" to="98" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,7.70,556.60,7.03,14.22;19,7.70,522.39,7.03,31.55;19,7.70,514.39,7.03,5.34;19,7.70,473.51,7.03,38.22;19,7.70,462.85,7.03,8.00;19,7.70,450.41,7.03,9.78;19,7.70,416.21,7.03,31.54;19,7.70,368.66,7.03,44.89;19,7.70,328.22,7.03,37.78;19,7.70,318.89,7.03,6.66;19,7.70,304.68,7.03,11.55;19,7.70,295.35,7.03,6.66;19,7.70,285.13,7.03,7.56;19,7.70,264.70,7.03,17.78;19,7.70,227.15,7.03,34.89;19,17.70,567.25,7.03,14.22;19,17.70,544.60,7.03,19.99;19,17.70,536.60,7.03,5.34;19,17.70,506.39,7.03,27.55;19,17.70,484.62,7.03,19.11;19,17.70,472.63,7.03,9.33;19,17.70,460.19,7.03,9.78;19,17.70,430.42,7.03,27.10;19,17.70,417.10,7.03,10.66;19,17.70,407.77,7.03,6.66;19,17.70,395.33,7.03,9.78;19,17.70,360.22,7.03,32.45;19,17.70,344.23,7.03,13.33;19,17.70,330.02,7.03,11.55;19,17.70,322.02,7.03,5.34;19,17.70,309.14,7.03,10.22;19,17.70,300.25,7.03,6.22;19,17.70,290.04,7.03,7.55;19,17.70,245.60,7.03,41.78;19,17.70,216.50,7.03,26.44" xml:id="b65">
	<monogr>
		<title level="m" type="main">This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,77.20,240.02,7.03;20,56.00,87.20,232.02,7.03;20,56.00,97.20,231.94,7.03;20,56.00,107.20,26.00,7.03" xml:id="b66">
	<analytic>
		<title level="a" type="main">Cross-cultural emotional prosody recognition: Evidence from Chinese and British listeners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paulmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Uskul</surname></persName>
		</author>
		<idno type="DOI">10.1080/02699931.2013.812033</idno>
		<ptr target="http://dx.doi.org/10.1080/02699931.2013.812033" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="230" to="244" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,117.20,240.03,7.03;20,56.00,127.20,232.01,7.03;20,56.00,137.20,178.22,7.03" xml:id="b67">
	<analytic>
		<title level="a" type="main">Recognizing emotions in a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Pell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Monetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paulmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Kotz</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10919-008-0065-7</idno>
		<ptr target="http://dx.doi.org/10.1007/s10919-008-0065-7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Nonverbal Behavior</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="107" to="120" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,147.20,240.03,7.03;20,56.00,157.20,232.03,7.03;20,56.00,167.20,231.99,7.03;20,56.00,177.20,91.78,7.03" xml:id="b68">
	<analytic>
		<title level="a" type="main">Factors in the recognition of vocally expressed emotions: A comparison of four languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Pell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paulmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alasseri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Kotz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.wocn.2009.07.005</idno>
		<ptr target="http://dx.doi.org/10.1016/j.wocn.2009.07.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="417" to="435" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,187.20,240.03,7.03;20,56.00,197.20,232.02,7.03;20,56.00,207.20,163.99,7.03" xml:id="b69">
	<monogr>
		<title level="m" type="main">Speech science primer: Physiology, acoustics, and perception of speech (6th rev</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Borden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Lippincott Williams &amp; Wilkins</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,217.20,240.03,7.03;20,56.00,227.20,232.02,7.03;20,56.00,237.20,144.86,7.03" xml:id="b70">
	<monogr>
		<title level="m" type="main">Sensitivity to nonverbal communication: The PONS test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Dimatteo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Archer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Johns Hopkins University Press</publisher>
			<pubPlace>Baltimore, MD</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,247.20,240.00,7.03;20,56.00,257.20,232.02,7.03;20,56.00,267.20,155.78,7.03" xml:id="b71">
	<analytic>
		<title level="a" type="main">Contrasts and correlations in effect-size estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Rosnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.00287</idno>
		<ptr target="http://dx.doi.org/10.1111/1467-9280.00287" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="446" to="453" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,277.20,240.03,7.03;20,56.00,287.20,232.02,7.03;20,56.00,297.20,232.00,7.03;20,56.00,307.20,56.21,7.03" xml:id="b72">
	<analytic>
		<title level="a" type="main">The effect of affect on various acoustic measures of prosody in tone and non-tone languages: A comparison based on computer analysis of voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Edmondson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Seibert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="215" to="223" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,317.20,240.03,7.03;20,56.00,327.20,232.00,7.03;20,56.00,337.20,62.01,7.03" xml:id="b73">
	<analytic>
		<title level="a" type="main">Forced-choice response format in the study of facial expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00995206</idno>
		<ptr target="http://dx.doi.org/10.1007/BF00995206" />
	</analytic>
	<monogr>
		<title level="j">Motivation and Emotion</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,347.20,240.02,7.03;20,56.00,357.20,232.03,7.03;20,56.00,367.20,219.33,7.03" xml:id="b74">
	<analytic>
		<title level="a" type="main">Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.115.1.102</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-2909.115.1.102" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="102" to="141" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,377.20,240.05,7.03;20,56.00,387.20,232.00,7.03;20,56.00,397.20,224.51,7.03" xml:id="b75">
	<analytic>
		<title level="a" type="main">Facial and vocal expressions of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Bachorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Fernandez-Dols</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.54.101601.145102</idno>
		<ptr target="http://dx.doi.org/10.1146/annurev.psych.54.101601.145102" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="329" to="349" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,407.20,240.02,7.03;20,56.00,417.20,232.01,7.03;20,56.00,427.20,146.46,7.03" xml:id="b76">
	<analytic>
		<title level="a" type="main">More than happy: The need for disentangling positive emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721409359290</idno>
		<ptr target="http://dx.doi.org/10.1177/0963721409359290" />
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="36" to="40" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,437.20,240.00,7.03;20,56.00,447.20,232.02,7.03;20,56.00,457.20,181.77,7.03" xml:id="b77">
	<analytic>
		<title level="a" type="main">The role of motivation and cultural dialects in the in-group advantage for emotional vocalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00814</idno>
		<ptr target="http://dx.doi.org/10.3389/fpsyg.2013.00814" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">914</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,467.20,240.02,7.03;20,56.00,477.20,232.02,7.03;20,56.00,487.20,232.00,7.03;20,56.00,497.20,68.00,7.03" xml:id="b78">
	<analytic>
		<title level="a" type="main">Perceptual cues in nonverbal vocal expressions of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470211003721642</idno>
		<ptr target="http://dx.doi.org/10.1080/17470211003721642" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="2251" to="2272" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,507.20,240.05,7.03;20,56.00,517.20,232.02,7.03;20,56.00,527.20,232.00,7.03;20,56.00,537.20,231.85,7.03;20,56.00,547.20,42.00,7.03" xml:id="b79">
	<analytic>
		<title level="a" type="main">Cross-cultural recognition of basic emotions through nonverbal emotional vocalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0908239106</idno>
		<ptr target="http://dx.doi.org/10.1073/pnas.0908239106" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="2408" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,557.20,240.02,7.03;20,56.00,567.20,232.01,7.03;20,56.00,577.20,92.89,7.03" xml:id="b80">
	<analytic>
		<title level="a" type="main">Vocal affect expression: A review and a model for future research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.99.2.143</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-2909.99.2.143" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="143" to="165" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,587.20,240.03,7.03;20,56.00,597.20,232.00,7.03;20,56.00,607.20,129.11,7.03" xml:id="b81">
	<analytic>
		<title level="a" type="main">On the symbolic functions of vocal affect expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1177/0261927X8800700201</idno>
		<ptr target="http://dx.doi.org/10.1177/0261927X8800700201" />
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="79" to="100" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,617.20,240.02,7.03;20,56.00,627.20,232.00,7.03;20,56.00,637.20,120.00,7.03" xml:id="b82">
	<analytic>
		<title level="a" type="main">The role of culture in emotion-antecedent appraisal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.73.5.902</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.73.5.902" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="902" to="922" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,647.20,240.03,7.03;20,56.00,657.20,232.02,7.03;20,56.00,667.20,122.22,7.03" xml:id="b83">
	<analytic>
		<title level="a" type="main">Vocal communication of emotion: A review of research paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0167-6393%2802%2900084-5</idno>
		<idno>1016/S0167-6393(02)00084-5</idno>
		<ptr target="http://dx.doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="227" to="256" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,48.00,677.20,240.02,7.03;20,56.00,687.20,232.00,7.03;20,56.00,697.20,118.45,7.03" xml:id="b84">
	<analytic>
		<title level="a" type="main">Vocal markers of emotion: Comparing induction and acting elicitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2011.11.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.csl.2011.11.003" />
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="40" to="58" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,77.20,240.03,7.03;20,314.00,87.37,232.01,7.03;20,314.00,97.54,231.96,7.03;20,314.00,107.72,76.00,7.03" xml:id="b85">
	<analytic>
		<title level="a" type="main">Emotion inferences from vocal expression correlate across languages and cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Banse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Wallbott</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022022101032001009</idno>
		<ptr target="http://dx.doi.org/10.1177/0022022101032001009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="76" to="92" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,117.89,240.03,7.03;20,314.00,128.06,232.03,7.03;20,314.00,138.23,232.03,7.03;20,314.00,148.40,171.72,7.03" xml:id="b86">
	<analytic>
		<title level="a" type="main">On the use of actor portrayals in research on emotional expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>BÃ¤nziger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Blueprint for affective computing: A sourcebook</title>
		<editor>K. R. Scherer, T. BÃ¤nziger, &amp; E. B. Roesch</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="271" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,158.57,240.03,7.03;20,314.00,168.74,232.03,7.03;20,314.00,178.91,232.01,7.03;20,314.00,189.07,175.12,7.03" xml:id="b87">
	<analytic>
		<title level="a" type="main">In the eye of the beholder? Universality and cultural specificity in the expression and perception of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Clark-Polner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mortillaro</surname></persName>
		</author>
		<idno type="DOI">10.1080/00207594.2011.626049</idno>
		<ptr target="http://dx.doi.org/10.1080/00207594.2011.626049" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="401" to="435" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,199.23,240.02,7.03;20,314.00,209.39,232.03,7.03;20,314.00,219.55,232.01,7.03;20,314.00,229.70,134.00,7.03" xml:id="b88">
	<analytic>
		<title level="a" type="main">Recognizing realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Batliner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Steidl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seppi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.specom.2011.01.011</idno>
		<ptr target="http://dx.doi.org/10.1016/j.specom.2011.01.011" />
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1062" to="1087" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,239.86,240.03,7.03;20,314.00,250.02,232.03,7.03;20,314.00,260.18,232.01,7.03" xml:id="b89">
	<analytic>
		<title level="a" type="main">Intercultural perception of English, French and Japanese social affective prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shochi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rilliard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>AubergÃ©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The role of prosody in affective speech</title>
		<editor>S. Hancil</editor>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="31" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,314.00,270.34,100.86,7.03" xml:id="b90">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Switzerland</forename><surname>Bern</surname></persName>
		</author>
		<imprint>
			<publisher>Peter Lang</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,280.50,240.04,7.03;20,314.00,290.66,53.11,7.03" xml:id="b91">
	<monogr>
		<title level="m" type="main">An actor prepares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stanislavski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
			<publisher>Theatre Arts Books/Methuen</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,300.82,240.02,7.03;20,314.00,310.98,232.03,7.03;20,314.00,321.14,232.01,7.03;20,314.00,331.30,75.78,7.03" xml:id="b92">
	<analytic>
		<title level="a" type="main">Interdependencies among voice source parameters in emotional speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>BjÃ¶rkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1109/T-AFFC.2011.14</idno>
		<ptr target="http://dx.doi.org/10.1109/T-AFFC.2011.14" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="162" to="174" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,341.46,240.01,7.03;20,314.00,351.61,232.02,7.03;20,314.00,361.77,141.65,7.03" xml:id="b93">
	<analytic>
		<title level="a" type="main">Self-conscious emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Tangney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Tracy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of self and identity</title>
		<editor>M. Leary &amp; J. P. Tangney</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="446" to="478" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct coords="20,306.00,371.93,240.01,7.03;20,314.00,382.09,232.01,7.03;20,314.00,392.25,231.95,7.03;20,314.00,402.41,141.57,7.03" xml:id="b94">
	<analytic>
		<title level="a" type="main">The effect of groupidentification on emotion recognition: The case of cats and basketball players</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thibault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hess</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2005.10.006</idno>
		<ptr target="http://dx.doi.org/10.1016/j.jesp.2005.10.006" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="676" to="683" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,412.57,240.02,7.03;20,314.00,422.73,231.87,7.03;20,314.00,432.89,48.45,7.03" xml:id="b95">
	<analytic>
		<title level="a" type="main">Decoding speech prosody in five languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-L</forename><surname>Balkwill</surname></persName>
		</author>
		<idno type="DOI">10.1515/SEM.2006.017</idno>
		<ptr target="http://dx.doi.org/10.1515/SEM.2006.017" />
	</analytic>
	<monogr>
		<title level="j">Semiotica</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="407" to="424" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,443.05,240.03,7.03;20,314.00,453.21,232.01,7.03;20,314.00,463.37,177.41,7.03" xml:id="b96">
	<analytic>
		<title level="a" type="main">What and where are the primary affects? Some evidence for a theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mccarter</surname></persName>
		</author>
		<idno type="DOI">10.2466/pms.1964.18.1.119</idno>
		<ptr target="http://dx.doi.org/10.2466/pms.1964.18.1.119" />
	</analytic>
	<monogr>
		<title level="j">Perceptual and Motor Skills</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="119" to="158" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,473.53,240.03,7.03;20,314.00,483.68,232.02,7.03;20,314.00,493.84,206.98,7.03" xml:id="b97">
	<analytic>
		<title level="a" type="main">Four models of basic emotions: A review of Ekman and Cordaro, Izard, Levenson, and Panksepp and Watt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Tracy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Randles</surname></persName>
		</author>
		<idno type="DOI">10.1177/1754073911410747</idno>
		<ptr target="http://dx.doi.org/10.1177/1754073911410747" />
	</analytic>
	<monogr>
		<title level="j">Emotion Review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="397" to="405" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,504.00,240.03,7.03;20,314.00,514.16,232.02,7.03;20,314.00,524.32,232.01,7.03;20,314.00,534.48,158.46,7.03" xml:id="b98">
	<analytic>
		<title level="a" type="main">Recognition of vocal expressions of emotion: A three-nation study to identify universal characteristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Bezooijen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Heenan</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022002183014004001</idno>
		<ptr target="http://dx.doi.org/10.1177/0022002183014004001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="387" to="406" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,544.64,240.03,7.03;20,314.00,554.80,232.01,7.03;20,314.00,564.96,232.00,7.03;20,314.00,575.12,76.00,7.03" xml:id="b99">
	<monogr>
		<title level="m" type="main">Perception of emotional nonsense sentences in China</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Waaramaa</surname></persName>
		</author>
		<idno type="DOI">10.3109/14015439.2014.915982</idno>
		<ptr target="http://dx.doi.org/10.3109/14015439.2014.915982" />
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="129" to="135" />
			<pubPlace>Egypt, Estonia, Finland, Russia, Sweden, and the USA</pubPlace>
		</imprint>
	</monogr>
	<note>Logopedics, Phoniatrics, Vocology</note>
</biblStruct>

<biblStruct coords="20,306.00,585.28,240.01,7.03;20,314.00,595.44,232.01,7.03;20,314.00,605.59,124.24,7.03" xml:id="b100">
	<analytic>
		<title level="a" type="main">On measuring performance in category judgment studies of nonverbal behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00987006</idno>
		<ptr target="http://dx.doi.org/10.1007/BF00987006" />
	</analytic>
	<monogr>
		<title level="j">Journal of Nonverbal Behavior</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,306.00,615.75,240.02,7.03;20,314.00,625.91,232.02,7.03;20,314.00,636.07,232.00,7.03;20,314.00,646.23,148.67,7.03" xml:id="b101">
	<analytic>
		<title level="a" type="main">Which is the best listener group? Perception of Chinese emotional prosody by Chinese natives, naive Dutch listeners, and Dutch L2 learners of Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1075/dujal.2.2.03zhu</idno>
		<ptr target="http://dx.doi.org/10.1075/dujal.2.2.03zhu" />
	</analytic>
	<monogr>
		<title level="j">Dutch Journal of Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="170" to="183" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
