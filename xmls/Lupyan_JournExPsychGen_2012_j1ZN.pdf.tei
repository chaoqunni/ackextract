<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/jwu/github/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Evocative Power of Words: Activation of Concepts by Verbal and Nonverbal Means</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Lupyan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><forename type="middle">L</forename><surname>Thompson-Schill</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<postCode>2005</postCode>
									<settlement>Gentner &amp; Goldin</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Institute for Research in Cognitive Science, Center for Cognitive Neuroscience</orgName>
								<orgName type="department" key="dep3">Department of Psychology</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<addrLine>Sharon L. Thompson-Schill</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Evocative Power of Words: Activation of Concepts by Verbal and Nonverbal Means</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Supplemental materials: http://dx.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0-SNAPSHOT" ident="GROBID-SDO" when="2019-12-20T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>concepts</term>
					<term>labels</term>
					<term>words</term>
					<term>representations</term>
					<term>language and thought</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A major part of learning a language is learning to map spoken words onto objects in the environment. An open question is what are the consequences of this learning for cognition and perception? Here, we present a series of experiments that examine effects of verbal labels on the activation of conceptual information as measured through picture verification tasks. We find that verbal cues, such as the word "cat," lead to faster and more accurate verification of congruent objects and rejection of incongruent objects than do either nonverbal cues, such as the sound of a cat meowing, or words that do not directly refer to the object, such as the word "meowing." This label advantage does not arise from verbal labels being more familiar or easier to process than other cues, and it does extends to newly learned labels and sounds. Despite having equivalent facility in learning associations between novel objects and labels or sounds, conceptual information is activated more effectively through verbal means than through nonverbal means. Thus, rather than simply accessing nonverbal concepts, language activates aspects of a conceptual representation in a particularly effective way. We offer preliminary support that representations activated via verbal means are more categorical and show greater consistency between subjects. These results inform the understanding of how human cognition is shaped by language and hint at effects that different patterns of naming can have on conceptual structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two hallmarks of human development are developing conceptual categories-learning that things with feathers tend to fly, that animals possessing certain features are dogs, and that foods of a certain color and shape are edible <ref type="bibr" coords="1,215.72,433.04,51.45,7.91" target="#b6">(Carey, 1987;</ref><ref type="bibr" coords="1,269.59,433.04,18.46,7.91;1,48.00,444.04,21.22,7.91" target="#b35">Keil, 1992;</ref><ref type="bibr" coords="1,73.38,444.04,112.17,7.91" target="#b68">Rogers &amp; McClelland, 2004</ref>)-and learning names for these categories <ref type="bibr" coords="1,113.09,455.04,63.00,7.91" target="#b88">(Waxman, 2004)</ref>. Although many have commented on the transformative power of names <ref type="bibr" coords="1,236.12,466.04,51.94,7.91" target="#b9">(Clark, 1998;</ref><ref type="bibr" coords="1,48.00,477.04,55.89,7.91" target="#b11">Dennett, 1996;</ref><ref type="bibr" coords="1,106.57,477.04,53.71,7.91" target="#b27">Harnad, 2005;</ref><ref type="bibr" coords="1,162.95,477.04,49.04,7.91" target="#b34">James, 1890;</ref><ref type="bibr" coords="1,214.66,477.04,61.48,7.91" target="#b84">Vygotsky, 1962)</ref>, it is only recently that the interplay between verbal labels and concepts is becoming a subject of systematic empirical study. Given the tight linkage between the representations of verbal meanings and the larger conceptual system <ref type="bibr" coords="1,472.01,400.04,58.48,7.91" target="#b55">(Murphy, 2002)</ref>, an important question is what effects language learning has on the activation and the organization of putatively nonverbal representations.</p><p>The learning of categories is, in principle, separable from the learning of their names. A child can have a conceptual category of "dog" without having a verbal label associated with the category. However, in practice, the two processes are intimately linked. Not only does conceptual development shape linguistic development (e.g., <ref type="bibr" coords="1,325.88,501.29,99.78,7.91" target="#b74">Snedeker &amp; Gleitman, 2004)</ref>, but linguistic development-and in particular, learning words-impacts conceptual development (e.g., <ref type="bibr" coords="1,306.00,523.79,57.60,7.91" target="#b8">Casasola, 2005;</ref><ref type="bibr" coords="1,368.26,523.79,128.75,7.91" target="#b23">Gentner &amp; Goldin-Meadow, 2003;</ref><ref type="bibr" coords="1,501.68,523.79,44.25,7.91;1,306.00,535.04,57.36,7.91" target="#b26">Gumperz &amp; Levinson, 1996;</ref><ref type="bibr" coords="1,366.58,535.04,57.36,7.91" target="#b39">Levinson, 1997;</ref><ref type="bibr" coords="1,427.17,535.04,118.86,7.91;1,306.00,546.29,19.80,7.91" target="#b48">Lupyan, Rakison, &amp; McClelland, 2007;</ref><ref type="bibr" coords="1,328.63,546.29,48.32,7.91" target="#b76">Spelke, 2003;</ref><ref type="bibr" coords="1,379.79,546.29,87.44,7.91" target="#b77">Spelke &amp; Tsivkin, 2001;</ref><ref type="bibr" coords="1,470.06,546.29,75.96,7.91;1,306.00,557.54,19.80,7.91" target="#b91">Waxman &amp; Markow, 1995;</ref><ref type="bibr" coords="1,328.16,557.54,84.53,7.91" target="#b101">Yoshida &amp; Smith, 2005)</ref>. For example, <ref type="bibr" coords="1,467.14,557.54,56.23,7.91" target="#b8">Casasola (2005)</ref> found that 18-month old infants could form an abstract spatial category only when accompanied by a familiar word.</p><p>Words continue to impact category learning in adulthood. For example, <ref type="bibr" coords="1,342.36,602.54,155.45,7.91" target="#b48">Lupyan, Rakison, and McClelland (2007)</ref> showed that learning verbal labels for novel categories improved category learning, even though the labels were entirely redundant. Once a word is learned, it appears to exert influences on visual recognition memory <ref type="bibr" coords="1,342.34,647.54,65.83,7.91" target="#b47">(Lupyan, 2008b)</ref> as well as perceptual processing <ref type="bibr" coords="1,306.00,658.79,62.17,7.91" target="#b46">(Lupyan, 2008a;</ref><ref type="bibr" coords="1,373.09,658.79,81.66,7.91" target="#b93">Winawer et al., 2007</ref>; see <ref type="bibr" coords="1,480.20,658.79,65.85,7.91;1,306.00,670.04,45.55,7.91" target="#b25">Gliga, Volein, &amp; Csibra, 2010</ref>, for intriguing results with 1-year-old infants). For example, hearing a verbal label such as "chair" facilitates the visual processing of the named category, compared with trials on which participants know the relevant object category but do not actually hear its name <ref type="bibr" coords="1,389.57,715.04,55.85,7.91" target="#b44">(Lupyan, 2007a</ref><ref type="bibr" coords="1,452.36,715.04,20.63,7.91" target="#b45">(Lupyan, , 2007b</ref><ref type="bibr" coords="1,480.01,715.04,19.46,7.91" target="#b46">(Lupyan, , 2008a</ref>. Hearing a label can even make an invisible object visible. <ref type="bibr" coords="2,218.50,77.04,69.56,7.91;2,48.00,88.12,27.99,7.91" target="#b49">Lupyan and Spivey (2010a)</ref> showed that hearing a spoken label increased visual sensitivity (i.e., increased the dЈ) in a simple object detection task: Simply hearing a label enabled participants to detect the presence of briefly presented masked objects that were otherwise invisible (see also <ref type="bibr" coords="2,83.88,132.44,204.16,7.91;2,48.00,143.52,51.49,7.91">Rosch, Mervis, Gray, Johnson, &amp; Boyes-Braem, 1976, Experiment 5)</ref>.</p><p>Understanding a word requires activation of conceptual representations denoted by that word. Of course, activation of concepts occurs in nonlinguistic contexts as well. It therefore makes sense to ask: Are conceptual representations activated by words different in some way from those activated via nonverbal means? Do words simply offer a way to access a language-independent concept-a concept that can be accessed equivalently through other, nonverbal means, or do words activate conceptual representations in a special way?</p><p>Before proceeding, we provide a short definition of what we mean by the terms concept and category. For present purposes, we define a concept more narrowly, as the mental representation of a category. A category in turn is a collection of discriminable entities that are treated as equivalent in some way <ref type="bibr" coords="2,216.24,287.56,71.81,7.91;2,48.00,298.64,61.06,7.91" target="#b4">(Bruner, Austin, &amp; Goodnow, 1956;</ref><ref type="bibr" coords="2,111.88,298.64,50.93,7.91" target="#b27">Harnad, 2005)</ref>. So, for example, the category of chairs forms a collection of discriminable entities that are equivalent in the certain contexts, such as finding something to sit on or something denoted by the word "chair. <ref type="bibr" coords="2,192.17,331.87,3.53,7.91">"</ref> We focus here on the visual aspects of conceptual representations and compare the power of verbal and nonverbal cues to activate visual information of both familiar and novel categoriesinformation we believe to be constitutive though clearly not exhaustive of the concept <ref type="bibr" coords="2,136.46,387.21,93.10,7.91" target="#b57">(Murphy &amp; Medin, 1985)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Logic of the Present Studies: Activation of Visual Information by Verbal and Nonverbal Means</head><p>A response to a visual stimulus can be altered by a cue presented prior to the target stimulus. These cues can be nonverbal <ref type="bibr" coords="2,265.82,460.47,22.25,7.91;2,48.00,471.54,81.92,7.91" target="#b15">(Egly, Driver, &amp; Rafal, 1994;</ref><ref type="bibr" coords="2,132.24,471.54,96.68,7.91" target="#b17">Eriksen &amp; Hoffman, 1972;</ref><ref type="bibr" coords="2,231.22,471.54,56.81,7.91;2,48.00,482.61,70.08,7.91" target="#b64">Posner, Snyder, &amp; Davidson, 1980)</ref> as well as verbal. For example, verbal cues in the form of words like "left" and "right" produce automatic shifts of attention just as reliably as nonverbal cues such as directional arrows, even when the words are entirely nonpredictive of the target's location (e.g., <ref type="bibr" coords="2,131.63,526.88,152.55,7.91" target="#b31">Hommel, Pratt, Colzato, &amp; Godijn, 2001)</ref>. Words related to motion, for example, "float," have been shown to affect visual motion processing, changing the sensitivity in detecting motion in random-dot kinematograms <ref type="bibr" coords="2,202.76,560.09,85.29,7.91;2,48.00,571.16,59.37,7.91" target="#b53">(Meteyard, Bahrami, &amp; Vigliocco, 2007)</ref>. A number of studies have also shown that visual object processing and attentional guidance can be altered by verbal cues <ref type="bibr" coords="2,66.89,593.29,128.81,7.91" target="#b61">(Pertzov, Zohary, &amp; Avidan, 2009;</ref><ref type="bibr" coords="2,198.59,593.29,89.44,7.91" target="#b65">Puri &amp; Wojciulik, 2008;</ref><ref type="bibr" coords="2,48.00,604.36,99.28,7.91" target="#b71">Schmidt &amp; Zelinsky, 2009;</ref><ref type="bibr" coords="2,149.95,604.36,110.93,7.91" target="#b83">Vickery, King, &amp; Jiang, 2005;</ref><ref type="bibr" coords="2,263.56,604.36,24.49,7.91;2,48.00,615.43,79.99,7.91" target="#b85">Walter &amp; Dassonville, 2005;</ref><ref type="bibr" coords="2,131.86,615.43,91.23,7.91" target="#b99">Yang &amp; Zelinsky, 2009)</ref>. Such effects of cues on visual processing have been linked to increases in category-specific cortical activity. For example, seeing the word face increases activity in the fusiform face area, an increase that correlates with an improvement in making a gender judgment of faces embedded in visual noise <ref type="bibr" coords="2,162.77,670.77,96.19,7.91" target="#b18">(Esterman &amp; Yantis, 2010)</ref>. In this article, we take a sensorimotor view of concepts: The neural activity that composes a concept is multimodal; that is, the visual aspects of the concept are represented by some of the same structures as those involved in sensory processing of the modality (e.g., <ref type="bibr" coords="2,328.13,77.04,52.64,7.91" target="#b0">Allport, 1985;</ref><ref type="bibr" coords="2,384.65,77.04,58.63,7.91" target="#b1">Barsalou, 2008;</ref><ref type="bibr" coords="2,447.16,77.04,98.88,7.91;2,306.00,88.04,100.85,7.91" target="#b81">Thompson-Schill, Aguirre, D'Esposito, &amp; Farah, 1999)</ref>.</p><p>Is a verbal label merely a convenient method of communicating information, or is there something special in the effect of a verbal cue on the conceptual/perceptual information that is activated? To make this question more concrete: Are the representations activated when hearing the word "cow" different from those activated when hearing nonverbal cues (one that is similarly associated with the concept of cows, for example, a mooing sound)? Although both cow and the sound of a cow mooing are associated with cows, only the former is treated (in the normal course of things) as referring to a cow.</p><p>We present seven experiments in which we examined whether concepts evoked by verbal and nonverbal means are distinguishable. In particular, we focus on the visual aspects of concepts activated by verbal and nonverbal means. Experiments 1A-1C and Experiment 2 contrasted the effects of verbal and nonverbal cues on performance in picture-verification tasks. Experiments 3A-3B contrasted verbal and nonverbal cues in a visual discrimination task that requires minimal semantic processing of the target pictures. In Experiment 4, we controlled participants' exposure to verbal and nonverbal cues by teaching them to associate novel labels and nonverbal sounds with novel object categories. This allowed us to test whether the results observed in Experiments 1 and 2 arose because participants were more familiar with verbal cues (e.g., "cow") than the nonverbal cues (e.g., mooing sound) or whether verbal cues indeed produced a unique effect on conceptual activation visual processing, perhaps owing to their referential status.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 1A-1C</head><p>A simple way to compare the relative efficacy with which verbal and nonverbal cues activated conceptual representations is through a verification task. In our implementation of this task, participants hear a cue that is either a word (e.g., "cow") or a characteristic sound (e.g., a mooing sound) and then see a matching or mismatching picture, which remains on the screen until the participants respond "match" or "mismatch." The more effective a cue is, the more quickly and/or accurately participants can respond to the target picture. If verbal and nonverbal cues both activate the very same concept cow (put into neural terms, the same assembly of neurons) and do so equally fast, then verification performance should be equivalent in the two cuing conditions. 1 A second possibility is that the two cues result in the same conceptual activation at the limit but that one cue leads to faster activation than the other. A third possibility is that verbal and nonverbal cues lead to qualitatively distinct patterns of activation. That is, rather than being two routes to activating the same concept, concepts activated via verbal means are different in some way from concepts activated via nonverbal means.</p><p>One way to tease apart the second and third possibilities is by varying the delay between the cue and the target. If the difference between the two cues is just a difference in the speed of activation then it should diminish with longer delays, as the slower cue is allowed time to "catch up" with the faster cue. Varying the delay also allows us to test for the possibility that people may process one cue type more quickly than the other, for example, words may be processed more quickly because they are more familiar. Differences in verification performance for short delays may thus reflect an incomplete processing of the cue rather than a genuine difference in activation produced by the cue. For longer delays, however, verification time should reflect conceptual activation produced by the cue (e.g., <ref type="bibr" coords="3,143.66,210.81,99.11,7.91" target="#b56">Murphy &amp; Brownell, 1985;</ref><ref type="bibr" coords="3,245.05,210.81,42.99,7.91;3,48.00,221.96,208.69,7.91" target="#b78">Stadthagen-Gonzalez, Damian, Pérez, Bowers, &amp; Marín, 2009;</ref><ref type="bibr" coords="3,262.10,221.96,25.80,7.91;3,48.00,233.11,103.16,7.91" target="#b102">Yuval-Greenberg, &amp; Deouell, 2009</ref>, for similar reasoning).</p><p>If conceptual representations activated by verbal and nonverbal cues are genuinely different, then difference in verification performance should persist, even for longer delays. The cue difference should be observed for both matching and mismatching trials because the information activated by the cue is useful both for accepting a match object and for rejecting a mismatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. A total of 43 University of Pennsylvania undergraduates volunteered in the experiments in exchange for course credit: 18 in Experiment 1A, 15 in Experiment 1B, and 10 in Experiment 1C.</p><p>Materials. We selected 10 objects that were easily nameable and had characteristic sounds <ref type="bibr" coords="3,156.13,403.03,131.91,7.91;3,48.00,414.18,112.50,7.91">(cat, car, dog, frog, gun, motorcycle, rooster, train, cow, and whistle)</ref>. Each category was instantiated by five images: normed color drawings <ref type="bibr" coords="3,184.33,425.32,99.85,7.91" target="#b70">(Rossion &amp; Pourtois, 2004)</ref>, three photographs obtained from online image collections, and one cartoon image (see Figures S1 and S2 in the supplemental materials). We used several instances of each category to introduce visual heterogeneity. Spoken labels were all basic-level names. The nonverbal cues were animal sounds for the animals in the set and characteristic sounds for the artifacts in the set (e.g., a gun firing, the sound of a whistle). These sounds were obtained from online environmental sound libraries and are available for download (see Appendix).</p><p>All auditory stimulus sounds were volume normalized. We also equated the length of the label and sound cues for each category (i.e., the barking sound and the word "dog" were of identical durations). Two of the nonverbal sounds-the sound of a starting car, and the sound of a train-were difficult to recognize when presented at durations that matched the words "car" and "train." We therefore replaced the label cues for these categories with the longer (but less common) labels "automobile" and "locomotive," respectively (in Experiment 2, we used revised car and train, enabling the words "car" and "train" to be matched for length, and obtained results similar to the present studies).</p><p>In order to ensure that the sounds were (a) easily recognizable and (b) of comparable predictive power of the target category, we conducted two norming experiments that are described in detail in the Appendix. These results indicated that (with the possible exception of one item) the sound cues were easily recognizable and were of comparable predictive power as the cues.</p><p>Procedure. On each trial, participants heard a cue-a verbal label or a nonverbal sound-followed by a picture. The picture matched the cue 50% of the time. On the nonmatching trials, the picture was randomly selected among the nonmatching images. Participants responded by pressing a match or does not match key on a keyboard. Immediately following their response, auditory feedback in the form of a buzz or bleep indicated whether the response was correct. All factors were within-subjects and each participant completed 400 verification trials: 10 Categories ϫ 5 Category Exemplars ϫ 2 Levels of Congruence ϫ 2 Cue-Types (sound vs. label) ϫ 2 Repeats.</p><p>Experiments 1A-1C differed in just one respect: In Experiment 1A, the delay between cue offset and target picture onset was 400 ms. We refer to this as the ISI (interstimulus interval) from here onward. Note that because of differences in cue length between categories, it is timed from cue offset to picture onset. In Experiment 1B, it was increased to 1 s-a common delay used in verification tasks <ref type="bibr" coords="3,372.74,264.03,127.72,7.91" target="#b78">(Stadthagen-Gonzalez et al., 2009)</ref>. In Experiment 1C, the delay was increased further to 1.5 s. By repeating Experiment 1A with a longer delay, we could test whether any label advantage found in Experiment 1A arose from incomplete processing of the cue. By increasing the delay, we could ensure that the cue was sufficiently processed by the time the picture appeared. Thus, we could be sure that the verification reaction times (RTs) (the principal dependent measure) were determined by the time it took to recognize the picture rather than reflecting the residual processing of the label or sound cue <ref type="bibr" coords="3,524.56,363.03,17.19,7.91;3,306.00,374.03,85.73,7.91" target="#b56">(Murphy &amp; Brownell, 1985;</ref><ref type="bibr" coords="3,394.73,374.03,122.83,7.91" target="#b78">Stadthagen-Gonzalez et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Mean latencies for Experiments 1A-1C are shown in <ref type="figure" coords="3,517.98,418.04,28.07,7.91;3,306.00,429.04,24.50,7.91" target="#fig_0">Figures  1A-1C</ref>; latency and accuracy means are also presented in <ref type="table" coords="3,524.85,429.04,21.21,7.91;3,306.00,440.04,3.46,7.91" target="#tab_0">Table  1</ref>. The data were analyzed with a 2 (label or sound) ϫ 2 (match or mismatch) within-subjects analysis of variance (ANOVA). RTs less than 200 ms or greater than 1,500 ms were excluded. An analysis of correct RTs from Experiment 1A revealed a highly reliable matching advantage, F(1, 17) ϭ 35.72, p Ͻ .0005, and a strong advantage for label trials, F(1, 17) ϭ 24.77, p Ͻ .0005. In a subsequent analysis, we added category as a fixed factor and observed a highly reliable Cue-Type ϫ Picture Category interaction for RTs, F(9, 153) ϭ 2.7, p ϭ .005. That is, responses to all items were facilitated by the label, relative to nonverbal sound cue, but to different degrees. We explore this in more detail below.</p><p>The label advantage was also observed in accuracy, F(1, 17) ϭ 6.38, p ϭ .02. The label advantage was highly consistent. Of the 18 participants, 16 had shorter RTs on the label than on sound trials, and 11 had higher accuracy (of the remaining seven, three had equal performance in the two conditions). The label advantage was also reliable in an item-based analysis-RTs: F 2 (1, 9) ϭ 5.89, p ϭ .038, accuracy: F 2 (1, 9) ϭ 8.93, p ϭ .015. Experiment 1B likewise revealed a match advantage for RTs, F(1, 14) ϭ 20.80, p Ͻ .0005, and a strong label advantage, F(1, 14) ϭ 26.80, p Ͻ .0005. Every participant showed this label advantage. The label advantage was also observed in accuracy, F(1, 14) ϭ 13.11, p ϭ .003. There were no significant Cue-Type ϫ Picture Category interactions for RTs or accuracy (Fs Ͻ 1).</p><p>Increasing the delay further to 1.5 s-Experiment 1Cproduced a similar pattern of results. There was again a match advantage in RTs, F(1, 9) ϭ 7.56, p ϭ .022, and a strong label advantage for both RTs, F(1, 9) ϭ 7.66, p ϭ .022, and accuracy, F(1, 9) ϭ 62.61, p Ͻ .0005. Seven out of the 10 participants showed the label advantage in latency, and all 10, in accuracy. There was a marginal Cue-Type ϫ Picture Category interaction, F(9, 81) ϭ 1.90, p ϭ .064, in the same direction as in Experiment 1A (see Experiments 1A-1C, Discussion, for clarification). The label advantage remained highly significant in an item-based analysis-RTs: F 2 (1, 9) ϭ 39.26, p Ͻ .0005, accuracy: F 2 (1, 9) ϭ 25.49, p ϭ .001. The RTs in this experiment were nonsignificantly longer than in Experiments 1A-1B, probably due to the greater uncertainty of target onset owing to the longer ISI.</p><p>The label advantage observed for the shortest ISI became larger for the longer ISIs, increasing from 25 ms to 47 ms and 49 ms for the 1 s and 1.5 s ISIs, respectively. There was no difference between the label advantages for the two longer ISIs (t Ͻ 1). We therefore pooled these data and compared the label advantage between the shortest ISI (Experiment 1A) with the two longer ISIs (Experiments 1B-1C). The advantage was significantly larger in Experiments 1B-1C, compared with Experiment 1A, t(37) ϭ 2.37, p ϭ .023.</p><p>It is conceivable that the advantage of labels is short-lived, owing its existence to the initial unfamiliarity of the sound cues. If so, the advantage should diminish or vanish with practice. We divided each participant's data into four equal blocks and ran an analysis of covariance with block as a covariate. Although participants became faster and more accurate over time (Fs Ͼ 10), there were no hints of an interaction between block and cue-type for either RT or accuracy in any of the three studies (Fs Ͻ 1). This is surprising, and we do not have a full explanation for this negative finding. However, combined with the norming results (see Appendix) it supports the interpretation that the label advantage is not due to differences in familiarity insofar as it does not change, even as participants become more familiar with the sound cues during the experiment. In Experiment 4, we test this interpretation more directly by training participants on objects with which they have no prior experience.</p><p>We now return to the Cue-Type ϫ Picture-Category interaction found in Experiment 1A, the experiment with the shortest cuetarget delay. To explore this effect further, we divided the pictures into two semantic categories, animals (n ϭ 5) and artifacts (n ϭ 5), and ran an ANOVA with matching, cue-type, and semantic category as within-subject factors. We found a reliable main effect of semantic category: Participants responded about 20 ms faster to animals than to artifacts, F(1, 17) ϭ 4.77, p ϭ .043. A separate analysis with accuracy as the dependent variable was congruent with the RT analysis, showing greater accuracy for the animal targets, F(1, 17) ϭ 10.07, p ϭ .006. There was also a reliable Cue-Type ϫ Semantic-Category interaction for RTs, F(1, 17) ϭ 12.37, p ϭ .003. Although label cues produced faster judgments to both animals and artifacts, the label advantage was larger for artifacts (M ϭ 42 ms) than for animals (M ϭ 18 ms).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Hearing a verbal label compared with a nonverbal sound afforded a faster and more accurate identification of a subsequent  picture. This label advantage is entirely unexpected, on the view that there is a single concept that is accessed by the verbal cues, the nonverbal cues, and the picture and that the match/no-match response is generated based on the activation of this common concept (e.g., <ref type="bibr" coords="5,88.76,121.04,115.52,7.91" target="#b24">Gleitman &amp; Papafragou, 2005;</ref><ref type="bibr" coords="5,208.04,121.04,66.00,7.91" target="#b33">Jackendoff, 2002;</ref><ref type="bibr" coords="5,277.80,121.04,10.25,7.91;5,48.00,132.04,91.82,7.91" target="#b40">Li, Dunham, &amp; Carey, 2009;</ref><ref type="bibr" coords="5,142.27,132.04,104.07,7.91" target="#b74">Snedeker &amp; Gleitman, 2004;</ref><ref type="bibr" coords="5,248.78,132.04,39.25,7.91;5,48.00,143.04,20.50,7.91" target="#b75">Snodgrass, 1984;</ref><ref type="bibr" coords="5,71.50,143.04,67.10,7.91" target="#b82">Vanderwart, 1984)</ref>. The label advantage not only held for a wide range of delays between the cue and the picture (ISIs) but actually increased with longer ISIs (compare <ref type="figure" coords="5,130.11,176.04,52.86,7.91" target="#fig_0">Figures 1A-1C</ref>). This finding further supports our claim that the label advantage does not arise from incomplete processing of the nonverbal cue. Moreover, if the only difference between the cuing conditions was the speed of activation, one would expect that the label advantage would diminish or disappear with an ISI as long as 1.5 s. That it did not, suggests to us that verbal labels do not simply activate conceptual representations faster but that representations activated via verbal cues are different in some way from representations activated via nonverbal means. An examination of correlations between RTs for the two cuing conditions and typicality ratings (see Further Analyses of Experiments 1A-1C: Effects of Typicality) provides further support for this claim.</p><p>Might the advantage arise from the label cues being more specific than the sound cues?</p><p>For example, one would not be surprised if a superordinate cue, such as "animal," led to slower verification RTs of pictures of dogs than a more specific cue, such as "dog" <ref type="bibr" coords="5,204.69,363.04,83.35,7.91;5,48.00,374.04,121.32,7.91" target="#b69">(Rosch, Mervis, Gray, Johnson, &amp; Boyes-Braem, 1976;</ref><ref type="bibr" coords="5,172.76,374.04,89.45,7.91" target="#b58">Murphy &amp; Smith, 1982)</ref>. Even allowing for the possibility that a sound of, for example, a barking dog is less uniquely associated with dogs than the word "dog"-an assumption not supported by the norming results-the task provided plenty of opportunities for associating the particular sound cue with a category. One would imagine that by the time one heard the identical barking sound for the 20th time, any doubt as to its referent would be eliminated (especially because participants received accuracy feedback for each trial). The argument that the difference in specificity/predictiveness was not the main driver of the label advantage is also supported by the finding that the label advantage was found even for the categories whose sound cues elicited, in a free response task, the target categories from almost all tested participants (see Appendix). The strong association between the sounds and the labels means that it was possible that the verbal labels were (perhaps automatically) activated in response to the sounds, for example, hearing a meowing sound, activated the word "cat." This possibility does not detract from the results but does make interpretation more complex. We return to this point in Experiment 4.</p><p>Last, we observed in Experiment 1A (and somewhat in Experiment 1C) that the label advantage was stronger for artifacts than for animals. The present work was not aimed at investigating differences between semantic categories, but we can speculate as to why there was a Cue-Type ϫ Semantic-Category interaction. <ref type="bibr" coords="5,48.00,649.03,146.95,7.91">Thompson-Schill and colleagues (1999)</ref> found that making judgments involving visual features of animals or artifacts activated the left fusiform gyrus, a cortical region associated with retrieval of visual information (e.g., <ref type="bibr" coords="5,137.68,682.03,84.81,7.91" target="#b12">D'Esposito et al., 1997)</ref>. Notably, the left fusiform gyrus was also activated by judgments involving nonvisual features for animals, but not artifacts. This suggests that as a whole, representations of living things are more grounded in visual features than are representations of artifacts (which may be organized more according to their function), an idea supported by neuropsychological and computational evidence <ref type="bibr" coords="5,481.37,99.03,60.40,7.91;5,306.00,110.03,41.62,7.91" target="#b20">(Farah &amp; McClelland, 1991;</ref><ref type="bibr" coords="5,350.99,110.03,109.22,7.91" target="#b86">Warrington &amp; Shallice, 1984)</ref>. The present task was one of visual identification. A correct response could only be made if participants processed the visual features of the target picture; preactivation of visual features by the cue is hypothesized to speed the response. Because representations of animals appear to be more grounded in visual information than do representations of artifacts, it is conceivable that a cue such as the crowing of a rooster activates the visual features of the rooster to a greater extent than, for example, a motorcycle engine sound activates the visual properties of a motorcycle. This results in a smaller label advantage for animals than for artifacts. Interestingly, although the size of the label advantage did not diminish with increasing cuetarget delays, the Cue-Type ϫ Semantic-Category interaction disappeared when a longer delay was used (Experiments 1B-1C).</p><p>There are many ideas about the differences between living things and artifacts beyond differential grounding in visual features, such as greater coherent covariation between perceptual aspects of living things and artifacts <ref type="bibr" coords="5,401.29,297.03,107.34,7.91" target="#b68">(Rogers &amp; McClelland, 2004)</ref>. Whether such distinctions capture the interaction we observed here between Cue-Type ϫ Semantic Category should be the subject of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>The results from Experiments 1A-1C suggest that labels activate conceptual information more effectively than familiar sounds. As outlined in <ref type="table" coords="5,358.73,393.04,25.94,7.91" target="#tab_1">Table 2</ref>, the verbal cues and nonverbal sounds differ in a number of ways. Labels are words, labels are used to refer to object categories, and labels have phonological forms that can be easily reproduced by a person. Nonverbal sounds have none of these properties. In Experiments 1A-1C, these differences were all conflated. This makes it unclear whether advantage is a referential label advantage or a word advantage, or even possibly, a speech advantage. Experiment 2 teases these apart by introducing two new cue-types (see <ref type="table" coords="5,361.95,481.04,27.23,7.91" target="#tab_1">Table 2</ref>). Verbs referring to characteristic sounds are words but do not refer to the object's category. Sound imitations (e.g., "arf-arf") constitute speech but are not conventional words; the degree to which they "refer" to the object's category is unclear. If the label advantage is simply an advantage of having a cue that is a word, we should observe equal performance in the label-noun and label-verb conditions. If the label advantage at least partially derives from a speech advantage, then sound-imitation cues should lead to faster RTs than do nonverbal sound cues. A finding that noun labels lead to better performance than all the other cues would support the hypothesis that it is the referential </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants.</head><p>A total of 20 University of Wisconsin-Madison undergraduates participated for course credit.</p><p>Materials. The materials partially overlapped with those used in Experiments 1A-1C but had to be altered to meet the requirements of this task, namely that each item needed to have not only a characteristic sound but also a characteristic verb that referred to the sound. In addition, each item had to have a sound that could be imitated by a person in a stereotypical way. We selected the following 10 items: car, cat, clock, cow, dog, frog, motorcycle, phone, rooster, and spring. Some example verbs and sound imitations were barking/arf-arf for a dog, revving/vroom-vroom for a motorcycle, and ticking/tick-tock for a clock. The full list of cues along with a download link is provided in the Appendix. The labels (both nouns and verbs) and sound imitations were produced by the same female native English speaker. For each item, the four cue-types were edited to have the exact same duration, and all sounds were volume normalized. To compensate for the addition of the new cue-types, we reduced the number of pictures per category from the five used in Experiments 1A-1C to two.</p><p>Procedure. Experiment 2 was identical to Experiment 1B, except for the addition of two additional cue-types (verbs and sound imitations). Participants were instructed that they should respond with "match" if the animal or object shown in the picture was associated with the word or sound preceding it. To familiarize the participants with the nature of the cues, the experiment began with 15 practice trials. Each participant completed 320 trials: 10 Categories ϫ 2 Picture per Category ϫ 2 Levels of Congruence ϫ 4 Cue-Types ϫ 2 Repeats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Mean latencies are shown in <ref type="figure" coords="6,164.91,478.04,29.76,7.91" target="#fig_1">Figure 2</ref>. The data were analyzed as in Experiments 1A-1C. We once again found a highly reliable matching advantage (M match ϭ 612 ms, M mismatch ϭ 661 ms), F(1, 39) ϭ 32.82, p Ͻ .0005, as well as an effect of cue-type, F(3, 39) ϭ 7.97, p Ͻ .0005. There was no reliable Matching ϫ Cue-Type interaction, F(3, 39) ϭ 2.23, p ϭ .10, and we collapsed matching and mismatching trials for the subsequent analyses. The label cues (606 ms) led to significantly faster RTs than did soundimitation cues (635 ms), t(13) ϭ 3.80, p ϭ .002, sound cues (636 ms), t(13) ϭ 2.31, p ϭ .038, and verb cues (664 ms), t(13) ϭ 4.77, p Ͻ .0005. The effect of cue type was likewise significant in an item-based analysis, F(3, 27) ϭ 14.45, p Ͻ .0005, with the label-cue trials being faster than the other three pooled RTs from the other cuing conditions, F(1, 9) ϭ 63.15, p Ͻ .0005. It is unclear why the label-verb condition led to such high RTs for matching trials.</p><p>In an additional analysis, we examined whether the difference between cue-types changed between the first half and the second half of the experiment. The interaction was not significant, F(3, 39) ϭ 1.73, p ϭ .18. A more targeted analysis comparing the differences between label cues and all other cues found no hint of the difference changing between the first half and the second half of the experiment, F(1, 13) ϭ 0.06.</p><p>For nine subjects, hearing a label as a cue led to faster RTs than hearing any of the other cues (p ϭ .002; exact binomial test; H 0 ϭ no effect of cue type). For comparison, the sound cues were the fastest condition for three participants, the verb cues were the fastest condition for one participant, and the sound-imitation cues were the fastest condition for one participant.</p><p>The average accuracy was 92.7%; there were no reliable differences in accuracy among the four cuing conditions (F Ͻ 1) and no evidence of a speed-accuracy tradeoff for the label-cue condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our aim in Experiment 2 was to examine whether the label advantage found in Experiments 1A-1C stemmed from a difference between the word status of label and sound cues or a difference in their referential status. We found that verbal category labels (e.g., "dog") led to faster verification RTs than did words labeling the characteristic sound (e.g., "barking") and nonword sound imitations (e.g., "arf-arf").</p><p>The much higher mean RTs for the verb condition relative to the other conditions may have partly been due to some verb labels being somewhat ambiguous (e.g., "revving" and "bouncing"). However, other verb labels were quite unambiguous. For example, in a free-response task of the type described in the Appendix, eight of eight participants typed dog in response to hearing the word "barking" and typed cat in response to the word "meowing"; seven of eight typed clock in response to "ticking," and six of eight typed phone in response to "ringing" (recall that in the experiment, participants received extensive exposure and accuracy feedback). In a repetition of the task with the sound imitation cues, the target category was the modal response for all the categories except "motorcycle."</p><p>Results from Experiment 2 suggest that the label advantage does not stem simply from a difference in word status of the cues. Nouns (words referring to the category of the pictured objects), but not verbs (words referring to a property of the pictured object) or sound imitations (quasireferential expressive terms), facilitated picture recognition relative to nonverbal cues. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 3A-3B</head><p>A limitation of using picture verification as a measure of conceptual processing is that making a verification response requires, by design, participants to explicitly compare the cue with the semantic category of the target. Thus, one might obtain faster verification responses due either to faster activation of the concept (as, for example, caused by a top-down activation of visual features by the label) or to a facilitated comparison process. That is, it may be easier to compare a picture and a verbal cue relative to a picture and a sound cue because the comparison process in both cases is mediated by the picture name. One way to tease apart these explanations, at least to some degree, is to use a task that greatly minimizes conceptual processing of the target images and a task in which the cue is entirely incidental to the task.</p><p>Experiments 3A-3B provide just such a task. Participants were asked to discriminate an upright image from an upside-down one. The task is similar to one used by <ref type="bibr" coords="7,179.70,262.37,98.01,7.91" target="#b65">Puri and Wojciulik (2008)</ref> to examine effects of general and specific cues on visual processing. Participants heard sound or label cues, as in Experiments 1A-1C, and were then presented with two side-by-side pictures of an identical object. One of these pictures was upside down. Participants had to report the side (left or right) of the upright object. The cues were either valid or invalid. Because responses were now entirely independent of the cue, we could include no-cue trials to serve as a baseline. This allowed us to measure the potential benefits of valid cues as well as potential costs of invalid cues. Note that the function of the cue here is somewhat different from its function in Experiments 1-2, in that it is now entirely incidental to the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. A total of 43 University of Pennsylvania undergraduates volunteered in the experiments in exchange for course credit: 18 in Experiment 3A and 25 in Experiment 3B.</p><p>Materials. The verbal and nonverbal sounds were identical to those in Experiments 1A-1C, except that one item (the motorcycle) was omitted. 2 All auditory cues were normalized to the same volume. In addition to the verbal and nonverbal cue, we created an uninformative cue consisting of white noise with a duration of the average sound-label cue. For the picture stimuli in Experiments 3A and 3B, we used a subset of the pictures in Experiments 1A-1C, with each category instantiated by a single picture from a set of normed colored pictures <ref type="bibr" coords="7,137.92,561.04,94.60,7.91" target="#b70">(Rossion &amp; Pourtois, 2004</ref>; see <ref type="figure" coords="7,252.73,561.04,35.32,7.91" target="#fig_1">Figure S2</ref> in supplemental materials).</p><p>Procedure. On each trial, participants saw for 200 ms two pictures presented simultaneously to the left and the right of a fixation cross. These pictures were identical except that one was upside down (flipped about the x-axis). The participants' task was simply to indicate which side of the screen contained the upright picture by pressing the Z key with their left index finger if it was the picture on the left and the / key (the slash key) with their right index finger if it was the picture on the right. It was stressed that it did not matter what object was shown in the picture. The pictures were preceded by an auditory cue. The trials were evenly divided into label cues, sound cues, and uninformative noise cues. The label and sound cues validly cued the upcoming picture on 80% of the trials. On the remaining 20%, the cue was invalid, for example, participants would hear "cow" or hear a mooing sound but then see a car. This allowed us to measure the advantage of a valid cue relative to a noise cue (Are people faster to locate the upright cow after hearing "cow"/a mooing sound?), the cost of an invalid cue relative to a noise cue baseline, and, critically, a comparison of these benefits and costs for label versus sound cues. Unlike Experiment 1, in which the participant could not respond without attending to the cue, in the present experiment, one could achieve 100% accuracy while completely ignoring the cues. Setting the validity proportion to 80% provided an implicit signal that the cues should be attended.</p><p>Experiments 3A and 3B were identical except for the delay between the offset of the cue and the onset of the pictures. In Experiment 3A, the delay was 400 ms. In Experiment 3B, it was lengthened to 1 s to determine whether the results observed in Experiment 3A were due to insufficient time to process the nonverbal sound. There were 20 practice and 300 experimental trials in each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Mean latencies are shown in <ref type="figure" coords="7,421.46,314.04,29.47,7.91" target="#fig_2">Figure 3</ref>. Latencies were analyzed with a repeated-measures ANOVA followed by planned comparisons. The first analysis included validity and cue-type (sound vs. label) as within-subject fixed factors (validity is undefined for noise cue trials). We found a highly reliable effect of validity, with valid trials being reliably faster than invalid trials, F(1, 17) ϭ 39.72, p Ͻ .0005. We also found a significant Validity ϫ Cue-Type interaction, with label cues showing a larger cuing effect than sound cues, F(1, 17) ϭ 8.23, p ϭ .011. Relative to the no-cue baseline, valid sound cues improved performance, t(17) ϭ 2.84, p ϭ .03. Label cues also improved performance, t(17) ϭ 5.01, p Ͻ .0005, but importantly, this improvement was significantly greater than the improvement due to sounds, t(17) ϭ 2.93, p ϭ .009. Relative to the no-cue baseline, invalid label cues significantly slowed responses, t(17) ϭ 4.38, p Ͻ .0005; sounds cues did not, t(17) ϭ 1.19, p Ͼ .2. The effect of invalid cues differed reliably between cuing conditions: invalid labels hurt performance more than invalid sounds did, t(17) ϭ 2.12, p ϭ .048. Accuracy was very high (M ϭ 97.8%) and did not vary reliably between any of the conditions (ps Ͼ .5).</p><p>Did the label advantage result from a lack of time to process the sound cue? This was unlikely, given the results of Experiments 1B and 1C, but nevertheless, we conducted a replication of Experiment 3A with a longer (1 s) delay between cue offset and picture onset. There was, once again, a highly reliable validity effect, F(1, 24) ϭ 8.41, p ϭ .008. The Cue-Type ϫ Validity interaction was marginally significant, F(1, 24) ϭ 4.26, p ϭ .05. As shown in <ref type="figure" coords="7,306.00,611.04,37.03,7.91" target="#fig_2">Figure 3B</ref>, valid labels led to reliably faster RTs relative to baseline, t(24) ϭ 2.45, p ϭ .022, whereas sounds did not, t(24) ϭ 1.13, p Ͼ .2, though valid labels and sounds lowered RTs by a similar degree. As in Experiment 3A, invalid cues resulted in slower responses relative to the baseline, though with the longer ISI, both label cues, t(24) ϭ 4.90, p Ͻ .0005, and sound cues, t(24) ϭ 3.14, p ϭ .004, increased the RTs. Importantly, the RT cost of invalid label cues was greater than that for invalid sound cues, t(24) ϭ 2.22, p ϭ .036. Accuracy was very high (M ϭ 98.0%) and did not vary reliably between any of the conditions, ps Ͼ .5. In sum, in both Experiments 3A and 3B, labels continued to function as more effective cues than nonverbal sounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Experiments 3A-3B showed that auditory cues facilitate judgments of images that are congruent with the cues and slow down judgments of images that are incongruent with the cues. Critically, verbal cues produce substantially greater validity/invalidity effects relative to uninformative cues than do nonverbal cues. Because in these experiments the cue was entirely incidental to the task-that is, the response was independent of the cue-the observed pattern is consistent with our claim that verbal cues are particularly effective in activating at least the visual components of the conceptual representation.</p><p>Despite the qualitative similarity of the results in Experiments 3A and 3B-a greater effect of label cues relative to sound cues-there was suggestive evidence that increasing the ISI from 400 ms to 1 s had some effect. The longer ISI increased the effectiveness of invalid cues, with sound cues now having a significant negative impact on RTs relative to the no-cue baseline (though still a significantly smaller impact than invalid label cues). An additional departure from Experiment 3A was that although valid label cues significantly decreased RTs and valid sound cues did not, the two valid conditions did not differ from each other. The effect of increasing the ISI suggests that cues processed for a longer time are more effective (though note that they do not lead to faster RTs overall). Having a longer time in which to "commit" to a particular category appears to more significantly impair per-ceptual judgments involving nonmatching categories. It is possible that an increase in the effectiveness of sound cues was a form of verbal mediation, with the longer ISI allowing sufficient time for the activation of the verbal label in response to the sound cue (cf. Experiment 4).</p><p>Although the present task did not require participants to identify the target image, it is likely that participants identified the target images (i.e., they knew that the image on the left was of an upside-down cow and not just something that was upside down). This does not detract from the present finding because the response the participants needed to make was completely independent of the category. Participants did not need to hear a cue of any kind to make a response (indeed, accuracy was no lower in the uninformative cue condition than in other conditions).</p><p>The results from Experiments 3A-3B are consistent with our claim that labels activate visual information more effectively than do nonverbal cues and speak to the broader claim that the representations activated by verbal means (via a noun label) are not identical to representations activated by nonverbal means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 4</head><p>Experiments 1-3 have examined the effects of words and sounds on the visual processing of objects with which participants have had extensive prior experience. We had no control over this prior experience, making it difficult to know, for instance, whether the label advantage derives simply from differences in the quantity of experience with nouns compared with other cues-verbal and nonverbal. If true, the effects we are seeing may be different manifestations of familiarity making the rather mundane point that more familiar cues are more effective cues. (see <ref type="bibr" coords="8,382.57,418.04,94.76,7.91" target="#b50">Lupyan &amp; Spivey, 2010b</ref>, for an argument that many effects of familiarity are actually effects of meaningfulness). Additionally, although the norming data leads one to argue against the possibility that the label advantage occurs because sound cues are systematically less specific or predictive of the target category than are the label cues, it is difficult to fully eliminate this possibility with norming.</p><p>This experiment tests the hypothesis that verbal cues activate conceptual information differently from nonverbal cues even when (a) the concepts are newly acquired and when (b) the experience with verbal and nonverbal cues is fully equated. Our goal in Experiment 4 was to test the hypothesis that verbal cues will activate conceptual information more effectively than will nonverbal cues when both conditions above are met. In this experiment, participants learned either verbal labels or nonverbal sounds with six novel categories. Example items are shown in <ref type="figure" coords="8,317.85,594.04,32.53,7.91" target="#fig_3">Figure 4</ref>. This design had the advantage of equating the learning opportunities between the cues and their visual referents and measuring the degree to which participants are able to learn the picture-label versus picture-sound associations. Because individuals in the sound group never learned the corresponding labels (i.e., cue-type was now a between-subjects factor), there was no opportunity for the sound group participants to label the sound with its corresponding name, as was possible in Experiment 3A (as well as in Experiments 1-2). That is, with familiar categories, hearing a meowing sound can activate the verbal label ("cat"). This is not possible in the present study because participants in the sound condition have no names for the objects. A finding of a label advantage in this context would further strengthen the conclusion that wordseven those just learned-have a special power to activate visual features (partly) constitutive of the object concept.</p><p>After being trained to associate these objects with either novel auditory labels or novel sounds, participants performed a speeded orientation judgment task identical to Experiment 3B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. A total of 20 University of Pennsylvania undergraduates volunteered in the experiment in exchange for course credit.</p><p>Materials. The training set consisted of six categories of novel three-dimensional objects shown on a computer screen (see <ref type="figure" coords="9,48.00,473.04,30.69,7.91" target="#fig_3">Figure 4</ref>). There were three variants of each object to increase visual heterogeneity. These variants involved changes in viewpoint and slight changes in feature configuration. Each category was paired with a novel label (shonk, whelph, scaif, crelch, foove, and streil). Each of these nonce words was designed to have approximately equal bigram and trigram statistics and similar real-world lexical neighborhoods. We also created six nonverbal sounds, one for each category. These were created by splicing and editing environmental and animal sounds to create six sounds that were not readily nameable, as judged by pilot testing. The sounds may be downloaded from http://sapir.psych.wisc.edu/stimuli/ labelsSoundsExp4.zip Procedure. Participants were randomly assigned to either the label group or the sound group to form two groups of equal size (n ϭ 10). The experimenter told participants a cover story about the task, explaining that they would see some alien musical instruments and animals and would be asked to learn what sounds they make (sound group) or what they are called (label group). <ref type="bibr" coords="9,284.54,658.61,3.50,4.83">3</ref> The experiment had three parts, presented one after the other. In the first part (pretraining), participants passively viewed all the 12 trials during which all three exemplars of each category were presented together with a recording, e.g., "These are all shonks" (for the label condition) or "These all make the sound ___" (for the sound condition). Part 2 consisted of a verification-with-feedback task. Participants saw two exemplars from different categories followed by a prompt, for example, "Which one's the streil?" or "Which one makes the sound ___" and had to select whether the left or right stimulus matched. There were 180 verification-withfeedback trials. All verbal and sound cues were presented only auditorily.</p><p>The last part of Experiment 4 was a replication of Experiment 3B, but now with the newly learned novel stimuli. As in Experiment 3B, participants had to judge whether the left or right picture was upright (i.e., in the familiar orientation) after hearing one of the newly learned nonverbal sounds or labels. The images were presented for 200 ms after a 1 s delay following the offset of the cue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Participants were highly adept at learning the six categories. After pretraining-just two exposures to each categoryparticipants performed the verification-with-feedback task with ϳ95% accuracy. The label group was slightly less accurate and slower than the sound group (ps ϭ .08; ANOVA with condition as a between-subjects variable); there were no Reliable Condition ϫ Block interactions. By Block 5, both groups were performing at 99% (see <ref type="figure" coords="9,342.07,348.04,35.55,7.91" target="#fig_2">Figure S3</ref> in the supplemental materials), demonstrating that participants were able to learn both labels and nonverbal cue-to-picture, equally quickly, with a slight advantage for learning to associate novel objects with nonverbal sounds.</p><p>The critical part of the experiment was the subsequent orientation judgment task. Having ruled out differences in familiarity and association strength between labels and sounds, would labels continue to evoke visual activations in a more robust way than sounds? Indeed, that is what we found. As shown in <ref type="figure" coords="9,493.66,436.41,28.94,7.91">Figure 5</ref>, there was a significant validity advantage (M valid ϭ 400 ms, M invalid ϭ 443 ms), F(1, 18) ϭ 49.55, p Ͻ .0005, and this validity advantage was significantly larger for labels (M ϭ 59 ms) than sound cues (28 ms), F(1, 18) ϭ 6.14, p ϭ .023. The valid cue also reduced RTs relative to the uninformative noise cue, F(1, 18) ϭ 38.34, p Ͻ .0005, and this benefit also was larger for the label (M ϭ 51 ms) than for the sound trials (M ϭ 22 ms), F(1, 18) ϭ 10.73, p ϭ .004. Finally, there was a significant cost of hearing an invalid cue relative to not hearing a cue, F(1, 18) ϭ 8.08, p ϭ .011. The pattern was a qualitative match to that observed in Experiment 3, but in the present case, the cost due to invalid labels was not reliably greater than the cost due to invalid sounds (F Ͻ 1). Examining the effects of invalid versus no-cue trials separately for sound and label groups revealed marginally slower RTs in the invalid-cue condition, labels: t(9) ϭ 2.25, p ϭ .051; sounds, t(9) ϭ 2.00, p ϭ .076 (see <ref type="figure" coords="9,381.21,612.97,29.74,7.91">Figure 5</ref>).</p><p>An identical pattern of results was found when we repeated the analyses using RT proportions (e.g., RT invalid /RT valid ) instead of RT differences. There were no reliable effects of cues on accuracy (F Ͻ 1).</p><p>The two groups did not differ in overall response times, M label ϭ 433 ms, M sound ϭ 389 ms, F(1, 18) ϭ 1.70, p Ͼ .2, or accuracy, M label ϭ 96.4%, M sound ϭ 95.7%, F Ͻ 1. There were also no reliable effects of validity on accuracy, F(1, 18) ϭ 2.04, p ϭ .17.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In Experiment 4, we had complete control over participants' exposure to all the materials. We could thereby ensure that participants were equally familiar with verbal and nonverbal cues and had equivalent experience associating the two with their referents. Indeed, participants were equally proficient in learning to associate the novel categories with labels and sounds. Given this equivalence, we could then ask whether labels still had an advantage in activating visual information. A positive finding would indicate that one cannot account for the label advantage simply through differences in cue strength/familiarity. After only about 10 min of training (pretraining plus the category verification-with-feedback task), hearing a label or sound facilitated a visual judgment, as revealed by an RT advantage on valid trials and an RT cost on invalid trials. This in itself is quite remarkable. Critically for our thesis, the label cues were more reliable in activating the concept than were the sound cues, as measured by stronger cuing effects of labels relative to sounds. This result confirms that even when familiarity and type of experience with verbal and nonverbal associates are strictly equated, verbal cues activate the associated concept more effectively than nonverbal cues. How is this possible? One general answer is that participants in our studies brought with them a lifetime of experience with language. This experience is not limited to already familiar words and includes knowledge about the type of relation words have with the objects/categories they denote. This prior experience is brought to bear on learning novel categories (this idea is explored computationally by <ref type="bibr" coords="10,182.96,640.03,94.60,7.91" target="#b66">Rakison &amp; Lupyan, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Further Analyses of Experiments 1A-1C: Effects of Typicality</head><p>Our original goal in the present work was to ask the basic question of whether concepts activated via verbal means differ in some way from those activated via nonverbal means. The reliable difference in accuracy and RTs provide one type of evidence for difference between conceptual representations cued by verbal and nonverbal means. In this section, we provide additional evidence that the differences between the label and the sound conditions in Experiments 1A-1C are not simply differences in speed in activating a putatively common representation but rather are that the two cues produce representations that actually diverge over time.</p><p>In assembling the pictorial materials of Experiments 1A-1C, we collected typicality ratings for each picture by asking a separate group of 15 participants from the university participant pool to rate the typicality of each picture relative to the category referred to by the label. Participants saw each of the 50 pictures used in Experiments 1A-1C and responded to the prompt, "How typical is this picture of the text label below it?" using a Likert scale (1 ϭ very atypical; 5 ϭ very typical).</p><p>Not surprisingly, picture identification times were correlated with the rated typicality of the pictures: people were faster to recognize more typical pictures. The correlation coefficients for Experiments 1A-1C were, respectively, r ϭ Ϫ.32, p ϭ .024; r ϭ Ϫ.14, p ϭ .32, and r ϭ Ϫ.44, p ϭ .002. The corresponding b values were Ϫ15 ms, Ϫ10 ms, and Ϫ31 ms. <ref type="bibr" coords="10,471.18,297.61,3.50,4.83">4</ref> Importantly, as shown in <ref type="figure" coords="10,407.56,310.13,29.33,7.91">Figure 6</ref>, the relation between typicality and recognition times appeared to depend on how the concept was cued. Across all three studies, the relation between typicality and RTs was numerically stronger (i.e., had a more negative slope) for label-cue trials compared with sound-cue trials.</p><p>Collapsing across the three experiments (by averaging the mean RTs for each picture across the three experiments, cued by either the sound or the label), we found that the label advantage was reliably stronger for the more typical items (i.e., hearing the labels induced a steeper typicality gradient), F(1, 47) ϭ 4.51, p ϭ .039.</p><p>To test the hypothesis that the association between label advantage and typicality varied as a function of ISI, we ran a general linear model predicting the difference between label and sound conditions from the ISI and typicality ratings. The model showed a reliable interaction between typicality and ISI (b ϭ .047, t ϭ 2.2, p ϭ .028; outliers, identified as items having standardized Cook's distances Ͼ3.5 SDs, were excluded from the analysis): The effect of typicality on the label advantage increased with increasing ISI.</p><p>Analyzing the three experiments separately, this effect did not reach significance for Experiments 1A and 1B. With the longer ISI of Experiment 1C, the difference between effects of typicality on RTs between sound and label trials became reliable, F(1, 47) ϭ 8.79, p ϭ .005. This difference also means that the label advantage was significantly correlated with typicality (r ϭ .40, p ϭ .005): The label advantage was largest for the more typical, compared with less typical, exemplars. Thus, at least with a longer ISI, label cues induced a steeper typicality gradient than did sound cues (see <ref type="figure" coords="10,306.00,609.58,30.08,7.91">Figure 6</ref>, right). The analysis above supports the idea that labels activate more typical representations of the cued category than do nonverbal cues and is consistent with a number of other reports showing that effects of verbal labels on memory and basic visual processing is strongly modulated by typicality <ref type="bibr" coords="10,484.61,653.95,57.30,7.91" target="#b45">(Lupyan, 2007b</ref><ref type="bibr" coords="10,306.00,665.04,20.21,7.91" target="#b46">(Lupyan, , 2008a</ref><ref type="bibr" coords="10,333.24,665.04,19.82,7.91" target="#b47">(Lupyan, , 2008b</ref>. <ref type="figure" coords="10,48.00,190.50,27.80,6.86">Figure 5</ref>. Results of Experiment 4. Error bars show Ϯ1 standard error (SE) of the difference from the cuing to the no-cue condition from the label (L) or sound (s) group. Mean differences marked "-" are marginally significant (.08 Ͼ p Ͼ .05). ‫ء‬ p Ͻ .05 (condition difference). ‫ءء‬ p Ͻ .001 (condition difference).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In acquiring language, humans master an elaborate system of conventions, learning that certain sequences of sounds that denote categories of objects, relations, types of motion, emotions, and so on. With this system of associations in place, a concept can be activated simply by hearing the appropriate word-arguably the dominant function of language. In this work we asked whether conceptual representations are activated differently via verbal means and nonverbal means. An affirmative finding has important consequences for not only the understanding of the relation between language and other cognitive processes but also for understanding how conceptual information is brought to bear on a given situation.</p><p>Experiments 1A-1C comprised picture identification tasks in which participants heard a word (e.g., "dog") or a characteristic sound (e.g., barking) and made a match/no-match response to a picture appearing after a varying delay. Verbal labels were more effective at activating the concept, as evidenced by consistently shorter RTs on the label, compared with sound trials. A subsequent analysis of the data provided preliminary evidence that labels instantiated conceptual representations corresponding to more typical category exemplars and representations that were more similar across participants. Experiment 2 contrasted labels referring to the objects/animals with other types of verbal cues (see <ref type="table" coords="11,239.85,561.04,26.48,7.91" target="#tab_1">Table 2</ref>). We found that referential words resulted in faster identification times than did all other cues (e.g., faster than speech utterances associated with the category). Experiments 3A-3B extended these findings to a simple, visual minimally semantic task in which participants had to discriminate a normal exemplar from an upside-down one. Relative to baseline and to sound cues, valid label cues facilitated performance; invalid label cues hurt performance. Experiment 4 showed that the label advantage found in Experiment 3 holds not only for familiar stimuli but, in fact, emerges quickly with novel stimuli, the visual forms of which are activated more quickly by newly learned verbal labels than are equally welllearned sounds.</p><p>The finding that both highly familiar categories (e.g., dogs, cats, and cars) and newly learned categories can be activated more effectively by labels than by sounds, even a full 1.5 s after cue offset, hints at the powerful effects of language on the activation of at least the visual components of the conceptual representation and shows that at least temporarily, the representation of "dog" that is activated by hearing the category name is not the same as that activated by hearing a barking sound. These findings contradict the idea that language simply accesses nonverbal concepts (e.g., <ref type="bibr" coords="11,525.04,143.03,17.50,7.91;11,306.00,154.03,101.43,7.91" target="#b24">Gleitman &amp; Papafragou, 2005;</ref><ref type="bibr" coords="11,412.49,154.03,67.30,7.91" target="#b33">Jackendoff, 2002;</ref><ref type="bibr" coords="11,484.85,154.03,61.19,7.91" target="#b40">Li et al., 2009;</ref><ref type="bibr" coords="11,306.00,165.03,104.38,7.91" target="#b74">Snedeker &amp; Gleitman, 2004;</ref><ref type="bibr" coords="11,412.92,165.03,62.30,7.91" target="#b75">Snodgrass, 1984;</ref><ref type="bibr" coords="11,477.76,165.03,68.27,7.91" target="#b82">Vanderwart, 1984)</ref> because presumably such concepts should have been accessed in the same way by equally informative and predictive nonverbal cues.</p><p>The analysis of typicality in Experiments 1A-1C suggest that not only are conceptual representations activated more quickly by verbal cues but that they are different, diverging over longer delays between the cue and the target, with representations activated by labels providing a better match to typical category exemplars.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance of the Present Work to Understanding the Relation Between Language and Thought</head><p>Much has been written on the subject of how learning and using language might supplement or augment our cognition and perception (see <ref type="bibr" coords="11,339.68,330.04,75.44,7.91">Boroditsky, in press;</ref><ref type="bibr" coords="11,417.70,330.04,61.84,7.91" target="#b7">Casasanto, 2008;</ref><ref type="bibr" coords="11,482.13,330.04,63.92,7.91;11,306.00,341.04,16.20,7.91">Wolff &amp; Holmes, 2010</ref>, for recent reviews). In most work investigating the relations among language, cognition, and perception, it has been assumed that verbal and nonverbal representations are fundamentally distinct and that the goal of the "language and thought" research program is to understand whether and how linguistic representations affect nonlinguistic representations <ref type="bibr" coords="11,454.39,396.04,87.79,7.91" target="#b94">(Wolff &amp; Holmes, 2011)</ref>. This assumption is problematic for a number of reasons, with the primary one being that it is impossible to determine a priori whether a particular representation is verbal.</p><p>Despite the inherent difficulty with distinguishing verbal and nonverbal representations, practically all language-and-thought debate has taken place under the assumption that information communicated or encoded via language comprises what is essentially a "verbal" modality-the notion at the core of dual coding theory <ref type="bibr" coords="11,306.00,495.04,50.56,7.91" target="#b60">(Paivio, 1986)</ref>. On this account, the reason why a verbal cue and a nonverbal cue can lead to a different representations is that verbal and nonverbal representations are distinct and processed separately, being combined at some higher level (e.g., <ref type="bibr" coords="11,509.05,528.04,36.99,7.91;11,306.00,539.04,64.20,7.91" target="#b13">Dessalegn &amp; Landau, 2008;</ref><ref type="bibr" coords="11,373.93,539.04,172.12,7.91" target="#b54">Mitterer, Horschig, Musseler, &amp; Majid, 2009;</ref><ref type="bibr" coords="11,306.00,550.04,154.12,7.91" target="#b62">Pilling, Wiggett, Ozgen, &amp; Davies, 2003;</ref><ref type="bibr" coords="11,463.34,550.04,82.69,7.91;11,306.00,561.04,19.37,7.91" target="#b67">Roberson &amp; Davidoff, 2000)</ref>. Indeed, the very use of terms such as "verbal" and "nonverbal" representations (e.g., <ref type="bibr" coords="11,415.29,572.04,85.02,7.91">Wolff &amp; Holmes, 2010</ref>, for review and discussion) presupposes that they are separable.</p><p>On a sensorimotor view of concepts to which we subscribe, visual representations used to make the decisions in the present tasks are partly constitutive of the concept to which the label refers. The label does not constitute a verbal code for the concept. Rather, it is a cue <ref type="bibr" coords="11,380.15,638.04,49.63,7.91" target="#b16">(Elman, 2004</ref>) that modulates, among other things, ongoing perceptual processing. Thus, although it is useful to distinguish between a verbal and a nonverbal stimulus, the distinction between a verbal and a nonverbal representation may be moot.</p><p>A framework that naturally accommodates this account and the present findings is what Lupyan has called the label feedback hypothesis <ref type="bibr" coords="11,346.13,715.04,55.08,7.91" target="#b44">(Lupyan, 2007a</ref><ref type="bibr" coords="11,407.38,715.04,19.82,7.91" target="#b47">(Lupyan, , 2008b</ref>. According to this view, verbal <ref type="figure" coords="11,48.00,227.58,28.89,6.86">Figure 6</ref>. Effects of picture typicality on mean RT. For example, a coefficient of Ϫ10 indicates that for each 1 point increase in rated typicality, there is a 10 ms increase in the speed of correct identification. Error bars show Ϯ1 standard error of the coefficient estimate. RT ϭ reaction time; ISI ϭ interstimulus interval. labels, once activated, modulate ongoing perceptual processing. As a result, the dog that you see after hearing the word "dog" is, in a sense, not the same dog as the dog you see after hearing a barking sound or just thinking about dogs. This is not language voodoo: It is simply the consequence of the fact that visual representations involved in making even simple visual decisions are subject to substantial top-down modulations (e.g., <ref type="bibr" coords="12,198.05,143.04,89.99,7.91" target="#b21">Foxe &amp; Simpson, 2002;</ref><ref type="bibr" coords="12,48.00,154.04,109.81,7.91" target="#b38">Lamme &amp; Roelfsema, 2000)</ref>. Language is one form of such top-down modulation. Because the present experiments require visual decisions, modulation of visual representations induced by language would affect our dependent variables.</p><p>According to the label-feedback hypothesis, rather than trying to decide whether representation comprises a verbal or visual "code" <ref type="bibr" coords="12,48.00,220.04,103.46,7.91" target="#b13">(Dessalegn &amp; Landau, 2008)</ref>, one should aim to classify behavior on specific tasks as either being modulated by language, being modulated differently by different languages, or being truly independent of any experimental manipulations that can be termed linguistic. The present findings suggest that a concept activated via different means, for example, via an auditory verbal label or via nonverbal auditory information, is detectably different. Specifically, the visual aspects of a category (e.g., the shape of a dog) are more effectively activated after hearing a word rather than a nonverbal sound or a nonreferential word associated with the category.</p><p>Obviously, the concept of a dog is more than just its visual information. The present studies are limited to testing visual aspects of concepts (which we believe to be partly constitutive of the dog "concept"). Verbal cues can be used to elicit all sorts of representations including smells <ref type="bibr" coords="12,166.40,385.04,44.41,7.91" target="#b29">(Herz, 2000)</ref>, motor actions <ref type="bibr" coords="12,268.58,385.04,15.60,7.91;12,48.00,396.04,174.79,7.91" target="#b92">(Willems, Toni, Hagoort, &amp; Casasanto, 2009)</ref>, and emotions <ref type="bibr" coords="12,48.00,407.04,186.07,7.91" target="#b41">(Lindquist, Barrett, Bliss-Moreau, &amp; Russell, 2006)</ref>. It remains an open question whether the verbal modality provides an advantage (or a disadvantage) in eliciting nonvisual information, as well as what specific aspects of visual representations are most strongly evoked by verbal means (e.g., texture, shape, size, color).</p><p>It is informative that learning nouns and attention to shape are, at least in English, closely linked during language acquisition <ref type="bibr" coords="12,48.00,484.04,93.35,7.91" target="#b10">(Colunga &amp; Smith, 2005;</ref><ref type="bibr" coords="12,144.22,484.04,143.83,7.91;12,48.00,495.03,19.37,7.91" target="#b95">Woodward, Markman, &amp; Fitzsimmons, 1994)</ref>, suggesting that the label advantage observed in the present experiments may have to do with nouns selectively activating shape information. Although such a shape bias may contribute to the present results, we believe that it is overly limiting to focus on shape as a dimension selectively affected by verbal cues.</p><p>Lexicalization patterns differ dramatically between languages (e.g., <ref type="bibr" coords="12,68.67,561.03,94.04,7.91" target="#b3">Bowerman &amp; Choi, 2001;</ref><ref type="bibr" coords="12,165.14,561.03,92.54,7.91" target="#b19">Evans &amp; Levinson, 2009;</ref><ref type="bibr" coords="12,260.10,561.03,27.93,7.91;12,48.00,572.03,54.07,7.91" target="#b42">Lucy &amp; Gaskins, 2001;</ref><ref type="bibr" coords="12,104.39,572.03,179.77,7.91" target="#b51">Majid, Gullberg, van Staden, &amp; Bowerman, 2007)</ref>. The present results suggest that the consequence of activating a conceptual representation via verbal means may differ crosslinguistically according to the patterns of learned associations between words and their referents (e.g., <ref type="bibr" coords="12,191.66,616.03,96.39,7.91;12,48.00,627.03,60.26,7.91" target="#b32">Huettig, Chen, Bowerman, &amp; Majid, 2010)</ref>. Words may matter far more for conceptual representations than previously considered, in that some concepts may only attain sufficient "coherence" when activated by verbal means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Further Considerations</head><p>It has been long known that concepts activated in different contexts are different. For example the piano concept that is activated by reading about moving pianos is different from the concept activated by reading about playing pianos <ref type="bibr" coords="12,503.65,88.04,42.38,7.91;12,306.00,99.04,78.33,7.91" target="#b79">(Tabossi &amp; Johnson-Laird, 1980)</ref>. Similarly, findings that instantiations of eagles differ when reading about flying versus sitting eagles <ref type="bibr" coords="12,306.00,121.04,134.43,7.91" target="#b103">(Zwaan, Stanfield, &amp; Yaxley, 2002)</ref> also speak to the flexibility with which we deploy our semantic knowledge. The label advantage observed in the present studies was obtained without explicitly manipulating context or experimental task. In the present studies, although different aspects of the concept's meaning may have been activated by the verbal and nonverbal cues (that is partially our point), the task and the participants' goal was exactly the same on all trials. For example, in Experiments 3-4, participants were performing one extremely simple task: judging which side of the screen showed the upright of a picture.</p><p>A further question concerns the specificity of information evoked by verbal versus nonverbal means. On the one hand, language can be used to specify visual properties with a great degree of specificity. A sentence such as "The ranger saw the eagle in the sky" activates a representation of not just an eagle but an eagle with outstretched wings <ref type="bibr" coords="12,414.86,286.04,70.63,7.91" target="#b103">(Zwaan et al., 2002)</ref>. The hypothesis that sentence context actually modulates visual processing has recently received more direct support through a MEG study by Hirschfeld and colleagues <ref type="bibr" coords="12,410.31,319.04,135.59,7.91;12,306.00,330.04,19.37,7.91" target="#b30">(Hirschfeld, Zwitserlood, &amp; Dobel, 2010)</ref>.</p><p>On the other hand, in the absence of such rich context, concepts evoked through verbal means (of which perceptual images are a part) may be more categorical than concepts evoked through nonverbal means. For example, the concept evoked by the word "dog" may, in the absence of other information, correspond to a more prototypical exemplar of the category than the more idiosyncratic representation activated by other cues. The section on typicality effects provides some support for this claim: We found a significantly steeper typicality gradient in verification RTs following label cues, compared with sound cues. The difference in typicality gradients between label and sound conditions appeared to increase with longer ISIs, reaching significance for the longest (1,500 ms) ISI (Experiment 1C). This finding is consistent with the notion of verbal labels aligning category representations between individuals.</p><p>Whether an increase in the degree to which representations are categorical and/or typical is good depends on the task. Evoking a concept through verbal means may facilitate categorization <ref type="bibr" coords="12,522.57,528.03,19.57,7.91;12,306.00,539.03,39.98,7.91" target="#b8">(Casasola, 2005;</ref><ref type="bibr" coords="12,348.71,539.03,73.68,7.91" target="#b48">Lupyan et al., 2007;</ref><ref type="bibr" coords="12,425.12,539.03,85.93,7.91" target="#b59">Nazzi &amp; Gopnik, 2001;</ref><ref type="bibr" coords="12,513.78,539.03,32.26,7.91;12,306.00,550.03,73.07,7.91" target="#b63">Plunkett, Hu, &amp; Cohen, 2008)</ref>, enhance inference (e.g., <ref type="bibr" coords="12,474.43,550.03,67.12,7.91;12,306.00,561.03,41.35,7.91" target="#b98">Yamauchi &amp; Markman, 2000)</ref>, and enhance perceptual discriminability <ref type="bibr" coords="12,509.31,561.03,36.75,7.91;12,306.00,572.03,98.80,7.91" target="#b36">(Kikutani, Roberson, &amp; Hanley, 2008;</ref><ref type="bibr" coords="12,406.90,572.03,55.20,7.91" target="#b46">Lupyan, 2008a)</ref>. However, when highfidelity analogical representations are called for, as is the case in a within-category visual recognition task, representations modulated by verbal labels may prove detrimental <ref type="bibr" coords="12,458.42,605.03,60.35,7.91" target="#b47">(Lupyan, 2008b)</ref>. Likewise, the finding that labels facilitated the recognition of artifacts more than the recognition of animals in Experiment 1A might hinge on the task involving visual recognition. The effect of labels on animal versus artifact concepts may well be reversed in a task calling on attributes from other modalities.</p><p>The consequences of activating categorical representations may go far beyond visual tasks requiring recognizing or discrimination of category instances. For example, activation of concepts through verbal means may be critical in reasoning about generics, for example, dogs bark; he's a carrot eater (cf. he eats carrots <ref type="bibr" coords="12,512.01,715.03,3.37,7.91">;</ref><ref type="bibr" coords="12,517.58,715.03,28.49,7.91;13,48.00,77.04,54.59,7.91" target="#b22">Gelman &amp; Coley, 1991)</ref>. Categorical representations may also be crucial to reasoning about spatial relations such as "above" <ref type="bibr" coords="13,232.04,88.12,56.02,7.91;13,48.00,99.20,21.00,7.91" target="#b37">(Kosslyn et al., 1989)</ref> and for performing reasoning about relations: For instance, although naïve chimpanzees fail to group together instances of same versus different object pairs, they succeed after being taught to associate arbitrary tokens with instances of same and different relations-an experience that may facilitate forming categorical representations for instances of same versus different relations <ref type="bibr" coords="13,48.00,165.68,133.09,7.91" target="#b80">(Thompson, Oden, &amp; Boysen, 1997)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Special Status of Words: From Reference Versus Associations to Reference Via Associations</head><p>The present work suggests that words are not simply a "pointer" or a means to access a nonverbal concept. Rather, they provide a special way to activate the multimodal representation that constitutes the concept. We have argued that verbal labels activate conceptual information-the visual components, at least-(a) more quickly and accurately and (b) in a less idiosyncratic way. This finding is well captured by the label feedback hypothesis briefly described above <ref type="bibr" coords="13,137.12,305.48,55.99,7.91" target="#b44">(Lupyan, 2007a</ref><ref type="bibr" coords="13,200.20,305.48,19.82,7.91" target="#b47">(Lupyan, , 2008b</ref>, which proposes that labels are cues that modulate the trajectories of perceptuoconceptual representations. In this final section, we attempt to relate this way of thinking about the nature of verbal labels to the currently ongoing debate in the literature regarding the special status of words as referential entities.</p><p>A common claim in developmental psychology is that words are special because they are referential <ref type="bibr" coords="13,173.55,383.00,98.93,7.91" target="#b89">(Waxman &amp; Gelman, 2009;</ref><ref type="bibr" coords="13,275.15,383.00,12.90,7.91;13,48.00,394.07,18.64,7.91" target="#b96">Xu, 2002)</ref>. A considerable amount of work within the field has been done to investigate the degree to which infants expect words to refer to object kinds, object properties, and so on (e.g., <ref type="bibr" coords="13,221.82,416.21,66.22,7.91;13,48.00,427.27,19.80,7.91" target="#b10">Colunga &amp; Smith, 2005;</ref><ref type="bibr" coords="13,70.69,427.27,71.65,7.91" target="#b14">Dewar &amp; Xu, 2009;</ref><ref type="bibr" coords="13,145.23,427.27,56.37,7.91" target="#b87">Waxman, 1999;</ref><ref type="bibr" coords="13,204.49,427.27,36.08,7.91" target="#b97">Xu, 2003)</ref> and the consequences that learning and using words has on the categorization and inference process <ref type="bibr" coords="13,114.58,449.41,90.95,7.91" target="#b59">(Nazzi &amp; Gopnik, 2001;</ref><ref type="bibr" coords="13,209.82,449.41,78.22,7.91" target="#b63">Plunkett et al., 2008;</ref><ref type="bibr" coords="13,48.00,460.48,84.30,7.91" target="#b72">Sloutsky &amp; Fisher, 2001</ref><ref type="bibr" coords="13,161.13,460.48,83.14,7.91" target="#b90">Waxman &amp; Hall, 1993;</ref><ref type="bibr" coords="13,246.84,460.48,41.17,7.91;13,48.00,471.55,55.06,7.91" target="#b91">Waxman &amp; Markow, 1995;</ref><ref type="bibr" coords="13,106.65,471.55,88.21,7.91" target="#b100">Yoshida &amp; Smith, 2003)</ref>. This topic has been the subject of an ongoing debate between an associationist account in which words are features of the associated stimulus and an account in which words are special because they have referential powers (e.g., see <ref type="bibr" coords="13,61.78,515.82,136.13,7.91">Waxman &amp; Gelman, 2009, for review)</ref>.</p><p>We believe this dichotomy is a false one. There are indeed numerous reasons to reject simple associationist accounts of word learning and effects of words on concepts. For example, relying solely on the cue-to-picture associations learned during Experiment 4 fails to explain why labels relative to nonverbal sounds, despite being equally well-learned, are more effective cues. Clearly, accounting for the results of Experiment 4 requires that participants bring to bear on the task prior expectations about words.</p><p>The statement that words derive their powers from "reference" is an odd one. The fact that words refer is a property of language, not a mechanism for understanding interactions between language and thought. The idea that words are features of the entities to which they refer is also an odd one. It is useful descriptive shorthand to talk about bananas having features such as is edible, is yellow, and is curved. What makes these features useful is that objects that are not bananas possess some of them, and we can talk about two objects from different categories sharing a feature such as is yellow. But only bananas are "bananas." This makes direct comparisons of perceptual features and labels problematic (cf. <ref type="bibr" coords="13,306.00,88.05,87.74,7.91" target="#b73">Sloutsky &amp; Fisher, 2004</ref>).</p><p>An effect of word learning and word usage on concepts means that concepts activated in response to a word are systematically different than in response to various nonverbal or nonreferential cues. It is this phenomenon that we should try to understand. Word learning requires associating an arbitrary token (the word) with external entities (objects, object attributes, relations, types of motion, etc.). The learning of these word-to-world associations may make it possible to activate the referent in a more categorical way. That is, the representations become more invariant to withincategory differences and more sensitive to between-categories differences. In the present experiments this has the effect of facilitating visual recognition (Experiments 1-2) and facilitating locating the canonical (upright) object (Experiments 3-4). We believe this is accomplished through associationist mechanisms: Words are cues that activate perceptuo-conceptual representations. Our experience of treating words as referential, that is, "standing in" for real-world objects, enables verbal cues to activate these representations in a "special"-perhaps more categorical-way than is possible by nonverbal means. How this is accomplished vis-à-vis neural mechanisms is still a mystery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantifying the Familiarity and Predictiveness of Verbal and Nonverbal Cues</head><p>To quantify whether the nonverbal cues used in Experiments 1 and 3 (see <ref type="table" coords="16,88.82,352.04,32.77,7.91" target="#tab_0">Table A1</ref>) had high predictive power, we recruited 17 participants from the online service Mechanical Turk (www.mturk.com; see <ref type="bibr" coords="16,98.76,374.04,135.47,7.91" target="#b5">Buhrmester, Kwang, &amp; Gosling, 2011</ref>, for a detailed assessment) and presented them with the same nonverbal sounds used in the studies. Participants were asked to respond to the following prompt: "What object or animal typically produces this sound? Please respond using a single word in the singular."</p><p>The target label was the modal response for all 10 categories. Of the nontarget responses, only one was provided by more than a single person (two people wrote "jackhammer" for motorcycle). Across all categories, an average of 15.1 out of 17 participants (89%) responded with the target category after hearing the sound (we accepted withincategory answers such as shotgun for gun, "scooter" for motorcycle, "train whistle" for train, and "calf" for cow). Marking as errors responses that deviated in any way from the target labels, the mean number of participants providing the target label in response to the sound decreased, but only slightly: 14.2 out of 17 (84%).</p><p>The label advantage reported in Experiments 1A-1C was not driven by items with lower percentages of participants producing the target label in response to the sound cue. The item analysis in the text showing faster RTs following the label relative to sound cues held even for the six items, with agreement scores above 94%: Experiment 1, t(5) ϭ 3.81, p ϭ .013; Experiment 1B, t(5) ϭ 3.11, p ϭ .027, and marginal for Experiment 1C, t(5) ϭ 1.98, p ϭ .104, though the label advantage for the four items with 100% agreement was reliable, t(3) ϭ 4.19, p ϭ .025. For these same six items, in Experiment 3A, valid labels led to significantly faster responses than did valid sounds, t(5) ϭ 3.61, p ϭ .015 (all ps were two tailed).We did not conduct a parallel analysis for Experiment 3B because there was no reliable difference between valid label and valid sound cues.</p><p>The analysis above shows that the sound cues were highly informative and specific, but we sought to directly compare the informativeness of sound and label cues using a common task (it obviously does not make sense to repeat the task above with (Appendix continues) Note. All sounds can be downloaded from http://sapir.psych.wisc.edu/ stimuli/labelsSoundsExp1.zip a Participants answered the question "How well did the picture match the image you thought of?" using a 5-point Likert scale (1 ϭ did not match at all; 5 ϭ matched perfectly). b The motorcycle item was omitted from Experiments 3A-3B.</p><p>auditory labels). The common task we used was imagery concordance, following the procedure used by <ref type="bibr" coords="17,206.70,88.54,81.34,7.91;17,48.00,100.04,22.49,7.91" target="#b70">Rossion and Pourtois (2004)</ref>. Participants were told that they would hear sounds (labels) produced by (referring to) common objects and animals and that they should form an image. Separate groups of participants heard the sound or label cues and, 3 s after the offset, were shown one of the photographic exemplars of each category used in Experiments 1A-1C. The picture was displayed for 3 s. On each of the 10 trials (1 per category), participants responded to the question "How well did the picture match the image you thought of?" using a 5-point Likert scale (1 ϭ did not match at all; 5 ϭ matched perfectly). Before starting the task, participants were asked to imagine in their mind's eye the object or animal making the sound or named by the label and to enter a rating depending on how well the picture they imagined matched the picture shown.</p><p>We recruited 26 new participants from Mechanical Turk and assigned them to a label-concordance or sound-concordance condition (see <ref type="table" coords="17,65.50,284.05,31.18,7.91" target="#tab_1">Table A2</ref>). There were no overall differences in concordance ratings in either a subject-based, t(24) ϭ 1.23, p ϭ .23, or item-based analysis, t(9) ϭ 1.28, p ϭ .23. The item with the greatest difference between label and sound condition (z ϭ 2.7) was "gun" (M label concordance ϭ 4.38, M sound concordance ϭ 2.31). With this item excluded, the concordance between sounds and pictures was actually reliably greater than the concordance between the labels and the same pictures, t(8) ϭ 6.40, p Ͻ .0005. This difference was marginal in a subject-based analysis, t(24) ϭ 1.82, p ϭ .08.</p><p>These results provide evidence that at least in an explicit (and untimed) rating task, the sounds cues were no less predictive of the category than the labels. For 9 of the 10 pictures, participants in the sound condition actually provided higher matching ratings than did participants in the label condition.</p><p>Received June 15, 2011 Revision received June 15, 2011</p><p>Accepted June 15, 2011 Ⅲ </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,48.00,480.07,240.02,7.03;4,48.00,490.07,240.00,7.03;4,48.00,500.07,240.01,7.03;4,48.00,509.36,240.04,8.00;4,48.00,519.36,159.06,8.00"><head>Figure 1 .</head><label>1</label><figDesc>Verification times for the sound trials versus label trials. A: Experiment 1A. B: Experiment 1B. C: Experiment 1C. The auditory cue and the picture matched on match trials and mismatched on mismatch trials. Error bars show Ϯ1 standard error of the mean difference between label and sound conditions. RT ϭ reaction time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,48.00,695.69,240.03,7.03;6,48.00,704.99,240.03,8.00;6,48.00,714.99,196.83,8.00"><head>Figure 2 .</head><label>2</label><figDesc>Verification times for each condition of Experiment 2. Error bars show Ϯ1 standard error of the difference between the label-noun condition and the condition of interest. RT ϭ reaction time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,48.00,278.92,240.04,8.00;8,48.00,289.62,240.01,7.03;8,48.00,299.62,239.99,7.03;8,48.00,308.92,164.59,8.00;8,48.00,317.92,222.24,9.00"><head>Figure 3 .</head><label>3</label><figDesc>Results of Experiments 3A-3B. Error bars show Ϯ1 standard error of the difference between the no-cue (noise cue) condition and the condition closest to its mean. The mean of the noise cue trials is plotted twice for ease of comparison. Exp. ϭ experiment. ‫ء‬ p Ͻ .05 (condition difference). ‫ءء‬ p Ͻ .001 (condition difference).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,48.00,270.20,240.01,7.03;9,48.00,280.20,121.07,7.03"><head>Figure 4 .</head><label>4</label><figDesc>Materials used in the learning task for Experiment 3. Each category had two additional variants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,306.00,544.54,240.03,178.19"><head>Table 1</head><label>1</label><figDesc>Results From Experiments 1A-1C</figDesc><table coords="4,306.00,575.20,240.03,147.53">Experiment 
Trial type 
Sound cue latency 
Label cue latency 

1A 
Match 
610 (95.6) 
590 (97.2) 
Mismatch 
567 (94.8) 
536 (95.4) 
Mean 
589 (95.2) 
563 (96.3) 

1B 
Match 
625 (95.4) 
575 (97.6) 
Mismatch 
664 (96.5) 
620 (98.0) 
Mean 
645 (96.0) 
598 (97.8) 

1C 
Match 
678 (89.9) 
632 (96.0) 
Mismatch 
709 (94.4) 
657 (96.3) 
Mean 
694 (92.2) 
645 (96.2) 

Note. Latency means (ms) are outside the parentheses, and accuracy 
means (percentage correct) are inside the parentheses. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,306.00,626.54,239.51,91.20"><head>Table 2</head><label>2</label><figDesc>Cue Types, Word-Hood, and Referentiality status of labels that is responsible for the effect (the idea of referentiality is discussed in more detail in the General Discussion).</figDesc><table coords="5,306.00,657.20,239.51,60.53">Cue type 

Is the cue 
a word? 

Is the cue produced 
by a human? 

Does the cue refer to 
the object's category? 

Noun label 
Yes 
Yes 
Yes 
Verb labels 
Yes 
Yes 
No 
Sound 
No 
No 
No 
Sound imitations 
No 
Yes 
Somewhat 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="16,48.00,446.04,239.51,156.20"><head>Table A1 Stimuli</head><label>A1</label><figDesc>Used in Experiments 1 and 3</figDesc><table coords="16,48.00,475.44,239.51,126.81">Verbal label 

Percentage producing target 
label in response to the 
nonverbal cue 

Imagery concordance a 

Label cues Sound cues 

n 
17 
13 
13 
Car (automobile) 
94 
3.4 
3.8 
Cat 
100 
3.6 
4.2 
Cow 
100 
3.9 
4.4 
Dog 
100 
3.6 
4.5 
Frog 
100 
4.1 
4.2 
Gun 
59 
4.4 
2.3 
Motorcycle b 
65 
3.2 
3.8 
Rooster 
94 
3.5 
4.3 
Train (locomotive) 
88 
3.2 
4.2 
Whistle 
88 
3.3 
4.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="17,306.00,77.04,240.03,163.19"><head>Table A2 Stimuli</head><label>A2</label><figDesc>Used in Experiment 2Note. All sounds can be downloaded from http://sapir.psych.wisc.edu/ stimuli/labelsSoundsExp2.zip</figDesc><table coords="17,306.50,107.70,239.01,105.53">Verbal label 
Sound imitation cues 
Verb label cues 

Car 
beep beep 
honking 
Cat 
meow 
meowing 
Clock 
tick tock 
ticking 
Cow 
moo 
mooing 
Dog 
arf arf 
barking 
Frog 
ribbit ribbit 
croaking 
Motorcycle 
vroom vroom 
revving 
Phone 
brring brring 
ringing 
Rooster 
cock-a-doodle-doo 
crowing 
Spring 
boing 
bouncing 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that the converse is not necessarily true. On a distributed, sensorimotor theory of concepts<ref type="bibr" coords="2,410.88,665.70,50.80,7.03" target="#b0">(Allport, 1985;</ref><ref type="bibr" coords="2,466.24,665.70,79.67,7.03;2,306.00,675.70,42.33,7.03" target="#b52">Martin, Ungerleider, &amp; Haxby, 2000)</ref>, the visual features are partly constitutive of the "conceptual" representation. A finding that different cues produce equal performance in picture verification may mean that the different cues activate nonoverlapping or partly overlapping representations that are both equally adequate for making a verification judgment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This procedural deviance was due to the fact that Experiment 3 was conducted chronologically prior to Experiment 1. The motorcycle item was added to balance the number of pictures representing artifact and animal categories.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Participants were not told which objects were animals and which were instruments but were told that they would never need to know which ones were which. This distinction was added to the cover story to impose some control over what participants thought the novel nonverbal sounds were. Some of these sounds had characteristics of artifacts, whereas others sounded like they could be made by an animate entity.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">One item, the cartoon car image, was identified as an outlierstandardized Cook's distance Ͼ6 SDs-and was removed. Inclusion of this item artificially inflated all correlation coefficients.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,306.00,355.70,240.03,7.03;13,314.00,365.70,232.03,7.03;13,314.00,375.70,215.57,7.03" xml:id="b0">
	<analytic>
		<title level="a" type="main">Distributed memory, modular subsystems, and dysphasia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Allport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Current perspectives in dysphasia</title>
		<editor>S. K. Newman &amp; R. Epstein</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Churchill Livingstone</publisher>
			<date type="published" when="1985" />
			<biblScope unit="page" from="32" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,385.70,240.01,7.03;13,314.00,395.70,211.60,7.03" xml:id="b1">
	<analytic>
		<title level="a" type="main">Grounded cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.59.103006.093639</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,405.70,240.03,7.03;13,314.00,415.70,232.03,7.03;13,314.00,425.70,232.01,7.03;13,314.00,435.70,78.43,7.03" xml:id="b2">
	<monogr>
		<title level="m" type="main">How the languages we speak shape the ways we think: The FAQs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boroditsky</surname></persName>
		</author>
		<editor>M. Spivey, M. Joanisse, &amp; K. McRae</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
	<note>The Cambridge handbook of psycholinguistics</note>
</biblStruct>

<biblStruct coords="13,306.00,445.70,240.01,7.03;13,314.00,455.70,232.03,7.03;13,314.00,465.70,232.01,7.03;13,314.00,475.70,232.01,7.03;13,314.00,485.70,78.43,7.03" xml:id="b3">
	<analytic>
		<title level="a" type="main">Shaping meanings for language: Universal and language-specific in the acquisition of spatial semantic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bowerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language acquisition and conceptual development</title>
		<editor>M. Bowerman &amp; S. C. Levinson</editor>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="475" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,495.70,240.00,7.03;13,314.00,505.70,76.86,7.03" xml:id="b4">
	<monogr>
		<title level="m" type="main">Study of thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bruner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Goodnow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1956" />
			<publisher>Wiley</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,515.70,240.03,7.03;13,314.00,525.70,232.01,7.03;13,314.00,535.70,64.00,7.03" xml:id="b5">
	<analytic>
		<title level="a" type="main">Amazon&apos;s mechanical Turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buhrmester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
		<idno>doi:10.1177/ 1745691610393980</idno>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3" to="5" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,545.70,240.00,7.03;13,314.00,555.70,36.21,7.03" xml:id="b6">
	<monogr>
		<title level="m" type="main">Conceptual change in childhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,565.70,240.03,7.03;13,314.00,575.70,232.00,7.03;13,314.00,585.70,150.22,7.03" xml:id="b7">
	<analytic>
		<title level="a" type="main">Who&apos;s afraid of the big bad whorf?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Casasanto</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9922.2008.00462.x</idno>
	</analytic>
	<monogr>
		<title level="m">Crosslinguistic differences in temporal language and thought. Language Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="63" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,595.70,240.03,7.03;13,314.00,605.70,232.02,7.03;13,314.00,615.70,216.64,7.03" xml:id="b8">
	<monogr>
		<title level="m" type="main">Can language do the driving? The effect of linguistic input on infants&apos; categorization of support spatial relations. Developmental Psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Casasola</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.41.1.183</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,625.70,240.03,7.03;13,314.00,635.70,232.02,7.03;13,314.00,645.70,232.02,7.03;13,314.00,655.70,78.43,7.03" xml:id="b9">
	<analytic>
		<title level="a" type="main">Magic words: How language augments human computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language and thought: Interdisciplinary themes</title>
		<editor>P. Carruthers &amp; J. Boucher</editor>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="162" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,665.70,240.02,7.03;13,314.00,675.70,232.02,7.03;13,314.00,685.70,127.77,7.03" xml:id="b10">
	<analytic>
		<title level="a" type="main">From the lexicon to expectations about kinds: A role for associative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Colunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.112.2.347</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="347" to="382" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,306.00,695.70,239.99,7.03;13,314.00,705.70,232.02,7.03;13,314.00,715.70,78.43,7.03" xml:id="b11">
	<monogr>
		<title level="m" type="main">The role of language in intelligence. What is intelligence? The Darwin College Lectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Dennett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,77.20,240.02,7.03;14,56.00,87.51,232.01,7.03;14,56.00,97.82,232.01,7.03;14,56.00,108.13,55.99,7.03" xml:id="b12">
	<analytic>
		<title level="a" type="main">A functional MRI study of mental image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>D&amp;apos;esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Detre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stallcup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Alsop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Tippet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Farah</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0028-3932</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">96</biblScope>
			<biblScope unit="page" from="121" to="123" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,118.43,240.02,7.03;14,56.00,128.74,232.01,7.03;14,56.00,139.05,133.16,7.03" xml:id="b13">
	<analytic>
		<title level="a" type="main">More than meets the eye: The role of language in binding and maintaining feature conjunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dessalegn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">2066</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,149.35,240.02,7.03;14,56.00,159.66,232.02,7.03;14,56.00,169.97,158.22,7.03" xml:id="b14">
	<analytic>
		<title level="a" type="main">Do early nouns refer to kinds or distinct shapes? Evidence from 10-month-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dewar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2009.02278.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="252" to="257" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,180.28,240.02,7.03;14,56.00,190.58,232.01,7.03;14,56.00,200.89,232.01,7.03;14,56.00,211.20,109.34,7.03" xml:id="b15">
	<analytic>
		<title level="a" type="main">Shifting visual-attention between objects and locations: Evidence from normal and parietal lesion subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Egly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Driver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Rafal</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.123.2.161</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="161" to="177" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,221.50,240.00,7.03;14,56.00,231.81,205.31,7.03" xml:id="b16">
	<analytic>
		<title level="a" type="main">An alternative view of the mental lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2004.05.003</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="301" to="306" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,242.12,240.03,7.03;14,56.00,252.41,232.02,7.03;14,56.00,262.71,155.99,7.03" xml:id="b17">
	<analytic>
		<title level="a" type="main">Temporal and spatial characteristics of selective encoding from visual displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Eriksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Hoffman</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03212870</idno>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="201" to="204" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,273.00,239.83,7.03;14,56.00,283.30,232.02,7.03;14,56.00,293.59,86.88,7.03" xml:id="b18">
	<analytic>
		<title level="a" type="main">Perceptual expectation evokes category-selective cortical activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhp188</idno>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1245" to="1253" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,303.89,240.01,7.03;14,56.00,314.19,232.00,7.03;14,56.00,324.48,227.66,7.03" xml:id="b19">
	<analytic>
		<title level="a" type="main">The myth of language universals: Language diversity and its importance for cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Levinson</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X0999094X</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="429" to="448" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,334.78,240.02,7.03;14,56.00,345.07,232.02,7.03;14,56.00,355.37,232.02,7.03;14,56.00,365.66,142.96,7.03" xml:id="b20">
	<analytic>
		<title level="a" type="main">A computational model of semantic memory impairment: Modality specificity and emergent category specificity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Farah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.120.4.339</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="339" to="357" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,375.96,240.01,7.03;14,56.00,386.25,232.04,7.03;14,56.00,396.55,232.02,7.03;14,56.00,406.84,22.66,7.03" xml:id="b21">
	<analytic>
		<title level="a" type="main">Flow of activation from V1 to frontal cortex in humans: A framework for defining &quot;early&quot; visual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Foxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Simpson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00221-001-0906-7</idno>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="139" to="150" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,417.14,240.02,7.03;14,56.00,427.43,232.02,7.03;14,56.00,437.80,232.02,6.86;14,56.00,448.02,216.91,7.03" xml:id="b22">
	<analytic>
		<title level="a" type="main">Language and categorization: The acquisition of natural kind terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Coley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perspectives on language and thought: Interrelations in development</title>
		<editor>J. D. Byrnes &amp; S. A. Gelman</editor>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="146" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,458.32,240.03,7.03;14,56.00,468.61,211.28,7.03" xml:id="b23">
	<monogr>
		<title level="m" type="main">Language in mind: Advances in the study of language and thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,478.91,240.01,7.03;14,56.00,489.20,232.01,7.03;14,56.00,499.50,232.02,7.03;14,56.00,509.79,18.89,7.03" xml:id="b24">
	<analytic>
		<title level="a" type="main">Language and thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gleitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papafragou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cambridge handbook of thinking and reasoning</title>
		<editor>K. Holyoak &amp; B. Morrison</editor>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="633" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,520.09,240.02,7.03;14,56.00,530.38,232.01,7.03;14,56.00,540.68,142.65,7.03" xml:id="b25">
	<analytic>
		<title level="a" type="main">Verbal labels modulate perceptual object processing in 1-year-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gliga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Volein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csibra</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn.2010.21427</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,550.97,240.01,7.03;14,56.00,561.27,165.30,7.03" xml:id="b26">
	<monogr>
		<title level="m" type="main">Rethinking linguistic relativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gumperz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Levinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,571.57,240.03,7.03;14,56.00,581.86,232.01,7.03" xml:id="b27">
	<analytic>
		<title level="a" type="main">Cognition is categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of categorization in cognitive science</title>
		<editor>H. Cohen &amp; C. Lefebvre</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="19" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,56.00,592.16,217.97,7.03" xml:id="b28">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/B978-008044612-7/50056-1</idno>
		<imprint>
			<publisher>Elsevier</publisher>
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,602.45,240.03,7.03;14,56.00,612.75,219.76,7.03" xml:id="b29">
	<analytic>
		<title level="a" type="main">Verbal coding in olfactory versus nonolfactory cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Herz</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03209343</idno>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="957" to="964" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,623.04,240.02,7.03;14,56.00,633.34,232.02,7.03;14,56.00,643.63,232.01,7.03;14,56.00,653.93,104.67,7.03" xml:id="b30">
	<monogr>
		<title level="m" type="main">Effects of language comprehension on visual processing: MEG dissociates early perceptual and late N400 effects. Brain and Language. Advance online publication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hirschfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zwitserlood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dobel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandl.2010.07.002</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,664.22,240.00,7.03;14,56.00,674.52,231.99,7.03;14,56.00,684.81,56.66,7.03" xml:id="b31">
	<analytic>
		<title level="a" type="main">Symbolic control of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Colzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Godijn</surname></persName>
		</author>
		<idno>doi:10.1111/ 1467-9280.00367</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="360" to="365" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,48.00,695.11,240.02,7.03;14,56.00,705.40,232.02,7.03;14,56.00,715.70,232.01,7.03;14,314.00,77.20,232.00,7.03;14,314.00,87.33,65.78,7.03" xml:id="b32">
	<analytic>
		<title level="a" type="main">Do languagespecific categories shape conceptual processing? Mandarin classifier distinctions influence eye gaze behavior, but only during linguistic processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bowerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majid</surname></persName>
		</author>
		<idno>doi:10.1163/ 156853710X497167</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Culture</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="39" to="58" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,97.47,240.01,7.03;14,314.00,107.61,207.06,7.03" xml:id="b33">
	<monogr>
		<title level="m" type="main">Foundations of language: Brain, meaning, grammar, and evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Jackendoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,117.74,240.03,7.03;14,314.00,127.88,75.34,7.03" xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<idno type="DOI">10.1037/10538-000</idno>
		<title level="m">Principles of psychology</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Holt</publisher>
			<date type="published" when="1890" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,138.01,240.01,7.03;14,314.00,148.15,94.19,7.03" xml:id="b35">
	<monogr>
		<title level="m" type="main">Concepts, kinds, and cognitive development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Keil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,158.29,240.02,7.03;14,314.00,168.42,232.02,7.03;14,314.00,178.56,232.01,7.03;14,314.00,188.69,20.00,7.03" xml:id="b36">
	<analytic>
		<title level="a" type="main">What&apos;s in the name? Categorical perception for unfamiliar faces can occur through labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kikutani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hanley</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.15.4.787</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,198.83,240.01,7.03;14,314.00,208.97,232.02,7.03;14,314.00,219.10,232.02,7.03;14,314.00,229.31,232.03,6.86;14,314.00,239.37,138.00,7.03" xml:id="b37">
	<analytic>
		<title level="a" type="main">Evidence for two types of spatial representations: Hemispheric specialization for categorical and coordinate relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Cave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Gabrieli</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.15.4.723</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="723" to="735" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,249.51,240.03,7.03;14,314.00,259.65,232.03,7.03;14,314.00,269.78,189.31,7.03" xml:id="b38">
	<analytic>
		<title level="a" type="main">The distinct modes of vision offered by feedforward and recurrent processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A F</forename><surname>Lamme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-2236(00)01657-X</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,279.92,240.03,7.03;14,314.00,290.06,232.01,7.03;14,314.00,300.19,232.01,7.03;14,314.00,310.33,55.33,7.03" xml:id="b39">
	<analytic>
		<title level="a" type="main">From outer to inner space: Linguistic categories and non-linguistic thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Levinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language and conceptualization</title>
		<editor>J. Nuyts &amp; E. Pederson</editor>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="13" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,320.46,240.02,7.03;14,314.00,330.60,232.01,7.03;14,314.00,340.74,117.11,7.03" xml:id="b40">
	<analytic>
		<title level="a" type="main">Of substance: The nature of language effects on entity construal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dunham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carey</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2008.12.001</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="487" to="524" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,350.87,240.04,7.03;14,314.00,361.01,231.99,7.03;14,314.00,371.14,88.89,7.03" xml:id="b41">
	<analytic>
		<title level="a" type="main">Language and the perception of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Lindquist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bliss-Moreau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.6.1.125</idno>
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="125" to="138" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,381.28,240.03,7.03;14,314.00,391.42,232.02,7.03" xml:id="b42">
	<analytic>
		<title level="a" type="main">Grammatical categories and the development of classification preferences: A comparative approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gaskins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">M</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,314.00,401.55,232.01,7.03;14,314.00,411.69,232.00,7.03;14,314.00,421.82,43.33,7.03" xml:id="b43">
	<monogr>
		<title level="m" type="main">Language acquisition and conceptual development</title>
		<editor>Bowerman &amp; S. C. Levinson</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page" from="257" to="283" />
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,431.96,240.01,7.03;14,314.00,442.10,232.03,7.03;14,314.00,452.23,66.00,7.03" xml:id="b44">
	<monogr>
		<title level="m" type="main">The label feedback hypothesis: Linguistic influences on visual processing (Doctoral dissertation)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,462.37,240.02,7.03;14,314.00,472.50,232.03,7.03;14,314.00,482.64,232.01,7.03;14,314.00,492.78,103.31,7.03" xml:id="b45">
	<analytic>
		<title level="a" type="main">Reuniting categories, language, and perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29tj Annual Conference of the Cognitive Science Society</title>
		<editor>D. S. McNamara &amp; J. G. Trafton</editor>
		<meeting>the 29tj Annual Conference of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1247" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,502.91,240.03,7.03;14,314.00,513.05,232.00,7.03;14,314.00,523.18,104.67,7.03" xml:id="b46">
	<analytic>
		<title level="a" type="main">The conceptual grouping effect: Categories matter (and named categories matter more)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2008.03.009</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="566" to="577" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,533.32,240.03,7.03;14,314.00,543.46,232.02,7.03;14,314.00,553.59,207.37,7.03" xml:id="b47">
	<analytic>
		<title level="a" type="main">From chair to &quot;chair&quot;: A representational shift account of object labeling effects on memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.137.2.348</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="348" to="369" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,563.73,240.01,7.03;14,314.00,573.86,232.02,7.03;14,314.00,584.00,232.00,7.03" xml:id="b48">
	<analytic>
		<title level="a" type="main">Language is not just for talking: Labels facilitate learning of novel categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Rakison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2007.02028.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1077" to="1083" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,594.14,240.00,7.03;14,314.00,604.27,232.01,7.03;14,314.00,614.41,110.89,7.03" xml:id="b49">
	<analytic>
		<title level="a" type="main">Making the invisible visible: Auditory cues facilitate visual object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Spivey</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0011452</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11452</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,624.54,240.01,7.03;14,314.00,634.68,232.01,7.03;14,314.00,644.80,143.62,7.03" xml:id="b50">
	<monogr>
		<title level="m" type="main">Redundant spoken labels facilitate perception of multiple items. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Spivey</surname></persName>
		</author>
		<idno type="DOI">10.3758/APP.72.8.2236</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="2236" to="2253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,654.93,240.03,7.03;14,314.00,665.05,232.03,7.03;14,314.00,675.25,232.00,6.86;14,314.00,685.30,231.94,7.03;14,314.00,695.43,77.11,7.03" xml:id="b51">
	<monogr>
		<title level="m" type="main">September). How similar are semantic categories in closely related languages? A comparison of cutting and breaking in four Germanic languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gullberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Staden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bowerman</surname></persName>
		</author>
		<idno type="DOI">10.1515/COG.2007.007</idno>
		<ptr target="http://www.reference-global.com/doi/abs/10.1515/COG.2007.007" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,306.00,705.55,240.04,7.03;14,314.00,715.68,232.01,7.03;15,56.00,77.20,232.03,7.03;15,56.00,87.51,137.53,7.03" xml:id="b52">
	<analytic>
		<title level="a" type="main">Category specificity and the brain: The sensory/motor model of semantic representations of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Ungerleider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The new cognitive neurosciences</title>
		<editor>M. S. Gazzaniga</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1023" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,97.82,240.02,7.03;15,56.00,108.13,232.02,7.03;15,56.00,118.43,222.64,7.03" xml:id="b53">
	<analytic>
		<title level="a" type="main">Motion detection and motion verbs: Language affects low-level visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Meteyard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vigliocco</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2007.02016.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1007" to="1013" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,128.74,240.02,7.03;15,56.00,139.05,232.00,7.03;15,56.00,149.35,232.02,7.03;15,56.00,159.66,208.20,7.03" xml:id="b54">
	<analytic>
		<title level="a" type="main">The influence of memory on perception: It&apos;s not what things look like, it&apos;s what you call them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Horschig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Musseler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majid</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0017019</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1557" to="1562" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,169.97,240.02,7.03;15,56.00,180.28,36.21,7.03" xml:id="b55">
	<monogr>
		<title level="m" type="main">The big book of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,190.58,240.02,7.03;15,56.00,200.89,232.00,7.03;15,56.00,211.20,232.02,7.03;15,56.00,221.51,177.24,7.03" xml:id="b56">
	<analytic>
		<title level="a" type="main">Category differentiation in object recognition: Typicality constraints on the basic category advantage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Brownell</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.11.1.70</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="70" to="84" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,231.81,240.02,7.03;15,56.00,242.12,231.99,7.03;15,56.00,252.41,47.78,7.03" xml:id="b57">
	<analytic>
		<title level="a" type="main">The role of theories in conceptual coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Medin</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.92.3.289</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="289" to="316" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,262.71,240.02,7.03;15,56.00,273.01,232.01,7.03;15,56.00,283.30,140.44,7.03" xml:id="b58">
	<analytic>
		<title level="a" type="main">Basic level superiority in picture categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-5371(82)90412-1</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,293.60,240.00,7.03;15,56.00,303.89,232.00,7.03;15,56.00,314.19,184.88,7.03" xml:id="b59">
	<monogr>
		<title level="m" type="main">Linguistic and cognitive abilities in infancy: When does language become a tool for categorization? Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0010-0277(01)00112-3</idno>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,324.48,240.01,7.03;15,56.00,334.78,118.63,7.03" xml:id="b60">
	<monogr>
		<title level="m" type="main">Mental representations: A dual coding approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,345.07,240.02,7.03;15,56.00,355.37,232.01,7.03;15,56.00,365.66,56.67,7.03" xml:id="b61">
	<analytic>
		<title level="a" type="main">Implicitly perceived objects attract gaze during later free viewing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pertzov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zohary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Avidan</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.6.6</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,375.96,240.01,7.03;15,56.00,386.25,232.02,7.03;15,56.00,396.55,116.08,7.03" xml:id="b62">
	<analytic>
		<title level="a" type="main">Is color &quot;categorical perception&quot; really perceptual?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pilling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wiggett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ozgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R L</forename><surname>Davies</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196095</idno>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="538" to="551" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,406.84,240.01,7.03;15,56.00,417.14,232.01,7.03;15,56.00,427.43,79.10,7.03" xml:id="b63">
	<analytic>
		<title level="a" type="main">Labels can override perceptual categories in early infancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Plunkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<idno>doi: S0010-0277(07</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="108" to="112" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,437.73,240.01,7.03;15,56.00,448.02,232.01,7.03;15,56.00,458.32,142.96,7.03" xml:id="b64">
	<analytic>
		<title level="a" type="main">Attention and the detection of signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R R</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.109.2.160</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="160" to="174" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,468.61,240.00,7.03;15,56.00,478.91,231.99,7.03;15,56.00,489.20,64.89,7.03" xml:id="b65">
	<analytic>
		<title level="a" type="main">Expectation both helps and hinders object perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wojciulik</surname></persName>
		</author>
		<idno>doi:10.1016/ j.visres.2007.11.017</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="589" to="597" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,499.50,240.02,7.03;15,56.00,509.79,232.01,7.03;15,56.00,520.16,139.96,6.86" xml:id="b66">
	<monogr>
		<title level="m" type="main">Developing object concepts in infancy: An associative learning perspective. Monographs of the Society for Research in Child Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Rakison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,530.39,240.02,7.03;15,56.00,540.68,232.03,7.03;15,56.00,550.98,164.45,7.03" xml:id="b67">
	<analytic>
		<title level="a" type="main">The categorical perception of colors and facial expressions: The effect of verbal interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davidoff</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03209345</idno>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="977" to="986" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,561.27,240.02,7.03;15,56.00,571.57,218.85,7.03" xml:id="b68">
	<monogr>
		<title level="m" type="main">Semantic cognition: A parallel distributed processing approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Bradford Book</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,581.86,240.03,7.03;15,56.00,592.16,232.01,7.03;15,56.00,602.45,150.72,7.03" xml:id="b69">
	<analytic>
		<title level="a" type="main">Basic objects in natural categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Mervis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boyes-Braem</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(76)90013-X</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="382" to="439" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,612.75,240.02,7.03;15,56.00,623.04,232.02,7.03;15,56.00,633.34,186.86,7.03" xml:id="b70">
	<analytic>
		<title level="a" type="main">Revisiting Snodgrass and Vanderwart&apos;s object pictorial set: The role of surface detail in basic-level object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rossion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pourtois</surname></persName>
		</author>
		<idno type="DOI">10.1068/p5117</idno>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="217" to="236" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,643.63,240.02,7.03;15,56.00,653.93,232.02,7.03;15,56.00,664.22,228.93,7.03" xml:id="b71">
	<analytic>
		<title level="a" type="main">Search guidance is proportional to the categorical specificity of a target cue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Zelinsky</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210902853530</idno>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1904" to="1914" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,674.52,240.03,7.03;15,56.00,684.81,232.02,7.03;15,56.00,695.11,232.02,7.03;15,56.00,705.40,214.22,7.03" xml:id="b72">
	<analytic>
		<title level="a" type="main">Effects of linguistic and perceptual information on categorization in young children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Sloutsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the XXIII Annual Conference of the Cognitive Science Society</title>
		<editor>J. Moore &amp; K. Stenning</editor>
		<meeting>the XXIII Annual Conference of the Cognitive Science Society<address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="946" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,48.00,715.70,240.01,7.03;15,314.00,77.20,232.01,7.03;15,314.00,87.33,232.01,7.03" xml:id="b73">
	<analytic>
		<title level="a" type="main">Induction and categorization in young children: A similarity-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Sloutsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.133.2.166</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="166" to="188" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,97.47,239.99,7.03;15,314.00,107.61,232.03,7.03;15,314.00,117.74,219.49,7.03" xml:id="b74">
	<analytic>
		<title level="a" type="main">Why is it hard to label our concepts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snedeker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gleitman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From many strands: Weaving a lexicon</title>
		<editor>D. G. Hall &amp; S. R. Waxman</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="257" to="294" />
		</imprint>
	</monogr>
	<note>illustrated ed.</note>
</biblStruct>

<biblStruct coords="15,306.00,127.88,240.04,7.03;15,314.00,138.02,231.99,7.03;15,314.00,148.15,79.10,7.03" xml:id="b75">
	<monogr>
		<title level="m" type="main">Journal of Verbal Learning and Verbal Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Snodgrass</surname></persName>
		</author>
		<idno>doi:10.1016/ S0022-5371</idno>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="90479" to="90480" />
		</imprint>
	</monogr>
	<note>Concepts and their surface representations</note>
</biblStruct>

<biblStruct coords="15,306.00,158.29,240.01,7.03;15,314.00,168.42,232.01,7.03;15,314.00,178.56,232.00,7.03;15,314.00,188.70,94.20,7.03" xml:id="b76">
	<analytic>
		<title level="a" type="main">What makes us smart? Core knowledge and natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Spelke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language in mind: Advances in the study of language and thought</title>
		<editor>D. Gentner &amp; S. Goldin-Meadow</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="277" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,198.83,240.03,7.03;15,314.00,208.97,232.00,7.03;15,314.00,219.11,191.89,7.03" xml:id="b77">
	<monogr>
		<title level="m" type="main">Initial knowledge and conceptual change: Space and number. Language acquisition and conceptual development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Spelke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tsivkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page" from="475" to="511" />
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,229.24,240.03,7.03;15,314.00,239.38,232.02,7.03;15,314.00,249.51,232.00,7.03;15,314.00,259.65,232.00,7.03;15,314.00,269.79,96.22,7.03" xml:id="b78">
	<analytic>
		<title level="a" type="main">Name-picture verification as a control measure for object naming: A task analysis and norms for a large set of pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stadthagen-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Damian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marín</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210802511139</idno>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1581" to="1597" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,279.92,240.02,7.03;15,314.00,290.06,232.02,7.03;15,314.00,300.19,207.60,7.03" xml:id="b79">
	<analytic>
		<title level="a" type="main">Linguistic context and the priming of semantic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tabossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Johnson-Laird</surname></persName>
		</author>
		<idno type="DOI">10.1080/14640748008401848</idno>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="595" to="603" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,310.33,240.03,7.03;15,314.00,320.47,232.01,7.03;15,314.00,330.60,232.02,7.03;15,314.00,340.74,231.97,7.03;15,314.00,350.87,42.00,7.03" xml:id="b80">
	<analytic>
		<title level="a" type="main">Language-naive chimpanzees (Pan troglodytes) judge relations between relations in a conceptual matching-to-sample task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Oden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Boysen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0097-7403.23.1.31</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="1997" />
			<publisher>Animal Behavior Processes</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,361.01,240.04,7.03;15,314.00,371.15,232.02,7.03;15,314.00,381.28,231.99,7.03;15,314.00,391.42,55.99,7.03" xml:id="b81">
	<analytic>
		<title level="a" type="main">A neural basis for category and modality specificity of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Thompson-Schill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Farah</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0028-3932</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">98</biblScope>
			<biblScope unit="page" from="126" to="128" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,401.55,240.00,7.03;15,314.00,411.69,232.01,7.03;15,314.00,421.83,55.99,7.03" xml:id="b82">
	<analytic>
		<title level="a" type="main">Priming by pictures in lexical decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vanderwart</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-5371</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">84</biblScope>
			<biblScope unit="page" from="90509" to="90516" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,431.96,240.00,7.03;15,314.00,442.10,232.00,7.03" xml:id="b83">
	<analytic>
		<title level="a" type="main">Setting up the target template in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Vickery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-W</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno>doi:10:1167/5.1.8</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="81" to="92" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,452.23,240.01,7.03;15,314.00,462.37,75.34,7.03" xml:id="b84">
	<monogr>
		<title level="m" type="main">Thought and language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vygotsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/11193-000</idno>
		<imprint>
			<date type="published" when="1962" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,472.51,240.01,7.03;15,314.00,482.64,231.92,7.03;15,314.00,492.78,68.00,7.03" xml:id="b85">
	<analytic>
		<title level="a" type="main">Semantic guidance of attention within natural scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dassonville</surname></persName>
		</author>
		<idno>doi:10.1080/ 13506280444000670</idno>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">1124</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,502.91,240.02,7.03;15,314.00,513.05,210.12,7.03" xml:id="b86">
	<analytic>
		<title level="a" type="main">Category specific semantic impairments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shallice</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/107.3.829</idno>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="829" to="853" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,523.19,240.02,7.03;15,314.00,533.32,232.02,7.03;15,314.00,543.46,231.05,7.03" xml:id="b87">
	<analytic>
		<title level="a" type="main">The dubbing ceremony revisited: Object naming and categorization in infancy and early childhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Folkbiology</title>
		<editor>D. L. Medin &amp; S. Atran</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="233" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,553.59,240.02,7.03;15,314.00,563.73,232.01,7.03;15,314.00,573.87,232.00,7.03;15,314.00,584.00,232.02,7.03;15,314.00,594.14,142.19,7.03" xml:id="b88">
	<analytic>
		<title level="a" type="main">Everything had a name, and each name gave birth to a new thought: Links between early word-learning and conceptual organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From many strands: Weaving a lexicon</title>
		<editor>D. G. Hall &amp; S. R. Waxman</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="295" to="335" />
		</imprint>
	</monogr>
	<note>Why is it hard to label our concepts?. illustrated ed.</note>
</biblStruct>

<biblStruct coords="15,306.00,604.27,240.02,7.03;15,314.00,614.41,232.03,7.03;15,314.00,624.55,131.63,7.03" xml:id="b89">
	<analytic>
		<title level="a" type="main">Early word-learning entails reference, not merely associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Gelman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2009.03.006</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="258" to="263" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,634.68,240.01,7.03;15,314.00,644.81,232.02,7.03;15,314.00,654.93,232.01,7.03;15,314.00,665.06,56.22,7.03" xml:id="b90">
	<analytic>
		<title level="a" type="main">The development of a linkage between count nouns and object categories: Evidence from 15-monthold to 21-month-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Hall</surname></persName>
		</author>
		<idno type="DOI">10.2307/1131336</idno>
	</analytic>
	<monogr>
		<title level="j">Child Development</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1224" to="1241" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,675.18,240.02,7.03;15,314.00,685.31,232.01,7.03;15,314.00,695.43,167.54,7.03" xml:id="b91">
	<analytic>
		<title level="a" type="main">Words as invitations to form categories: Evidence from 12-to 13-month-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Markow</surname></persName>
		</author>
		<idno type="DOI">10.1006/cogp.1995.1016</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="257" to="302" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,306.00,705.56,240.02,7.03;15,314.00,715.68,232.02,7.03;16,56.00,77.20,232.02,7.03;16,56.00,87.20,88.44,7.03" xml:id="b92">
	<analytic>
		<title level="a" type="main">Bodyspecific motor imagery of hand actions: Neural evidence from right-and left-handers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hagoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Casasanto</surname></persName>
		</author>
		<idno type="DOI">10.3389/neuro.09.039.2009</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,48.00,97.20,239.96,7.03;16,56.00,107.20,232.02,7.03;16,56.00,117.20,232.00,7.03;16,56.00,127.20,231.89,7.03;16,56.00,137.20,42.00,7.03" xml:id="b93">
	<analytic>
		<title level="a" type="main">Russian blues reveal effects of language on color discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winawer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Witthoft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boroditsky</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0701644104</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="7780" to="7785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,48.00,147.20,240.01,7.03;16,56.00,157.20,216.17,7.03" xml:id="b94">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.104</idno>
		<title level="m">Linguistic relativity. Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="253" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,48.00,167.20,240.02,7.03;16,56.00,177.20,232.02,7.03;16,56.00,187.20,138.00,7.03" xml:id="b95">
	<analytic>
		<title level="a" type="main">Rapid word learning in 13-and 18-month-olds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Markman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Fitzsimmons</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.30.4.553</idno>
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="553" to="566" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,48.00,197.20,240.02,7.03;16,56.00,207.20,230.42,7.03" xml:id="b96">
	<analytic>
		<title level="a" type="main">The role of language in acquiring object kind concepts in infancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0010-0277(02)00109-9</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="223" to="250" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,48.00,217.20,240.02,7.03;16,56.00,227.20,232.03,7.03;16,56.00,237.20,232.01,7.03;16,56.00,247.20,168.69,7.03" xml:id="b97">
	<monogr>
		<title level="m" type="main">Early category and concept development: Making sense of the blooming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<editor>D. H. Rakison &amp; L. M. Oakes</editor>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="63" to="89" />
			<pubPlace>Oxford, England</pubPlace>
		</imprint>
	</monogr>
	<note>Categories, kinds, and object individuation in infancy. buzzing confusion</note>
</biblStruct>

<biblStruct coords="16,306.00,77.20,240.02,7.03;16,314.00,87.28,232.02,6.86;16,314.00,97.20,168.73,7.03" xml:id="b98">
	<analytic>
		<title level="a" type="main">Inference using categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamauchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Markman</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.26.3.776</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="776" to="795" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,306.00,107.20,240.00,7.03;16,314.00,117.20,231.85,7.03;16,314.00,127.20,93.11,7.03" xml:id="b99">
	<analytic>
		<title level="a" type="main">Visual search is guided to categorically-defined targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Zelinsky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2009.05.017</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="2095" to="2103" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,306.00,137.20,239.99,7.03;16,314.00,147.20,232.02,7.03;16,314.00,157.20,105.34,7.03" xml:id="b100">
	<analytic>
		<title level="a" type="main">Known and novel noun extensions: Attention at two levels of abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-8624.7402016</idno>
	</analytic>
	<monogr>
		<title level="j">Child Development</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="564" to="577" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,306.00,167.20,240.01,7.03;16,314.00,177.20,232.01,7.03;16,314.00,187.20,84.89,7.03" xml:id="b101">
	<analytic>
		<title level="a" type="main">Linguistic cues enhance the learning of perceptual cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
		<idno>doi:10.1111/ j.0956-7976.2005.00787.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="90" to="95" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,306.00,197.20,240.02,7.03;16,314.00,207.20,232.01,7.03;16,314.00,217.20,188.49,7.03" xml:id="b102">
	<analytic>
		<title level="a" type="main">The dog&apos;s meow: Asymmetrical interaction in cross-modal object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yuval-Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deouell</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00221-008-1664-6</idno>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="603" to="614" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,306.00,227.20,240.01,7.03;16,314.00,237.20,232.02,7.03;16,314.00,247.20,162.94,7.03" xml:id="b103">
	<analytic>
		<title level="a" type="main">Language comprehenders mentally represent the shapes of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Stanfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Yaxley</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.00430</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="168" to="171" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
